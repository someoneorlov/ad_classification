{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e_Aqq6abmn80"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "FOLDER_PATH = '/content/drive/MyDrive/Colab Notebooks/project/'\n",
    "sys.path.append(FOLDER_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 28432,
     "status": "ok",
     "timestamp": 1655659097397,
     "user": {
      "displayName": "Никита Орлов",
      "userId": "17221654573895787003"
     },
     "user_tz": -180
    },
    "id": "ng0KOOvlou6J",
    "outputId": "b12d52c4-753c-4898-ea3c-2031408e7298"
   },
   "outputs": [],
   "source": [
    "!pip install -r drive/MyDrive/Colab\\ Notebooks/project/requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4356,
     "status": "ok",
     "timestamp": 1655659101706,
     "user": {
      "displayName": "Никита Орлов",
      "userId": "17221654573895787003"
     },
     "user_tz": -180
    },
    "id": "Zw203rcwTKo7",
    "outputId": "9007d301-fe21-46da-aec2-a6a33532dde7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 2 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import imp\n",
    "import time\n",
    "import datetime\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "from pandarallel import pandarallel\n",
    "pandarallel.initialize(progress_bar=False)\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "\n",
    "from transformers import BertTokenizer, BertConfig\n",
    "from transformers import BertForSequenceClassification, AdamW\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from torch.utils.data import TensorDataset, random_split\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "# pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1654637899483,
     "user": {
      "displayName": "Никита Орлов",
      "userId": "17221654573895787003"
     },
     "user_tz": -180
    },
    "id": "AkeCLn_rmoUO",
    "outputId": "892e35a9-485f-4efe-8381-4c98f92c27b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found GPU at: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "device_name = tf.test.gpu_device_name()\n",
    "\n",
    "if device_name == '/device:GPU:0':\n",
    "    print('Found GPU at: {}'.format(device_name))\n",
    "else:\n",
    "    raise SystemError('GPU device not found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 436,
     "status": "ok",
     "timestamp": 1654637912344,
     "user": {
      "displayName": "Никита Орлов",
      "userId": "17221654573895787003"
     },
     "user_tz": -180
    },
    "id": "0fcsZCuDnHev",
    "outputId": "3d77e866-475b-4872-ce94-668e03d30fc8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: Tesla T4\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():    \n",
    "    device = torch.device(\"cuda\")\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GxP56LfYNOJ0"
   },
   "outputs": [],
   "source": [
    "def auc_group(df):\n",
    "    y = df['is_bad']\n",
    "    y_hat = df['predict_bert']\n",
    "    try:\n",
    "        return roc_auc_score(y, y_hat)\n",
    "    except ValueError:\n",
    "        return 0.5\n",
    "\n",
    "def flat_roc_auc(preds, labels):\n",
    "    pred_flat = preds[:, 1].flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    try:\n",
    "        return roc_auc_score(labels_flat, pred_flat)\n",
    "    except ValueError:\n",
    "        return 0.5\n",
    "\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5A2lSDcMmoW9"
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('./drive/MyDrive/Colab Notebooks/project/_data/train_prep.csv', sep='|')\n",
    "df_val = pd.read_csv('./drive/MyDrive/Colab Notebooks/project/_data/val_prep.csv', sep='|')\n",
    "df_test = pd.read_csv('./drive/MyDrive/Colab Notebooks/project/_data/test_prep.csv', sep='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10811,
     "status": "ok",
     "timestamp": 1654637981991,
     "user": {
      "displayName": "Никита Орлов",
      "userId": "17221654573895787003"
     },
     "user_tz": -180
    },
    "id": "aSumlkqUniw1",
    "outputId": "976fae36-0869-4fde-e761-e880309964a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.63 s, sys: 5.41 s, total: 8.04 s\n",
      "Wall time: 10.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "df_train['is_empty_price'] = df_train['is_empty_price'].parallel_apply(\n",
    "    lambda x: 'цена пустая' if pd.isna(x) else 'цена {}'.format(x))\n",
    "df_train['month'] = df_train['month'].parallel_apply(\n",
    "    lambda x: 'месяц {}'.format(str(x))).astype('str')\n",
    "df_train['hour'] = df_train['hour'].parallel_apply(\n",
    "    lambda x: 'час {}'.format(str(x))).astype('str')\n",
    "df_train['is_full_phone'] = df_train['is_full_phone'].parallel_apply(\n",
    "    lambda x: 'есть полный' if x == 1 else 'нет полного').astype('str')\n",
    "df_train['is_short_phone'] = df_train['is_short_phone'].parallel_apply(\n",
    "    lambda x: 'есть короткий' if x == 1 else 'нет короткого').astype('str')\n",
    "df_train['num_words_count'] = df_train['num_words_count'].parallel_apply(\n",
    "    lambda x: 'слов {}'.format(str(x))).astype('str')\n",
    "df_train['digits_count'] = df_train['digits_count'].parallel_apply(\n",
    "    lambda x: 'цифр {}'.format(str(x))).astype('str')\n",
    "df_train['contact_words_count'] = df_train['contact_words_count'].parallel_apply(\n",
    "    lambda x: 'контактных {}'.format(str(x))).astype('str')\n",
    "df_train['tel_count'] = df_train['tel_count'].parallel_apply(\n",
    "    lambda x: 'телефонов {}'.format(str(x))).astype('str')\n",
    "df_train['count_emoji'] = df_train['count_emoji'].parallel_apply(\n",
    "    lambda x: 'эмодзи {}'.format(str(x))).astype('str')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5018,
     "status": "ok",
     "timestamp": 1654637987003,
     "user": {
      "displayName": "Никита Орлов",
      "userId": "17221654573895787003"
     },
     "user_tz": -180
    },
    "id": "Rsy00vTDni0K",
    "outputId": "8724208e-4cab-4279-b9c5-c83fdce1b1b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 345 ms, sys: 4.63 s, total: 4.97 s\n",
      "Wall time: 5.09 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "df_val['is_empty_price'] = df_val['is_empty_price'].parallel_apply(\n",
    "    lambda x: 'цена пустая' if pd.isna(x) else 'цена {}'.format(x))\n",
    "df_val['month'] = df_val['month'].parallel_apply(\n",
    "    lambda x: 'месяц {}'.format(str(x))).astype('str')\n",
    "df_val['hour'] = df_val['hour'].parallel_apply(\n",
    "    lambda x: 'час {}'.format(str(x))).astype('str')\n",
    "df_val['is_full_phone'] = df_val['is_full_phone'].parallel_apply(\n",
    "    lambda x: 'есть полный' if x == 1 else 'нет полного').astype('str')\n",
    "df_val['is_short_phone'] = df_val['is_short_phone'].parallel_apply(\n",
    "    lambda x: 'есть короткий' if x == 1 else 'нет короткого').astype('str')\n",
    "df_val['num_words_count'] = df_val['num_words_count'].parallel_apply(\n",
    "    lambda x: 'слов {}'.format(str(x))).astype('str')\n",
    "df_val['digits_count'] = df_val['digits_count'].parallel_apply(\n",
    "    lambda x: 'цифр {}'.format(str(x))).astype('str')\n",
    "df_val['contact_words_count'] = df_val['contact_words_count'].parallel_apply(\n",
    "    lambda x: 'контактных {}'.format(str(x))).astype('str')\n",
    "df_val['tel_count'] = df_val['tel_count'].parallel_apply(\n",
    "    lambda x: 'телефонов {}'.format(str(x))).astype('str')\n",
    "df_val['count_emoji'] = df_val['count_emoji'].parallel_apply(\n",
    "    lambda x: 'эмодзи {}'.format(str(x))).astype('str')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5126,
     "status": "ok",
     "timestamp": 1654637992123,
     "user": {
      "displayName": "Никита Орлов",
      "userId": "17221654573895787003"
     },
     "user_tz": -180
    },
    "id": "DEeYO7Xw2ldR",
    "outputId": "64eb65c5-db0a-47f4-caed-d8ab80d68d4c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 179 ms, sys: 4.35 s, total: 4.53 s\n",
      "Wall time: 4.59 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "df_test['is_empty_price'] = df_test['is_empty_price'].parallel_apply(\n",
    "    lambda x: 'цена пустая' if pd.isna(x) else 'цена {}'.format(x))\n",
    "df_test['month'] = df_test['month'].parallel_apply(\n",
    "    lambda x: 'месяц {}'.format(str(x))).astype('str')\n",
    "df_test['hour'] = df_test['hour'].parallel_apply(\n",
    "    lambda x: 'час {}'.format(str(x))).astype('str')\n",
    "df_test['is_full_phone'] = df_test['is_full_phone'].parallel_apply(\n",
    "    lambda x: 'есть полный' if x == 1 else 'нет полного').astype('str')\n",
    "df_test['is_short_phone'] = df_test['is_short_phone'].parallel_apply(\n",
    "    lambda x: 'есть короткий' if x == 1 else 'нет короткого').astype('str')\n",
    "df_test['num_words_count'] = df_test['num_words_count'].parallel_apply(\n",
    "    lambda x: 'слов {}'.format(str(x))).astype('str')\n",
    "df_test['digits_count'] = df_test['digits_count'].parallel_apply(\n",
    "    lambda x: 'цифр {}'.format(str(x))).astype('str')\n",
    "df_test['contact_words_count'] = df_test['contact_words_count'].parallel_apply(\n",
    "    lambda x: 'контактных {}'.format(str(x))).astype('str')\n",
    "df_test['tel_count'] = df_test['tel_count'].parallel_apply(\n",
    "    lambda x: 'телефонов {}'.format(str(x))).astype('str')\n",
    "df_test['count_emoji'] = df_test['count_emoji'].parallel_apply(\n",
    "    lambda x: 'эмодзи {}'.format(str(x))).astype('str')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m1v9jDBUni6n"
   },
   "outputs": [],
   "source": [
    "df_train['text'] = df_train.fillna('')[[\n",
    "                'title_prep_l', \n",
    "                'desc_prep_l', \n",
    "                'subcategory', \n",
    "                'category', \n",
    "                'region', \n",
    "                'is_empty_price', \n",
    "                'month', \n",
    "                'hour', \n",
    "                'is_full_phone', \n",
    "                'is_short_phone', \n",
    "                'num_words_count', \n",
    "                'digits_count', \n",
    "                'contact_words_count', \n",
    "                'tel_count', \n",
    "                'count_emoji']].agg(' '.join, axis=1)\n",
    "df_val['text'] = df_val.fillna('')[[\n",
    "                'title_prep_l', \n",
    "                'desc_prep_l', \n",
    "                'subcategory', \n",
    "                'category', \n",
    "                'region', \n",
    "                'is_empty_price', \n",
    "                'month', \n",
    "                'hour', \n",
    "                'is_full_phone', \n",
    "                'is_short_phone', \n",
    "                'num_words_count', \n",
    "                'digits_count', \n",
    "                'contact_words_count', \n",
    "                'tel_count', \n",
    "                'count_emoji']].agg(' '.join, axis=1)\n",
    "df_test['text'] = df_test.fillna('')[[\n",
    "                'title_prep_l', \n",
    "                'desc_prep_l', \n",
    "                'subcategory', \n",
    "                'category', \n",
    "                'region', \n",
    "                'is_empty_price', \n",
    "                'month', \n",
    "                'hour', \n",
    "                'is_full_phone', \n",
    "                'is_short_phone', \n",
    "                'num_words_count', \n",
    "                'digits_count', \n",
    "                'contact_words_count', \n",
    "                'tel_count', \n",
    "                'count_emoji']].agg(' '.join, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12052,
     "status": "ok",
     "timestamp": 1654638040528,
     "user": {
      "displayName": "Никита Орлов",
      "userId": "17221654573895787003"
     },
     "user_tz": -180
    },
    "id": "LygEUSw26W93",
    "outputId": "90032d52-498b-4437-abb7-d1aaec462771"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    886038.000000\n",
       "mean         96.523757\n",
       "std          81.957491\n",
       "min          24.000000\n",
       "25%          43.000000\n",
       "50%          63.000000\n",
       "75%         121.000000\n",
       "90%         201.000000\n",
       "95%         271.000000\n",
       "99%         414.000000\n",
       "max        1153.000000\n",
       "Name: text, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['text'].parallel_apply(\n",
    "    lambda x: len(x.split())).describe([.25, .5, .75, .9, .95, .99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145,
     "referenced_widgets": [
      "876182259d4641c6924e0c0b6cf44ed9",
      "d7f676d7537e4534b61cbc2047071705",
      "29a00386264b4e62b9ea5d6e1067054c",
      "aaddc2bb67d6417cb6423d8e596b1bf9",
      "4b5e777a4a96423daca8076369398642",
      "5c4b7ba1d4bc4f1c9a236f8012ad0d26",
      "c6a086f0872d4c6caccbb438bf5cc300",
      "30438e54b06e4b12833ffe738cb9d233",
      "cf7274ce4c3d42028ad256108e67f120",
      "593ba65557a541b8bdb38037d9fd0a1e",
      "a92f0d23b5774fa1bafe30a24eecf4d1",
      "dfa9a81186764e1db86c2fb5e16a4aad",
      "df09aace68a143829e3eb99b6859d138",
      "30b30a1d140740e4bde9543a617e635a",
      "65a8d99e2bd54dc4b3b4c7aef779b2df",
      "af032737f88a497baea5cfcd1eff8c81",
      "8bf26675224348db9a67a98b71213b59",
      "a376f520e405413fb03ba1d402e12d56",
      "484099351add4e5592fd3eb789fae512",
      "b00badb5a5bd40b599f24d284205dfcb",
      "b61afbe1091840f29a2faed5bde0875f",
      "feba45020c754830b7332a4b329c0e9f",
      "3cc1e5ac220845fe9d307828267ab28c",
      "3fba166dda4c4ab5ad57ff3630238b64",
      "1c774e0029b0451b9ae6c3af7b8a1141",
      "7ce6f44f6bfb484b89a15884fa1e3542",
      "a353afa3a08f44d1961cb0bfe68e3e52",
      "a44c550b9a9c401cb947082e6a265b26",
      "758b78759d75479ab441efcc9f1e32dc",
      "4a3ad148b12c4af4be28dc579ca4180d",
      "50b37be900a24c40bb50c8976261836c",
      "c068ad5eb1b44047993cbbef767be0f8",
      "b837e6a7bac24fedb92b7802168ce640",
      "5cee5851f1f447668c9bdc6907bfc2f0",
      "d3c1327977484bb2acd15cd33ec7e119",
      "23897c9fe7cc40818615466a92a7a928",
      "8f63360cfacc49f388fdb848097d5ec4",
      "1f8cb1a444fc4ea7847f7b72f517498c",
      "6d5edf645e12481f934e60caba667fe0",
      "44f319aff64c4bd1bbb9c71abbde14c7",
      "da8caa8d438c4418af22e61c56521da7",
      "e0321a99b6d74bc98e5b8f43c8418055",
      "2e08d9642e4745d8a0997ddd73033fbf",
      "81910c054aeb4e36a6574d8fdded3f00"
     ]
    },
    "executionInfo": {
     "elapsed": 1348,
     "status": "ok",
     "timestamp": 1654638041868,
     "user": {
      "displayName": "Никита Орлов",
      "userId": "17221654573895787003"
     },
     "user_tz": -180
    },
    "id": "I7OdcEWR8CMc",
    "outputId": "dee583e9-3e2f-4b99-8d16-4daca278403f"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "876182259d4641c6924e0c0b6cf44ed9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.57M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfa9a81186764e1db86c2fb5e16a4aad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cc1e5ac220845fe9d307828267ab28c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/24.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cee5851f1f447668c9bdc6907bfc2f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/642 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\n",
    "    'DeepPavlov/rubert-base-cased', \n",
    "    do_lower_case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WJZmho1fTlrC"
   },
   "outputs": [],
   "source": [
    "max_len = 270"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PfSmo6AQ8YXy"
   },
   "source": [
    "## Train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wD6NouQ8tsHz"
   },
   "outputs": [],
   "source": [
    "sentences = df_train['text'].values\n",
    "labels = df_train['is_bad'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 681,
     "referenced_widgets": [
      "5da14ccd33844a89a47b88a63e90c5a6",
      "8f96098c11ce412c9abd6765d7ef0a27",
      "1b798bb4873842a68a4fd6e1061f58fa",
      "6ea7ff4b866e4023a37e890f44bda847",
      "e67f25a6e9b24c6395607e80fbe4e418",
      "2867cfebe57c41a290c702c879635fa3",
      "4ba0da3784784e9b96e1c257d355c011",
      "cc5ea50bc77a434488a5bc88e8ee13f1",
      "057a965896ed4378ab5339db4b6155d4",
      "92d14e2ad1a54671b9380c6ca94bf14b",
      "5d5cfc77b6e24a26a3fa64cb22c64fad"
     ]
    },
    "executionInfo": {
     "elapsed": 2437621,
     "status": "ok",
     "timestamp": 1654520407573,
     "user": {
      "displayName": "Никита Орлов",
      "userId": "17221654573895787003"
     },
     "user_tz": -180
    },
    "id": "IGboJy24tsbe",
    "outputId": "f25243f2-4173-49c5-cc63-9a3c5eedbbd0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5da14ccd33844a89a47b88a63e90c5a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/886038 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2291: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  капот toyota camry арт. 43381 капот номер производителя: 3220622610 подходит на toyota camry xv50 (тойота, тоета, тойета, камри) ・・・ артикул 43381. пожалуйста, назовите его при звонке. запчасть в наличии на собственном складе. дополнительную информацию по наличию и состоянию запчастей можно получить по телефону или написать сообщение в avito, whatsapp, viber. отправляем в регионы через деловые линии, пэк, ратэк, энергия, байкал, желдор. принимаем заказы на запчасти для любых автомобилей. выкупаем иномарки в разбор в любом состоянии. эвакуатор предоставляем. принимаем авто под реализацию. авторазбор у иваныча крупнейший авто разбор в самарской области. г. тольятти, южное шоссе, 602б график работы: пн сб с 9:00 69:00 вс. с 9:00 67:00 код: 9vysgan58z8idz5tkte54a капот. Запчасти и аксессуары Транспорт Самарская область цена 0 месяц 7 час 14 нет полного есть короткий слов 0 цифр 46 контактных 5 телефонов 3 эмодзи 0\n",
      "Token IDs: tensor([   101, 108623,  10626,  16106,  10725,  88918,  11420,   8427,    132,\n",
      "         43896,  51641, 108623,  15024,  33204,    156,  31551,    137,  46823,\n",
      "         22336,  13368,  32590,   1469,  10626,  16106,  10725,  88918,  11420,\n",
      "           278,    275,  11875,    120,  14578,   5866,    128,   3815,   3181,\n",
      "           128,  14578,   3181,    128,   6676,   2828,    122,   2540,   2540,\n",
      "          2540,  65043,   3313,  43896,  51641,    132, 114408,    128,  83082,\n",
      "         13185,   2752,   2790,  21648,   3231,    132,   3443,  14098,    896,\n",
      "           845,  25097,   1469,  36918,  57207,    132,  42813,  13373,   1516,\n",
      "         73575,    851,  13629,  78928,   7021,  12993,   1516,  33137,   3474,\n",
      "         31283,  17150,    845,  10682,  12902,    128,  13488,  10978,  14815,\n",
      "           128,  14468,  12724,    132,   7309,  13745,    845,  35030,   5806,\n",
      "         65234,  10479,    128,  70606,    862,    128,  24264,  14411,    128,\n",
      "         35641,    128,  61068,   1444,    128,   5630,  36315,    132,   7767,\n",
      "          4917,  48701,   1469,  90743,   2748,  28932,  16626,    132,  43446,\n",
      "          1515,  44887,  23894,    845,  33900,    845,  26689,  13922,    132,\n",
      "         15221,   5855,  10337,  13745,    132,   7767,   4917,   8157,   2068,\n",
      "         36392,    132,  18730,    856,   3339,    875, 109909,   1468,  13547,\n",
      "         26061,   8157,  33900,    845,  18106,  39205,   4161,    132,    847,\n",
      "           132,  88951,   3425,    128,  90936,  16681,    128,  50833,    844,\n",
      "         36063,   7089,    156,    871,    858,  10887,    869,    154,    156,\n",
      "         11537,  13085,    156,  11537,   2901,    132,    869,    154,    156,\n",
      "         11537,  12828,    156,  11537,  10044,    156,    154,  15855,  84617,\n",
      "          3808,  36849,    283,    153,   8599,    283,    147,    271,  13007,\n",
      "           241,  36695,    233, 108623,    132,   7639,  25652,    851,  68810,\n",
      "         31944,  78175,   9102,  23059,    136,  16293,    150,   7897,   4750,\n",
      "          8953,  23057,   6818,  29038,   4969,    136,  51660,  12040, 112401,\n",
      "           146,  34169,    142,  21526,  53583,    136,    102,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0])\n"
     ]
    }
   ],
   "source": [
    "input_ids = []\n",
    "attention_masks = []\n",
    "\n",
    "for sent in tqdm_notebook(sentences):\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        sent,\n",
    "                        add_special_tokens = True,\n",
    "                        max_length = max_len,\n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True,\n",
    "                        return_tensors = 'pt',\n",
    "                        truncation=True\n",
    "                   )\n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "    attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)\n",
    "labels = torch.tensor(labels)\n",
    "\n",
    "print('Original: ', sentences[0])\n",
    "print('Token IDs:', input_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iF2-hYNwzJkW"
   },
   "outputs": [],
   "source": [
    "# with open('{}bert_new/train_encoded_dict.pickle'.format(FOLDER_PATH), 'wb') as f:\n",
    "#   pickle.dump(encoded_dict, f)\n",
    "\n",
    "# with open('{}bert_new/train_input_ids.pickle'.format(FOLDER_PATH), 'wb') as f:\n",
    "#   pickle.dump(input_ids, f)\n",
    "\n",
    "# with open('{}bert_new/train_attention_masks.pickle'.format(FOLDER_PATH), 'wb') as f:\n",
    "#   pickle.dump(attention_masks, f)\n",
    "\n",
    "# with open('{}bert_new/train_labels.pickle'.format(FOLDER_PATH), 'wb') as f:\n",
    "#   pickle.dump(labels, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2-11Y1GO0Qw2"
   },
   "outputs": [],
   "source": [
    "# with open('{}bert_new/train_encoded_dict.pickle'.format(FOLDER_PATH), 'rb') as f:\n",
    "#   train_encoded_dict = pickle.load(f)\n",
    "\n",
    "with open('{}bert_new/train_input_ids.pickle'.format(FOLDER_PATH), 'rb') as f:\n",
    "  train_input_ids = pickle.load(f)\n",
    "\n",
    "with open('{}bert_new/train_attention_masks.pickle'.format(FOLDER_PATH), 'rb') as f:\n",
    "  train_attention_masks = pickle.load(f)\n",
    "\n",
    "with open('{}bert_new/train_labels.pickle'.format(FOLDER_PATH), 'rb') as f:\n",
    "  train_labels = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0z1S6Xs69pYd"
   },
   "source": [
    "# Val data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NnvZTW1R9xCJ"
   },
   "outputs": [],
   "source": [
    "sentences = df_val['text'].values\n",
    "labels = df_val['is_bad'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 681,
     "referenced_widgets": [
      "95906dd8dfdc431bbc58679dc8bda46e",
      "b3713751711b4557897a6ce904fc6377",
      "3ebfd9fdcdb042b2b5e13308aa872e93",
      "ae8b408ea4c2484da9b6f01e8530bb01",
      "24e36f8a747347adaee71ec8baff30ba",
      "05a057f5242247f586ed2cc6468e4aa9",
      "d396c4021235419080e8c93a72cd017e",
      "9e754f6b27ce4004b6229e5e9b3bcbfa",
      "05fbe7bb7190462d9e1189d2e81fb7f6",
      "095dfcdff7944b0c9470e0fe85f69225",
      "fddb966dbc184598b3fbf401fceb1462"
     ]
    },
    "executionInfo": {
     "elapsed": 276895,
     "status": "ok",
     "timestamp": 1654520727904,
     "user": {
      "displayName": "Никита Орлов",
      "userId": "17221654573895787003"
     },
     "user_tz": -180
    },
    "id": "6L7w2dsf9xUS",
    "outputId": "11a6010c-8b15-4883-903c-fe1d8daf008b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95906dd8dfdc431bbc58679dc8bda46e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/98449 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2291: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  samsung j7 6028 года практически новый телефон. без царапин, и глюков. всегда был в чехле. продаю так как нужны деньги. Телефоны Бытовая электроника Рязанская область цена 0 месяц 8 час 12 нет полного нет короткого слов 0 цифр 0 контактных 1 телефонов 1 эмодзи 0\n",
      "Token IDs: tensor([   101,  10660,  12899,  11228,    250,    151,  50833,    153,   1768,\n",
      "         11774,  10303,  17469,    132,   4428,  81695,   1505,    128,    851,\n",
      "         41939,   1388,    132,  12929,   2067,    845,  25989,   2832,    132,\n",
      "          3462,  16988,   2306,   2739,  36700,  13671,    132,  16655,    880,\n",
      "         75236,  11357,  85655,  71352,   9102,  23059,    136,  16293,    152,\n",
      "          7897,   4367,   8953,  23057,   8953,  44450,   4969,    136,  51660,\n",
      "           136, 112401,    138,  34169,    138,  21526,  53583,    136,    102,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0])\n"
     ]
    }
   ],
   "source": [
    "input_ids = []\n",
    "attention_masks = []\n",
    "\n",
    "for sent in tqdm_notebook(sentences):\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        sent,\n",
    "                        add_special_tokens = True,\n",
    "                        max_length = max_len,\n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True,\n",
    "                        return_tensors = 'pt',\n",
    "                        truncation=True\n",
    "                   )\n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "    attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)\n",
    "labels = torch.tensor(labels)\n",
    "\n",
    "print('Original: ', sentences[0])\n",
    "print('Token IDs:', input_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zWmXQEqG9xdw"
   },
   "outputs": [],
   "source": [
    "# with open('{}bert_new/val_encoded_dict.pickle'.format(FOLDER_PATH), 'wb') as f:\n",
    "#   pickle.dump(encoded_dict, f)\n",
    "\n",
    "# with open('{}bert_new/val_input_ids.pickle'.format(FOLDER_PATH), 'wb') as f:\n",
    "#   pickle.dump(input_ids, f)\n",
    "\n",
    "# with open('{}bert_new/val_attention_masks.pickle'.format(FOLDER_PATH), 'wb') as f:\n",
    "#   pickle.dump(attention_masks, f)\n",
    "\n",
    "# with open('{}bert_new/val_labels.pickle'.format(FOLDER_PATH), 'wb') as f:\n",
    "#   pickle.dump(labels, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2I9fqJpE9xmO"
   },
   "outputs": [],
   "source": [
    "# with open('{}bert_new/val_encoded_dict.pickle'.format(FOLDER_PATH), 'rb') as f:\n",
    "#   val_encoded_dict = pickle.load(f)\n",
    "\n",
    "with open('{}bert_new/val_input_ids.pickle'.format(FOLDER_PATH), 'rb') as f:\n",
    "    val_input_ids = pickle.load(f)\n",
    "\n",
    "with open('{}bert_new/val_attention_masks.pickle'.format(FOLDER_PATH), 'rb') as f:\n",
    "    val_attention_masks = pickle.load(f)\n",
    "\n",
    "with open('{}bert_new/val_labels.pickle'.format(FOLDER_PATH), 'rb') as f:\n",
    "    val_labels = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7vB1qoJQ-TMh"
   },
   "source": [
    "# Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2hrLpw3s9x2q"
   },
   "outputs": [],
   "source": [
    "sentences = df_test['text'].values\n",
    "labels = df_test['is_bad'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 681,
     "referenced_widgets": [
      "f65213fb61534f91812fb209fe851104",
      "bf1b459ed2c64ac6aad50ca2ead6b418",
      "ed81d0dcffc244c6963f97a3cd3ac91b",
      "2cf074fb0ace470d90e82fef4a4be4c0",
      "11374bd33580487483d643da4c38d838",
      "952aabb078474aa299ce60bcd38af2c6",
      "e58cb3a9d5b64acbaf11ef3d15032f2c",
      "aec7707589d24291b9e5ef97f90daee1",
      "523bd4d09a58439794e7706be0787d11",
      "7d3dd9bcd2544d8b894e88fcdb1eca6f",
      "3d5429c2c86c46fa83f6a52e7a6ccb80"
     ]
    },
    "executionInfo": {
     "elapsed": 58029,
     "status": "ok",
     "timestamp": 1654520789217,
     "user": {
      "displayName": "Никита Орлов",
      "userId": "17221654573895787003"
     },
     "user_tz": -180
    },
    "id": "v7SzQB509ySs",
    "outputId": "de3a8b1f-4aec-4882-8479-3f5955b314ce"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f65213fb61534f91812fb209fe851104",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16237 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2291: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  шины звонить 89425546881 Запчасти и аксессуары Транспорт Тульская область цена 0 месяц 10 час 0 есть полный есть короткий слов 0 цифр 11 контактных 1 телефонов 0 эмодзи 0\n",
      "Token IDs: tensor([   101,  53612,  98957,  74918,  17104,  36695,  36406,  51641,   7639,\n",
      "         25652,    851,  68810,  31944,  81763,   9102,  23059,    136,  16293,\n",
      "          3955,   7897,    136,   6818,  21228,   6818,  29038,   4969,    136,\n",
      "         51660,   4639, 112401,    138,  34169,    136,  21526,  53583,    136,\n",
      "           102,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
      "             0,      0,      0,      0,      0,      0,      0,      0,      0])\n"
     ]
    }
   ],
   "source": [
    "input_ids = []\n",
    "attention_masks = []\n",
    "\n",
    "for sent in tqdm_notebook(sentences):\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        sent,\n",
    "                        add_special_tokens = True,\n",
    "                        max_length = max_len,\n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True,\n",
    "                        return_tensors = 'pt',\n",
    "                        truncation=True\n",
    "                   )\n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "    attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)\n",
    "labels = torch.tensor(labels)\n",
    "\n",
    "print('Original: ', sentences[0])\n",
    "print('Token IDs:', input_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9XCwK3w79ymT"
   },
   "outputs": [],
   "source": [
    "# with open('{}bert_new/test_encoded_dict.pickle'.format(FOLDER_PATH), 'wb') as f:\n",
    "#   pickle.dump(encoded_dict, f)\n",
    "\n",
    "# with open('{}bert_new/test_input_ids.pickle'.format(FOLDER_PATH), 'wb') as f:\n",
    "#   pickle.dump(input_ids, f)\n",
    "\n",
    "# with open('{}bert_new/test_attention_masks.pickle'.format(FOLDER_PATH), 'wb') as f:\n",
    "#   pickle.dump(attention_masks, f)\n",
    "\n",
    "# with open('{}bert_new/test_labels.pickle'.format(FOLDER_PATH), 'wb') as f:\n",
    "#   pickle.dump(labels, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0fOzy_qw-d9Y"
   },
   "outputs": [],
   "source": [
    "# with open('{}bert_new/test_encoded_dict.pickle'.format(FOLDER_PATH), 'rb') as f:\n",
    "#   test_encoded_dict = pickle.load(f)\n",
    "\n",
    "with open('{}bert_new/test_input_ids.pickle'.format(FOLDER_PATH), 'rb') as f:\n",
    "    test_input_ids = pickle.load(f)\n",
    "\n",
    "with open('{}bert_new/test_attention_masks.pickle'.format(FOLDER_PATH), 'rb') as f:\n",
    "    test_attention_masks = pickle.load(f)\n",
    "\n",
    "with open('{}bert_new/test_labels.pickle'.format(FOLDER_PATH), 'rb') as f:\n",
    "    test_labels = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Tl1Hek4FIp8C"
   },
   "outputs": [],
   "source": [
    "# train_input_ids = train_input_ids[:400, :]\n",
    "# train_attention_masks = train_attention_masks[:400, :]\n",
    "# train_labels = train_labels[:400]\n",
    "\n",
    "# val_input_ids = val_input_ids[:400, :]\n",
    "# val_attention_masks = val_attention_masks[:400, :]\n",
    "# val_labels = val_labels[:400]\n",
    "\n",
    "# test_input_ids = test_input_ids[:400, :]\n",
    "# test_attention_masks = test_attention_masks[:400, :]\n",
    "# test_labels = test_labels[:400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OT26fugnIS-r"
   },
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(train_input_ids, train_attention_masks, train_labels)\n",
    "val_dataset = TensorDataset(val_input_ids, val_attention_masks, val_labels)\n",
    "test_dataset = TensorDataset(test_input_ids, test_attention_masks, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lj24EeA5tse9"
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "            train_dataset,\n",
    "            sampler=RandomSampler(train_dataset),\n",
    "            batch_size=batch_size,\n",
    "            drop_last=True)\n",
    "validation_dataloader = DataLoader(\n",
    "            val_dataset,\n",
    "            sampler = SequentialSampler(val_dataset),\n",
    "            batch_size = batch_size,\n",
    "            drop_last=True)\n",
    "test_dataloader = DataLoader(\n",
    "            test_dataset,\n",
    "            sampler = SequentialSampler(test_dataset),\n",
    "            batch_size = batch_size,\n",
    "            drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "c0e686f5f4eb4641b7a466d9d993d417",
      "05791eff4b74487f995a6cd51a8ce486",
      "071b93d88c17473aad8b3fcdb7801c41",
      "e0cbaa0fe4884257a6863fb934c9cdee",
      "ab5762e0ac4d4994a96012f5db4aea0a",
      "60b820e8f550425f95796cd2f0ecca3b",
      "32cd25fcbe1941cf9674d49f66fa837c",
      "abf2d3c4c5c944e3ae83ff0cba9f4b44",
      "0b4af6ff48bb4e7caf64e0e802ddadad",
      "8a8dd96b7fb04e14bf030320b4e21194",
      "2c10bd5bbadb4042b9a83388e7d55fff"
     ]
    },
    "executionInfo": {
     "elapsed": 14972,
     "status": "ok",
     "timestamp": 1654523976288,
     "user": {
      "displayName": "Никита Орлов",
      "userId": "17221654573895787003"
     },
     "user_tz": -180
    },
    "id": "UjPFUZAVvsjz",
    "outputId": "02f930ee-1c67-4517-9478-36d31d37cdb5"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0e686f5f4eb4641b7a466d9d993d417",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/681M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at DeepPavlov/rubert-base-cased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at DeepPavlov/rubert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    'DeepPavlov/rubert-base-cased', \n",
    "    num_labels = 2, \n",
    "    output_attentions = False,\n",
    "    output_hidden_states = False)\n",
    "\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 26,
     "status": "ok",
     "timestamp": 1654523976289,
     "user": {
      "displayName": "Никита Орлов",
      "userId": "17221654573895787003"
     },
     "user_tz": -180
    },
    "id": "HVQuulBQvsns",
    "outputId": "fe813f84-4d21-4786-d80a-8aa75be9971b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The BERT model has 201 different named parameters.\n",
      "\n",
      "==== Embedding Layer ====\n",
      "\n",
      "bert.embeddings.word_embeddings.weight                  (119547, 768)\n",
      "bert.embeddings.position_embeddings.weight                (512, 768)\n",
      "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
      "bert.embeddings.LayerNorm.weight                              (768,)\n",
      "bert.embeddings.LayerNorm.bias                                (768,)\n",
      "\n",
      "==== First Transformer ====\n",
      "\n",
      "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
      "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
      "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
      "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
      "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
      "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
      "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
      "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
      "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
      "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
      "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
      "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
      "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
      "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
      "\n",
      "==== Output Layer ====\n",
      "\n",
      "bert.pooler.dense.weight                                  (768, 768)\n",
      "bert.pooler.dense.bias                                        (768,)\n",
      "classifier.weight                                           (2, 768)\n",
      "classifier.bias                                                 (2,)\n"
     ]
    }
   ],
   "source": [
    "params = list(model.named_parameters())\n",
    "\n",
    "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
    "\n",
    "print('==== Embedding Layer ====\\n')\n",
    "\n",
    "for p in params[0:5]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "print('\\n==== First Transformer ====\\n')\n",
    "\n",
    "for p in params[5:21]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "print('\\n==== Output Layer ====\\n')\n",
    "\n",
    "for p in params[-4:]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1654523976289,
     "user": {
      "displayName": "Никита Орлов",
      "userId": "17221654573895787003"
     },
     "user_tz": -180
    },
    "id": "M2IkM3M-vsww",
    "outputId": "02880cbe-4179-4cd8-8233-cc17742bb5ca"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 2e-5,\n",
    "                  eps = 1e-8)\n",
    "epochs = 2\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer, \n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3prUW8-_NSDU"
   },
   "outputs": [],
   "source": [
    "CHECKPOINTS_PATH = '{}bert_new/checkpoints/'.format(FOLDER_PATH)\n",
    "MODEL_PATH = '{}bert_new/model/'.format(FOLDER_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 309818,
     "status": "ok",
     "timestamp": 1654547763333,
     "user": {
      "displayName": "Никита Орлов",
      "userId": "17221654573895787003"
     },
     "user_tz": -180
    },
    "id": "Bkc0RTn5C0eB",
    "outputId": "40af4159-5d9a-42e1-ee11-74417002409f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 2 ========\n",
      "Training...\n",
      "  Batch    40  of  27,688.    Elapsed: 0:00:33.\n",
      "  Batch    80  of  27,688.    Elapsed: 0:01:05.\n",
      "  Batch   120  of  27,688.    Elapsed: 0:01:37.\n",
      "  Batch   160  of  27,688.    Elapsed: 0:02:09.\n",
      "  Batch   200  of  27,688.    Elapsed: 0:02:42.\n",
      "  Batch   240  of  27,688.    Elapsed: 0:03:14.\n",
      "  Batch   280  of  27,688.    Elapsed: 0:03:46.\n",
      "  Batch   320  of  27,688.    Elapsed: 0:04:19.\n",
      "  Batch   360  of  27,688.    Elapsed: 0:04:51.\n",
      "  Batch   400  of  27,688.    Elapsed: 0:05:23.\n",
      "  Batch   440  of  27,688.    Elapsed: 0:05:55.\n",
      "  Batch   480  of  27,688.    Elapsed: 0:06:28.\n",
      "  Batch   520  of  27,688.    Elapsed: 0:07:35.\n",
      "  Batch   560  of  27,688.    Elapsed: 0:08:08.\n",
      "  Batch   600  of  27,688.    Elapsed: 0:08:40.\n",
      "  Batch   640  of  27,688.    Elapsed: 0:09:12.\n",
      "  Batch   680  of  27,688.    Elapsed: 0:09:45.\n",
      "  Batch   720  of  27,688.    Elapsed: 0:10:17.\n",
      "  Batch   760  of  27,688.    Elapsed: 0:10:49.\n",
      "  Batch   800  of  27,688.    Elapsed: 0:11:22.\n",
      "  Batch   840  of  27,688.    Elapsed: 0:11:54.\n",
      "  Batch   880  of  27,688.    Elapsed: 0:12:26.\n",
      "  Batch   920  of  27,688.    Elapsed: 0:12:58.\n",
      "  Batch   960  of  27,688.    Elapsed: 0:13:31.\n",
      "  Batch 1,000  of  27,688.    Elapsed: 0:14:03.\n",
      "  Batch 1,040  of  27,688.    Elapsed: 0:14:44.\n",
      "  Batch 1,080  of  27,688.    Elapsed: 0:15:16.\n",
      "  Batch 1,120  of  27,688.    Elapsed: 0:15:49.\n",
      "  Batch 1,160  of  27,688.    Elapsed: 0:16:21.\n",
      "  Batch 1,200  of  27,688.    Elapsed: 0:16:53.\n",
      "  Batch 1,240  of  27,688.    Elapsed: 0:17:26.\n",
      "  Batch 1,280  of  27,688.    Elapsed: 0:17:58.\n",
      "  Batch 1,320  of  27,688.    Elapsed: 0:18:30.\n",
      "  Batch 1,360  of  27,688.    Elapsed: 0:19:02.\n",
      "  Batch 1,400  of  27,688.    Elapsed: 0:19:35.\n",
      "  Batch 1,440  of  27,688.    Elapsed: 0:20:07.\n",
      "  Batch 1,480  of  27,688.    Elapsed: 0:20:39.\n",
      "  Batch 1,520  of  27,688.    Elapsed: 0:21:21.\n",
      "  Batch 1,560  of  27,688.    Elapsed: 0:21:53.\n",
      "  Batch 1,600  of  27,688.    Elapsed: 0:22:26.\n",
      "  Batch 1,640  of  27,688.    Elapsed: 0:22:58.\n",
      "  Batch 1,680  of  27,688.    Elapsed: 0:23:30.\n",
      "  Batch 1,720  of  27,688.    Elapsed: 0:24:02.\n",
      "  Batch 1,760  of  27,688.    Elapsed: 0:24:35.\n",
      "  Batch 1,800  of  27,688.    Elapsed: 0:25:07.\n",
      "  Batch 1,840  of  27,688.    Elapsed: 0:25:39.\n",
      "  Batch 1,880  of  27,688.    Elapsed: 0:26:11.\n",
      "  Batch 1,920  of  27,688.    Elapsed: 0:26:44.\n",
      "  Batch 1,960  of  27,688.    Elapsed: 0:27:16.\n",
      "  Batch 2,000  of  27,688.    Elapsed: 0:27:48.\n",
      "  Batch 2,040  of  27,688.    Elapsed: 0:28:29.\n",
      "  Batch 2,080  of  27,688.    Elapsed: 0:29:01.\n",
      "  Batch 2,120  of  27,688.    Elapsed: 0:29:34.\n",
      "  Batch 2,160  of  27,688.    Elapsed: 0:30:06.\n",
      "  Batch 2,200  of  27,688.    Elapsed: 0:30:38.\n",
      "  Batch 2,240  of  27,688.    Elapsed: 0:31:10.\n",
      "  Batch 2,280  of  27,688.    Elapsed: 0:31:43.\n",
      "  Batch 2,320  of  27,688.    Elapsed: 0:32:15.\n",
      "  Batch 2,360  of  27,688.    Elapsed: 0:32:47.\n",
      "  Batch 2,400  of  27,688.    Elapsed: 0:33:20.\n",
      "  Batch 2,440  of  27,688.    Elapsed: 0:33:52.\n",
      "  Batch 2,480  of  27,688.    Elapsed: 0:34:24.\n",
      "  Batch 2,520  of  27,688.    Elapsed: 0:35:06.\n",
      "  Batch 2,560  of  27,688.    Elapsed: 0:35:38.\n",
      "  Batch 2,600  of  27,688.    Elapsed: 0:36:10.\n",
      "  Batch 2,640  of  27,688.    Elapsed: 0:36:43.\n",
      "  Batch 2,680  of  27,688.    Elapsed: 0:37:15.\n",
      "  Batch 2,720  of  27,688.    Elapsed: 0:37:47.\n",
      "  Batch 2,760  of  27,688.    Elapsed: 0:38:20.\n",
      "  Batch 2,800  of  27,688.    Elapsed: 0:38:52.\n",
      "  Batch 2,840  of  27,688.    Elapsed: 0:39:24.\n",
      "  Batch 2,880  of  27,688.    Elapsed: 0:39:57.\n",
      "  Batch 2,920  of  27,688.    Elapsed: 0:40:29.\n",
      "  Batch 2,960  of  27,688.    Elapsed: 0:41:01.\n",
      "  Batch 3,000  of  27,688.    Elapsed: 0:41:33.\n",
      "  Batch 3,040  of  27,688.    Elapsed: 0:42:14.\n",
      "  Batch 3,080  of  27,688.    Elapsed: 0:42:47.\n",
      "  Batch 3,120  of  27,688.    Elapsed: 0:43:19.\n",
      "  Batch 3,160  of  27,688.    Elapsed: 0:43:51.\n",
      "  Batch 3,200  of  27,688.    Elapsed: 0:44:24.\n",
      "  Batch 3,240  of  27,688.    Elapsed: 0:44:56.\n",
      "  Batch 3,280  of  27,688.    Elapsed: 0:45:28.\n",
      "  Batch 3,320  of  27,688.    Elapsed: 0:46:01.\n",
      "  Batch 3,360  of  27,688.    Elapsed: 0:46:33.\n",
      "  Batch 3,400  of  27,688.    Elapsed: 0:47:05.\n",
      "  Batch 3,440  of  27,688.    Elapsed: 0:47:37.\n",
      "  Batch 3,480  of  27,688.    Elapsed: 0:48:10.\n",
      "  Batch 3,520  of  27,688.    Elapsed: 0:48:51.\n",
      "  Batch 3,560  of  27,688.    Elapsed: 0:49:23.\n",
      "  Batch 3,600  of  27,688.    Elapsed: 0:49:56.\n",
      "  Batch 3,640  of  27,688.    Elapsed: 0:50:28.\n",
      "  Batch 3,680  of  27,688.    Elapsed: 0:51:00.\n",
      "  Batch 3,720  of  27,688.    Elapsed: 0:51:33.\n",
      "  Batch 3,760  of  27,688.    Elapsed: 0:52:05.\n",
      "  Batch 3,800  of  27,688.    Elapsed: 0:52:37.\n",
      "  Batch 3,840  of  27,688.    Elapsed: 0:53:09.\n",
      "  Batch 3,880  of  27,688.    Elapsed: 0:53:42.\n",
      "  Batch 3,920  of  27,688.    Elapsed: 0:54:14.\n",
      "  Batch 3,960  of  27,688.    Elapsed: 0:54:46.\n",
      "  Batch 4,000  of  27,688.    Elapsed: 0:55:19.\n",
      "  Batch 4,040  of  27,688.    Elapsed: 0:56:00.\n",
      "  Batch 4,080  of  27,688.    Elapsed: 0:56:32.\n",
      "  Batch 4,120  of  27,688.    Elapsed: 0:57:04.\n",
      "  Batch 4,160  of  27,688.    Elapsed: 0:57:37.\n",
      "  Batch 4,200  of  27,688.    Elapsed: 0:58:09.\n",
      "  Batch 4,240  of  27,688.    Elapsed: 0:58:41.\n",
      "  Batch 4,280  of  27,688.    Elapsed: 0:59:14.\n",
      "  Batch 4,320  of  27,688.    Elapsed: 0:59:46.\n",
      "  Batch 4,360  of  27,688.    Elapsed: 1:00:18.\n",
      "  Batch 4,400  of  27,688.    Elapsed: 1:00:50.\n",
      "  Batch 4,440  of  27,688.    Elapsed: 1:01:23.\n",
      "  Batch 4,480  of  27,688.    Elapsed: 1:01:55.\n",
      "  Batch 4,520  of  27,688.    Elapsed: 1:02:37.\n",
      "  Batch 4,560  of  27,688.    Elapsed: 1:03:09.\n",
      "  Batch 4,600  of  27,688.    Elapsed: 1:03:41.\n",
      "  Batch 4,640  of  27,688.    Elapsed: 1:04:13.\n",
      "  Batch 4,680  of  27,688.    Elapsed: 1:04:46.\n",
      "  Batch 4,720  of  27,688.    Elapsed: 1:05:18.\n",
      "  Batch 4,760  of  27,688.    Elapsed: 1:05:50.\n",
      "  Batch 4,800  of  27,688.    Elapsed: 1:06:23.\n",
      "  Batch 4,840  of  27,688.    Elapsed: 1:06:55.\n",
      "  Batch 4,880  of  27,688.    Elapsed: 1:07:27.\n",
      "  Batch 4,920  of  27,688.    Elapsed: 1:07:59.\n",
      "  Batch 4,960  of  27,688.    Elapsed: 1:08:32.\n",
      "  Batch 5,000  of  27,688.    Elapsed: 1:09:04.\n",
      "  Batch 5,040  of  27,688.    Elapsed: 1:09:45.\n",
      "  Batch 5,080  of  27,688.    Elapsed: 1:10:18.\n",
      "  Batch 5,120  of  27,688.    Elapsed: 1:10:50.\n",
      "  Batch 5,160  of  27,688.    Elapsed: 1:11:22.\n",
      "  Batch 5,200  of  27,688.    Elapsed: 1:11:55.\n",
      "  Batch 5,240  of  27,688.    Elapsed: 1:12:27.\n",
      "  Batch 5,280  of  27,688.    Elapsed: 1:12:59.\n",
      "  Batch 5,320  of  27,688.    Elapsed: 1:13:31.\n",
      "  Batch 5,360  of  27,688.    Elapsed: 1:14:04.\n",
      "  Batch 5,400  of  27,688.    Elapsed: 1:14:36.\n",
      "  Batch 5,440  of  27,688.    Elapsed: 1:15:08.\n",
      "  Batch 5,480  of  27,688.    Elapsed: 1:15:41.\n",
      "  Batch 5,520  of  27,688.    Elapsed: 1:16:22.\n",
      "  Batch 5,560  of  27,688.    Elapsed: 1:16:54.\n",
      "  Batch 5,600  of  27,688.    Elapsed: 1:17:26.\n",
      "  Batch 5,640  of  27,688.    Elapsed: 1:17:59.\n",
      "  Batch 5,680  of  27,688.    Elapsed: 1:18:31.\n",
      "  Batch 5,720  of  27,688.    Elapsed: 1:19:03.\n",
      "  Batch 5,760  of  27,688.    Elapsed: 1:19:35.\n",
      "  Batch 5,800  of  27,688.    Elapsed: 1:20:08.\n",
      "  Batch 5,840  of  27,688.    Elapsed: 1:20:40.\n",
      "  Batch 5,880  of  27,688.    Elapsed: 1:21:12.\n",
      "  Batch 5,920  of  27,688.    Elapsed: 1:21:45.\n",
      "  Batch 5,960  of  27,688.    Elapsed: 1:22:17.\n",
      "  Batch 6,000  of  27,688.    Elapsed: 1:22:49.\n",
      "  Batch 6,040  of  27,688.    Elapsed: 1:23:31.\n",
      "  Batch 6,080  of  27,688.    Elapsed: 1:24:03.\n",
      "  Batch 6,120  of  27,688.    Elapsed: 1:24:36.\n",
      "  Batch 6,160  of  27,688.    Elapsed: 1:25:08.\n",
      "  Batch 6,200  of  27,688.    Elapsed: 1:25:40.\n",
      "  Batch 6,240  of  27,688.    Elapsed: 1:26:13.\n",
      "  Batch 6,280  of  27,688.    Elapsed: 1:26:45.\n",
      "  Batch 6,320  of  27,688.    Elapsed: 1:27:17.\n",
      "  Batch 6,360  of  27,688.    Elapsed: 1:27:50.\n",
      "  Batch 6,400  of  27,688.    Elapsed: 1:28:22.\n",
      "  Batch 6,440  of  27,688.    Elapsed: 1:28:54.\n",
      "  Batch 6,480  of  27,688.    Elapsed: 1:29:27.\n",
      "  Batch 6,520  of  27,688.    Elapsed: 1:30:08.\n",
      "  Batch 6,560  of  27,688.    Elapsed: 1:30:41.\n",
      "  Batch 6,600  of  27,688.    Elapsed: 1:31:13.\n",
      "  Batch 6,640  of  27,688.    Elapsed: 1:31:45.\n",
      "  Batch 6,680  of  27,688.    Elapsed: 1:32:18.\n",
      "  Batch 6,720  of  27,688.    Elapsed: 1:32:50.\n",
      "  Batch 6,760  of  27,688.    Elapsed: 1:33:22.\n",
      "  Batch 6,800  of  27,688.    Elapsed: 1:33:55.\n",
      "  Batch 6,840  of  27,688.    Elapsed: 1:34:27.\n",
      "  Batch 6,880  of  27,688.    Elapsed: 1:34:59.\n",
      "  Batch 6,920  of  27,688.    Elapsed: 1:35:32.\n",
      "  Batch 6,960  of  27,688.    Elapsed: 1:36:04.\n",
      "  Batch 7,000  of  27,688.    Elapsed: 1:36:36.\n",
      "  Batch 7,040  of  27,688.    Elapsed: 1:37:17.\n",
      "  Batch 7,080  of  27,688.    Elapsed: 1:37:50.\n",
      "  Batch 7,120  of  27,688.    Elapsed: 1:38:22.\n",
      "  Batch 7,160  of  27,688.    Elapsed: 1:38:54.\n",
      "  Batch 7,200  of  27,688.    Elapsed: 1:39:27.\n",
      "  Batch 7,240  of  27,688.    Elapsed: 1:39:59.\n",
      "  Batch 7,280  of  27,688.    Elapsed: 1:40:31.\n",
      "  Batch 7,320  of  27,688.    Elapsed: 1:41:04.\n",
      "  Batch 7,360  of  27,688.    Elapsed: 1:41:36.\n",
      "  Batch 7,400  of  27,688.    Elapsed: 1:42:08.\n",
      "  Batch 7,440  of  27,688.    Elapsed: 1:42:41.\n",
      "  Batch 7,480  of  27,688.    Elapsed: 1:43:13.\n",
      "  Batch 7,520  of  27,688.    Elapsed: 1:43:54.\n",
      "  Batch 7,560  of  27,688.    Elapsed: 1:44:26.\n",
      "  Batch 7,600  of  27,688.    Elapsed: 1:44:59.\n",
      "  Batch 7,640  of  27,688.    Elapsed: 1:45:31.\n",
      "  Batch 7,680  of  27,688.    Elapsed: 1:46:03.\n",
      "  Batch 7,720  of  27,688.    Elapsed: 1:46:36.\n",
      "  Batch 7,760  of  27,688.    Elapsed: 1:47:08.\n",
      "  Batch 7,800  of  27,688.    Elapsed: 1:47:40.\n",
      "  Batch 7,840  of  27,688.    Elapsed: 1:48:13.\n",
      "  Batch 7,880  of  27,688.    Elapsed: 1:48:45.\n",
      "  Batch 7,920  of  27,688.    Elapsed: 1:49:17.\n",
      "  Batch 7,960  of  27,688.    Elapsed: 1:49:50.\n",
      "  Batch 8,000  of  27,688.    Elapsed: 1:50:22.\n",
      "  Batch 8,040  of  27,688.    Elapsed: 1:51:04.\n",
      "  Batch 8,080  of  27,688.    Elapsed: 1:51:36.\n",
      "  Batch 8,120  of  27,688.    Elapsed: 1:52:08.\n",
      "  Batch 8,160  of  27,688.    Elapsed: 1:52:41.\n",
      "  Batch 8,200  of  27,688.    Elapsed: 1:53:13.\n",
      "  Batch 8,240  of  27,688.    Elapsed: 1:53:45.\n",
      "  Batch 8,280  of  27,688.    Elapsed: 1:54:18.\n",
      "  Batch 8,320  of  27,688.    Elapsed: 1:54:50.\n",
      "  Batch 8,360  of  27,688.    Elapsed: 1:55:22.\n",
      "  Batch 8,400  of  27,688.    Elapsed: 1:55:55.\n",
      "  Batch 8,440  of  27,688.    Elapsed: 1:56:27.\n",
      "  Batch 8,480  of  27,688.    Elapsed: 1:57:00.\n",
      "  Batch 8,520  of  27,688.    Elapsed: 1:57:41.\n",
      "  Batch 8,560  of  27,688.    Elapsed: 1:58:13.\n",
      "  Batch 8,600  of  27,688.    Elapsed: 1:58:45.\n",
      "  Batch 8,640  of  27,688.    Elapsed: 1:59:18.\n",
      "  Batch 8,680  of  27,688.    Elapsed: 1:59:50.\n",
      "  Batch 8,720  of  27,688.    Elapsed: 2:00:22.\n",
      "  Batch 8,760  of  27,688.    Elapsed: 2:00:55.\n",
      "  Batch 8,800  of  27,688.    Elapsed: 2:01:27.\n",
      "  Batch 8,840  of  27,688.    Elapsed: 2:01:59.\n",
      "  Batch 8,880  of  27,688.    Elapsed: 2:02:32.\n",
      "  Batch 8,920  of  27,688.    Elapsed: 2:03:04.\n",
      "  Batch 8,960  of  27,688.    Elapsed: 2:03:36.\n",
      "  Batch 9,000  of  27,688.    Elapsed: 2:04:09.\n",
      "  Batch 9,040  of  27,688.    Elapsed: 2:04:50.\n",
      "  Batch 9,080  of  27,688.    Elapsed: 2:05:22.\n",
      "  Batch 9,120  of  27,688.    Elapsed: 2:05:55.\n",
      "  Batch 9,160  of  27,688.    Elapsed: 2:06:27.\n",
      "  Batch 9,200  of  27,688.    Elapsed: 2:06:59.\n",
      "  Batch 9,240  of  27,688.    Elapsed: 2:07:32.\n",
      "  Batch 9,280  of  27,688.    Elapsed: 2:08:04.\n",
      "  Batch 9,320  of  27,688.    Elapsed: 2:08:36.\n",
      "  Batch 9,360  of  27,688.    Elapsed: 2:09:09.\n",
      "  Batch 9,400  of  27,688.    Elapsed: 2:09:41.\n",
      "  Batch 9,440  of  27,688.    Elapsed: 2:10:14.\n",
      "  Batch 9,480  of  27,688.    Elapsed: 2:10:46.\n",
      "  Batch 9,520  of  27,688.    Elapsed: 2:11:27.\n",
      "  Batch 9,560  of  27,688.    Elapsed: 2:11:59.\n",
      "  Batch 9,600  of  27,688.    Elapsed: 2:12:32.\n",
      "  Batch 9,640  of  27,688.    Elapsed: 2:13:04.\n",
      "  Batch 9,680  of  27,688.    Elapsed: 2:13:37.\n",
      "  Batch 9,720  of  27,688.    Elapsed: 2:14:09.\n",
      "  Batch 9,760  of  27,688.    Elapsed: 2:14:41.\n",
      "  Batch 9,800  of  27,688.    Elapsed: 2:15:14.\n",
      "  Batch 9,840  of  27,688.    Elapsed: 2:15:46.\n",
      "  Batch 9,880  of  27,688.    Elapsed: 2:16:19.\n",
      "  Batch 9,920  of  27,688.    Elapsed: 2:16:51.\n",
      "  Batch 9,960  of  27,688.    Elapsed: 2:17:23.\n",
      "  Batch 10,000  of  27,688.    Elapsed: 2:17:56.\n",
      "  Batch 10,040  of  27,688.    Elapsed: 2:18:37.\n",
      "  Batch 10,080  of  27,688.    Elapsed: 2:19:10.\n",
      "  Batch 10,120  of  27,688.    Elapsed: 2:19:42.\n",
      "  Batch 10,160  of  27,688.    Elapsed: 2:20:14.\n",
      "  Batch 10,200  of  27,688.    Elapsed: 2:20:47.\n",
      "  Batch 10,240  of  27,688.    Elapsed: 2:21:19.\n",
      "  Batch 10,280  of  27,688.    Elapsed: 2:21:52.\n",
      "  Batch 10,320  of  27,688.    Elapsed: 2:22:24.\n",
      "  Batch 10,360  of  27,688.    Elapsed: 2:22:56.\n",
      "  Batch 10,400  of  27,688.    Elapsed: 2:23:29.\n",
      "  Batch 10,440  of  27,688.    Elapsed: 2:24:01.\n",
      "  Batch 10,480  of  27,688.    Elapsed: 2:24:34.\n",
      "  Batch 10,520  of  27,688.    Elapsed: 2:25:15.\n",
      "  Batch 10,560  of  27,688.    Elapsed: 2:25:47.\n",
      "  Batch 10,600  of  27,688.    Elapsed: 2:26:19.\n",
      "  Batch 10,640  of  27,688.    Elapsed: 2:26:52.\n",
      "  Batch 10,680  of  27,688.    Elapsed: 2:27:24.\n",
      "  Batch 10,720  of  27,688.    Elapsed: 2:27:57.\n",
      "  Batch 10,760  of  27,688.    Elapsed: 2:28:29.\n",
      "  Batch 10,800  of  27,688.    Elapsed: 2:29:01.\n",
      "  Batch 10,840  of  27,688.    Elapsed: 2:29:34.\n",
      "  Batch 10,880  of  27,688.    Elapsed: 2:30:06.\n",
      "  Batch 10,920  of  27,688.    Elapsed: 2:30:39.\n",
      "  Batch 10,960  of  27,688.    Elapsed: 2:31:11.\n",
      "  Batch 11,000  of  27,688.    Elapsed: 2:31:43.\n",
      "  Batch 11,040  of  27,688.    Elapsed: 2:32:25.\n",
      "  Batch 11,080  of  27,688.    Elapsed: 2:32:57.\n",
      "  Batch 11,120  of  27,688.    Elapsed: 2:33:30.\n",
      "  Batch 11,160  of  27,688.    Elapsed: 2:34:02.\n",
      "  Batch 11,200  of  27,688.    Elapsed: 2:34:35.\n",
      "  Batch 11,240  of  27,688.    Elapsed: 2:35:07.\n",
      "  Batch 11,280  of  27,688.    Elapsed: 2:35:39.\n",
      "  Batch 11,320  of  27,688.    Elapsed: 2:36:12.\n",
      "  Batch 11,360  of  27,688.    Elapsed: 2:36:44.\n",
      "  Batch 11,400  of  27,688.    Elapsed: 2:37:16.\n",
      "  Batch 11,440  of  27,688.    Elapsed: 2:37:49.\n",
      "  Batch 11,480  of  27,688.    Elapsed: 2:38:21.\n",
      "  Batch 11,520  of  27,688.    Elapsed: 2:39:02.\n",
      "  Batch 11,560  of  27,688.    Elapsed: 2:39:35.\n",
      "  Batch 11,600  of  27,688.    Elapsed: 2:40:07.\n",
      "  Batch 11,640  of  27,688.    Elapsed: 2:40:39.\n",
      "  Batch 11,680  of  27,688.    Elapsed: 2:41:12.\n",
      "  Batch 11,720  of  27,688.    Elapsed: 2:41:44.\n",
      "  Batch 11,760  of  27,688.    Elapsed: 2:42:16.\n",
      "  Batch 11,800  of  27,688.    Elapsed: 2:42:49.\n",
      "  Batch 11,840  of  27,688.    Elapsed: 2:43:21.\n",
      "  Batch 11,880  of  27,688.    Elapsed: 2:43:54.\n",
      "  Batch 11,920  of  27,688.    Elapsed: 2:44:26.\n",
      "  Batch 11,960  of  27,688.    Elapsed: 2:44:58.\n",
      "  Batch 12,000  of  27,688.    Elapsed: 2:45:31.\n",
      "  Batch 12,040  of  27,688.    Elapsed: 2:46:12.\n",
      "  Batch 12,080  of  27,688.    Elapsed: 2:46:44.\n",
      "  Batch 12,120  of  27,688.    Elapsed: 2:47:16.\n",
      "  Batch 12,160  of  27,688.    Elapsed: 2:47:49.\n",
      "  Batch 12,200  of  27,688.    Elapsed: 2:48:21.\n",
      "  Batch 12,240  of  27,688.    Elapsed: 2:48:53.\n",
      "  Batch 12,280  of  27,688.    Elapsed: 2:49:26.\n",
      "  Batch 12,320  of  27,688.    Elapsed: 2:49:58.\n",
      "  Batch 12,360  of  27,688.    Elapsed: 2:50:30.\n",
      "  Batch 12,400  of  27,688.    Elapsed: 2:51:03.\n",
      "  Batch 12,440  of  27,688.    Elapsed: 2:51:35.\n",
      "  Batch 12,480  of  27,688.    Elapsed: 2:52:07.\n",
      "  Batch 12,520  of  27,688.    Elapsed: 2:52:49.\n",
      "  Batch 12,560  of  27,688.    Elapsed: 2:53:21.\n",
      "  Batch 12,600  of  27,688.    Elapsed: 2:53:53.\n",
      "  Batch 12,640  of  27,688.    Elapsed: 2:54:26.\n",
      "  Batch 12,680  of  27,688.    Elapsed: 2:54:58.\n",
      "  Batch 12,720  of  27,688.    Elapsed: 2:55:30.\n",
      "  Batch 12,760  of  27,688.    Elapsed: 2:56:03.\n",
      "  Batch 12,800  of  27,688.    Elapsed: 2:56:35.\n",
      "  Batch 12,840  of  27,688.    Elapsed: 2:57:07.\n",
      "  Batch 12,880  of  27,688.    Elapsed: 2:57:40.\n",
      "  Batch 12,920  of  27,688.    Elapsed: 2:58:12.\n",
      "  Batch 12,960  of  27,688.    Elapsed: 2:58:44.\n",
      "  Batch 13,000  of  27,688.    Elapsed: 2:59:17.\n",
      "  Batch 13,040  of  27,688.    Elapsed: 2:59:59.\n",
      "  Batch 13,080  of  27,688.    Elapsed: 3:00:31.\n",
      "  Batch 13,120  of  27,688.    Elapsed: 3:01:03.\n",
      "  Batch 13,160  of  27,688.    Elapsed: 3:01:36.\n",
      "  Batch 13,200  of  27,688.    Elapsed: 3:02:08.\n",
      "  Batch 13,240  of  27,688.    Elapsed: 3:02:41.\n",
      "  Batch 13,280  of  27,688.    Elapsed: 3:03:13.\n",
      "  Batch 13,320  of  27,688.    Elapsed: 3:03:45.\n",
      "  Batch 13,360  of  27,688.    Elapsed: 3:04:18.\n",
      "  Batch 13,400  of  27,688.    Elapsed: 3:04:50.\n",
      "  Batch 13,440  of  27,688.    Elapsed: 3:05:22.\n",
      "  Batch 13,480  of  27,688.    Elapsed: 3:05:55.\n",
      "  Batch 13,520  of  27,688.    Elapsed: 3:06:36.\n",
      "  Batch 13,560  of  27,688.    Elapsed: 3:07:09.\n",
      "  Batch 13,600  of  27,688.    Elapsed: 3:07:41.\n",
      "  Batch 13,640  of  27,688.    Elapsed: 3:08:13.\n",
      "  Batch 13,680  of  27,688.    Elapsed: 3:08:46.\n",
      "  Batch 13,720  of  27,688.    Elapsed: 3:09:18.\n",
      "  Batch 13,760  of  27,688.    Elapsed: 3:09:50.\n",
      "  Batch 13,800  of  27,688.    Elapsed: 3:10:23.\n",
      "  Batch 13,840  of  27,688.    Elapsed: 3:10:55.\n",
      "  Batch 13,880  of  27,688.    Elapsed: 3:11:27.\n",
      "  Batch 13,920  of  27,688.    Elapsed: 3:12:00.\n",
      "  Batch 13,960  of  27,688.    Elapsed: 3:12:32.\n",
      "  Batch 14,000  of  27,688.    Elapsed: 3:13:04.\n",
      "  Batch 14,040  of  27,688.    Elapsed: 3:13:45.\n",
      "  Batch 14,080  of  27,688.    Elapsed: 3:14:17.\n",
      "  Batch 14,120  of  27,688.    Elapsed: 3:14:50.\n",
      "  Batch 14,160  of  27,688.    Elapsed: 3:15:22.\n",
      "  Batch 14,200  of  27,688.    Elapsed: 3:15:54.\n",
      "  Batch 14,240  of  27,688.    Elapsed: 3:16:27.\n",
      "  Batch 14,280  of  27,688.    Elapsed: 3:16:59.\n",
      "  Batch 14,320  of  27,688.    Elapsed: 3:17:31.\n",
      "  Batch 14,360  of  27,688.    Elapsed: 3:18:04.\n",
      "  Batch 14,400  of  27,688.    Elapsed: 3:18:36.\n",
      "  Batch 14,440  of  27,688.    Elapsed: 3:19:09.\n",
      "  Batch 14,480  of  27,688.    Elapsed: 3:19:41.\n",
      "  Batch 14,520  of  27,688.    Elapsed: 3:20:22.\n",
      "  Batch 14,560  of  27,688.    Elapsed: 3:20:55.\n",
      "  Batch 14,600  of  27,688.    Elapsed: 3:21:27.\n",
      "  Batch 14,640  of  27,688.    Elapsed: 3:21:59.\n",
      "  Batch 14,680  of  27,688.    Elapsed: 3:22:32.\n",
      "  Batch 14,720  of  27,688.    Elapsed: 3:23:04.\n",
      "  Batch 14,760  of  27,688.    Elapsed: 3:23:36.\n",
      "  Batch 14,800  of  27,688.    Elapsed: 3:24:09.\n",
      "  Batch 14,840  of  27,688.    Elapsed: 3:24:41.\n",
      "  Batch 14,880  of  27,688.    Elapsed: 3:25:13.\n",
      "  Batch 14,920  of  27,688.    Elapsed: 3:25:46.\n",
      "  Batch 14,960  of  27,688.    Elapsed: 3:26:18.\n",
      "  Batch 15,000  of  27,688.    Elapsed: 3:26:51.\n",
      "  Batch 15,040  of  27,688.    Elapsed: 3:27:32.\n",
      "  Batch 15,080  of  27,688.    Elapsed: 3:28:05.\n",
      "  Batch 15,120  of  27,688.    Elapsed: 3:28:37.\n",
      "  Batch 15,160  of  27,688.    Elapsed: 3:29:09.\n",
      "  Batch 15,200  of  27,688.    Elapsed: 3:29:42.\n",
      "  Batch 15,240  of  27,688.    Elapsed: 3:30:14.\n",
      "  Batch 15,280  of  27,688.    Elapsed: 3:30:46.\n",
      "  Batch 15,320  of  27,688.    Elapsed: 3:31:19.\n",
      "  Batch 15,360  of  27,688.    Elapsed: 3:31:51.\n",
      "  Batch 15,400  of  27,688.    Elapsed: 3:32:23.\n",
      "  Batch 15,440  of  27,688.    Elapsed: 3:32:56.\n",
      "  Batch 15,480  of  27,688.    Elapsed: 3:33:28.\n",
      "  Batch 15,520  of  27,688.    Elapsed: 3:34:10.\n",
      "  Batch 15,560  of  27,688.    Elapsed: 3:34:42.\n",
      "  Batch 15,600  of  27,688.    Elapsed: 3:35:14.\n",
      "  Batch 15,640  of  27,688.    Elapsed: 3:35:47.\n",
      "  Batch 15,680  of  27,688.    Elapsed: 3:36:19.\n",
      "  Batch 15,720  of  27,688.    Elapsed: 3:36:51.\n",
      "  Batch 15,760  of  27,688.    Elapsed: 3:37:24.\n",
      "  Batch 15,800  of  27,688.    Elapsed: 3:37:56.\n",
      "  Batch 15,840  of  27,688.    Elapsed: 3:38:29.\n",
      "  Batch 15,880  of  27,688.    Elapsed: 3:39:01.\n",
      "  Batch 15,920  of  27,688.    Elapsed: 3:39:33.\n",
      "  Batch 15,960  of  27,688.    Elapsed: 3:40:06.\n",
      "  Batch 16,000  of  27,688.    Elapsed: 3:40:38.\n",
      "  Batch 16,040  of  27,688.    Elapsed: 3:41:19.\n",
      "  Batch 16,080  of  27,688.    Elapsed: 3:41:52.\n",
      "  Batch 16,120  of  27,688.    Elapsed: 3:42:24.\n",
      "  Batch 16,160  of  27,688.    Elapsed: 3:42:57.\n",
      "  Batch 16,200  of  27,688.    Elapsed: 3:43:29.\n",
      "  Batch 16,240  of  27,688.    Elapsed: 3:44:01.\n",
      "  Batch 16,280  of  27,688.    Elapsed: 3:44:34.\n",
      "  Batch 16,320  of  27,688.    Elapsed: 3:45:06.\n",
      "  Batch 16,360  of  27,688.    Elapsed: 3:45:38.\n",
      "  Batch 16,400  of  27,688.    Elapsed: 3:46:11.\n",
      "  Batch 16,440  of  27,688.    Elapsed: 3:46:43.\n",
      "  Batch 16,480  of  27,688.    Elapsed: 3:47:15.\n",
      "  Batch 16,520  of  27,688.    Elapsed: 3:47:57.\n",
      "  Batch 16,560  of  27,688.    Elapsed: 3:48:29.\n",
      "  Batch 16,600  of  27,688.    Elapsed: 3:49:02.\n",
      "  Batch 16,640  of  27,688.    Elapsed: 3:49:34.\n",
      "  Batch 16,680  of  27,688.    Elapsed: 3:50:06.\n",
      "  Batch 16,720  of  27,688.    Elapsed: 3:50:39.\n",
      "  Batch 16,760  of  27,688.    Elapsed: 3:51:11.\n",
      "  Batch 16,800  of  27,688.    Elapsed: 3:51:43.\n",
      "  Batch 16,840  of  27,688.    Elapsed: 3:52:16.\n",
      "  Batch 16,880  of  27,688.    Elapsed: 3:52:48.\n",
      "  Batch 16,920  of  27,688.    Elapsed: 3:53:21.\n",
      "  Batch 16,960  of  27,688.    Elapsed: 3:53:53.\n",
      "  Batch 17,000  of  27,688.    Elapsed: 3:54:25.\n",
      "  Batch 17,040  of  27,688.    Elapsed: 3:55:07.\n",
      "  Batch 17,080  of  27,688.    Elapsed: 3:55:39.\n",
      "  Batch 17,120  of  27,688.    Elapsed: 3:56:12.\n",
      "  Batch 17,160  of  27,688.    Elapsed: 3:56:44.\n",
      "  Batch 17,200  of  27,688.    Elapsed: 3:57:16.\n",
      "  Batch 17,240  of  27,688.    Elapsed: 3:57:49.\n",
      "  Batch 17,280  of  27,688.    Elapsed: 3:58:21.\n",
      "  Batch 17,320  of  27,688.    Elapsed: 3:58:54.\n",
      "  Batch 17,360  of  27,688.    Elapsed: 3:59:26.\n",
      "  Batch 17,400  of  27,688.    Elapsed: 3:59:58.\n",
      "  Batch 17,440  of  27,688.    Elapsed: 4:00:31.\n",
      "  Batch 17,480  of  27,688.    Elapsed: 4:01:03.\n",
      "  Batch 17,520  of  27,688.    Elapsed: 4:01:44.\n",
      "  Batch 17,560  of  27,688.    Elapsed: 4:02:16.\n",
      "  Batch 17,600  of  27,688.    Elapsed: 4:02:49.\n",
      "  Batch 17,640  of  27,688.    Elapsed: 4:03:21.\n",
      "  Batch 17,680  of  27,688.    Elapsed: 4:03:53.\n",
      "  Batch 17,720  of  27,688.    Elapsed: 4:04:26.\n",
      "  Batch 17,760  of  27,688.    Elapsed: 4:04:58.\n",
      "  Batch 17,800  of  27,688.    Elapsed: 4:05:31.\n",
      "  Batch 17,840  of  27,688.    Elapsed: 4:06:03.\n",
      "  Batch 17,880  of  27,688.    Elapsed: 4:06:35.\n",
      "  Batch 17,920  of  27,688.    Elapsed: 4:07:08.\n",
      "  Batch 17,960  of  27,688.    Elapsed: 4:07:40.\n",
      "  Batch 18,000  of  27,688.    Elapsed: 4:08:12.\n",
      "  Batch 18,040  of  27,688.    Elapsed: 4:08:53.\n",
      "  Batch 18,080  of  27,688.    Elapsed: 4:09:26.\n",
      "  Batch 18,120  of  27,688.    Elapsed: 4:09:58.\n",
      "  Batch 18,160  of  27,688.    Elapsed: 4:10:31.\n",
      "  Batch 18,200  of  27,688.    Elapsed: 4:11:03.\n",
      "  Batch 18,240  of  27,688.    Elapsed: 4:11:35.\n",
      "  Batch 18,280  of  27,688.    Elapsed: 4:12:08.\n",
      "  Batch 18,320  of  27,688.    Elapsed: 4:12:40.\n",
      "  Batch 18,360  of  27,688.    Elapsed: 4:13:12.\n",
      "  Batch 18,400  of  27,688.    Elapsed: 4:13:45.\n",
      "  Batch 18,440  of  27,688.    Elapsed: 4:14:17.\n",
      "  Batch 18,480  of  27,688.    Elapsed: 4:14:49.\n",
      "  Batch 18,520  of  27,688.    Elapsed: 4:15:31.\n",
      "  Batch 18,560  of  27,688.    Elapsed: 4:16:03.\n",
      "  Batch 18,600  of  27,688.    Elapsed: 4:16:36.\n",
      "  Batch 18,640  of  27,688.    Elapsed: 4:17:08.\n",
      "  Batch 18,680  of  27,688.    Elapsed: 4:17:40.\n",
      "  Batch 18,720  of  27,688.    Elapsed: 4:18:13.\n",
      "  Batch 18,760  of  27,688.    Elapsed: 4:18:45.\n",
      "  Batch 18,800  of  27,688.    Elapsed: 4:19:17.\n",
      "  Batch 18,840  of  27,688.    Elapsed: 4:19:50.\n",
      "  Batch 18,880  of  27,688.    Elapsed: 4:20:22.\n",
      "  Batch 18,920  of  27,688.    Elapsed: 4:20:54.\n",
      "  Batch 18,960  of  27,688.    Elapsed: 4:21:27.\n",
      "  Batch 19,000  of  27,688.    Elapsed: 4:21:59.\n",
      "  Batch 19,040  of  27,688.    Elapsed: 4:22:40.\n",
      "  Batch 19,080  of  27,688.    Elapsed: 4:23:13.\n",
      "  Batch 19,120  of  27,688.    Elapsed: 4:23:45.\n",
      "  Batch 19,160  of  27,688.    Elapsed: 4:24:17.\n",
      "  Batch 19,200  of  27,688.    Elapsed: 4:24:50.\n",
      "  Batch 19,240  of  27,688.    Elapsed: 4:25:22.\n",
      "  Batch 19,280  of  27,688.    Elapsed: 4:25:54.\n",
      "  Batch 19,320  of  27,688.    Elapsed: 4:26:27.\n",
      "  Batch 19,360  of  27,688.    Elapsed: 4:26:59.\n",
      "  Batch 19,400  of  27,688.    Elapsed: 4:27:31.\n",
      "  Batch 19,440  of  27,688.    Elapsed: 4:28:04.\n",
      "  Batch 19,480  of  27,688.    Elapsed: 4:28:36.\n",
      "  Batch 19,520  of  27,688.    Elapsed: 4:29:17.\n",
      "  Batch 19,560  of  27,688.    Elapsed: 4:29:50.\n",
      "  Batch 19,600  of  27,688.    Elapsed: 4:30:22.\n",
      "  Batch 19,640  of  27,688.    Elapsed: 4:30:55.\n",
      "  Batch 19,680  of  27,688.    Elapsed: 4:31:27.\n",
      "  Batch 19,720  of  27,688.    Elapsed: 4:31:59.\n",
      "  Batch 19,760  of  27,688.    Elapsed: 4:32:32.\n",
      "  Batch 19,800  of  27,688.    Elapsed: 4:33:04.\n",
      "  Batch 19,840  of  27,688.    Elapsed: 4:33:36.\n",
      "  Batch 19,880  of  27,688.    Elapsed: 4:34:09.\n",
      "  Batch 19,920  of  27,688.    Elapsed: 4:34:41.\n",
      "  Batch 19,960  of  27,688.    Elapsed: 4:35:13.\n",
      "  Batch 20,000  of  27,688.    Elapsed: 4:35:46.\n",
      "  Batch 20,040  of  27,688.    Elapsed: 4:36:27.\n",
      "  Batch 20,080  of  27,688.    Elapsed: 4:36:59.\n",
      "  Batch 20,120  of  27,688.    Elapsed: 4:37:32.\n",
      "  Batch 20,160  of  27,688.    Elapsed: 4:38:04.\n",
      "  Batch 20,200  of  27,688.    Elapsed: 4:38:36.\n",
      "  Batch 20,240  of  27,688.    Elapsed: 4:39:09.\n",
      "  Batch 20,280  of  27,688.    Elapsed: 4:39:41.\n",
      "  Batch 20,320  of  27,688.    Elapsed: 4:40:13.\n",
      "  Batch 20,360  of  27,688.    Elapsed: 4:40:46.\n",
      "  Batch 20,400  of  27,688.    Elapsed: 4:41:18.\n",
      "  Batch 20,440  of  27,688.    Elapsed: 4:41:51.\n",
      "  Batch 20,480  of  27,688.    Elapsed: 4:42:23.\n",
      "  Batch 20,520  of  27,688.    Elapsed: 4:43:04.\n",
      "  Batch 20,560  of  27,688.    Elapsed: 4:43:36.\n",
      "  Batch 20,600  of  27,688.    Elapsed: 4:44:09.\n",
      "  Batch 20,640  of  27,688.    Elapsed: 4:44:41.\n",
      "  Batch 20,680  of  27,688.    Elapsed: 4:45:13.\n",
      "  Batch 20,720  of  27,688.    Elapsed: 4:45:46.\n",
      "  Batch 20,760  of  27,688.    Elapsed: 4:46:18.\n",
      "  Batch 20,800  of  27,688.    Elapsed: 4:46:51.\n",
      "  Batch 20,840  of  27,688.    Elapsed: 4:47:23.\n",
      "  Batch 20,880  of  27,688.    Elapsed: 4:47:55.\n",
      "  Batch 20,920  of  27,688.    Elapsed: 4:48:28.\n",
      "  Batch 20,960  of  27,688.    Elapsed: 4:49:00.\n",
      "  Batch 21,000  of  27,688.    Elapsed: 4:49:32.\n",
      "  Batch 21,040  of  27,688.    Elapsed: 4:50:14.\n",
      "  Batch 21,080  of  27,688.    Elapsed: 4:50:46.\n",
      "  Batch 21,120  of  27,688.    Elapsed: 4:51:18.\n",
      "  Batch 21,160  of  27,688.    Elapsed: 4:51:51.\n",
      "  Batch 21,200  of  27,688.    Elapsed: 4:52:23.\n",
      "  Batch 21,240  of  27,688.    Elapsed: 4:52:55.\n",
      "  Batch 21,280  of  27,688.    Elapsed: 4:53:28.\n",
      "  Batch 21,320  of  27,688.    Elapsed: 4:54:00.\n",
      "  Batch 21,360  of  27,688.    Elapsed: 4:54:33.\n",
      "  Batch 21,400  of  27,688.    Elapsed: 4:55:05.\n",
      "  Batch 21,440  of  27,688.    Elapsed: 4:55:37.\n",
      "  Batch 21,480  of  27,688.    Elapsed: 4:56:10.\n",
      "  Batch 21,520  of  27,688.    Elapsed: 4:56:51.\n",
      "  Batch 21,560  of  27,688.    Elapsed: 4:57:23.\n",
      "  Batch 21,600  of  27,688.    Elapsed: 4:57:55.\n",
      "  Batch 21,640  of  27,688.    Elapsed: 4:58:28.\n",
      "  Batch 21,680  of  27,688.    Elapsed: 4:59:00.\n",
      "  Batch 21,720  of  27,688.    Elapsed: 4:59:33.\n",
      "  Batch 21,760  of  27,688.    Elapsed: 5:00:05.\n",
      "  Batch 21,800  of  27,688.    Elapsed: 5:00:37.\n",
      "  Batch 21,840  of  27,688.    Elapsed: 5:01:10.\n",
      "  Batch 21,880  of  27,688.    Elapsed: 5:01:42.\n",
      "  Batch 21,920  of  27,688.    Elapsed: 5:02:14.\n",
      "  Batch 21,960  of  27,688.    Elapsed: 5:02:47.\n",
      "  Batch 22,000  of  27,688.    Elapsed: 5:03:19.\n",
      "  Batch 22,040  of  27,688.    Elapsed: 5:04:00.\n",
      "  Batch 22,080  of  27,688.    Elapsed: 5:04:33.\n",
      "  Batch 22,120  of  27,688.    Elapsed: 5:05:05.\n",
      "  Batch 22,160  of  27,688.    Elapsed: 5:05:37.\n",
      "  Batch 22,200  of  27,688.    Elapsed: 5:06:10.\n",
      "  Batch 22,240  of  27,688.    Elapsed: 5:06:42.\n",
      "  Batch 22,280  of  27,688.    Elapsed: 5:07:14.\n",
      "  Batch 22,320  of  27,688.    Elapsed: 5:07:47.\n",
      "  Batch 22,360  of  27,688.    Elapsed: 5:08:19.\n",
      "  Batch 22,400  of  27,688.    Elapsed: 5:08:52.\n",
      "  Batch 22,440  of  27,688.    Elapsed: 5:09:24.\n",
      "  Batch 22,480  of  27,688.    Elapsed: 5:09:56.\n",
      "  Batch 22,520  of  27,688.    Elapsed: 5:10:38.\n",
      "  Batch 22,560  of  27,688.    Elapsed: 5:11:10.\n",
      "  Batch 22,600  of  27,688.    Elapsed: 5:11:42.\n",
      "  Batch 22,640  of  27,688.    Elapsed: 5:12:15.\n",
      "  Batch 22,680  of  27,688.    Elapsed: 5:12:47.\n",
      "  Batch 22,720  of  27,688.    Elapsed: 5:13:19.\n",
      "  Batch 22,760  of  27,688.    Elapsed: 5:13:52.\n",
      "  Batch 22,800  of  27,688.    Elapsed: 5:14:24.\n",
      "  Batch 22,840  of  27,688.    Elapsed: 5:14:57.\n",
      "  Batch 22,880  of  27,688.    Elapsed: 5:15:29.\n",
      "  Batch 22,920  of  27,688.    Elapsed: 5:16:01.\n",
      "  Batch 22,960  of  27,688.    Elapsed: 5:16:34.\n",
      "  Batch 23,000  of  27,688.    Elapsed: 5:17:06.\n",
      "  Batch 23,040  of  27,688.    Elapsed: 5:17:47.\n",
      "  Batch 23,080  of  27,688.    Elapsed: 5:18:19.\n",
      "  Batch 23,120  of  27,688.    Elapsed: 5:18:52.\n",
      "  Batch 23,160  of  27,688.    Elapsed: 5:19:24.\n",
      "  Batch 23,200  of  27,688.    Elapsed: 5:19:56.\n",
      "  Batch 23,240  of  27,688.    Elapsed: 5:20:29.\n",
      "  Batch 23,280  of  27,688.    Elapsed: 5:21:01.\n",
      "  Batch 23,320  of  27,688.    Elapsed: 5:21:34.\n",
      "  Batch 23,360  of  27,688.    Elapsed: 5:22:06.\n",
      "  Batch 23,400  of  27,688.    Elapsed: 5:22:38.\n",
      "  Batch 23,440  of  27,688.    Elapsed: 5:23:11.\n",
      "  Batch 23,480  of  27,688.    Elapsed: 5:23:43.\n",
      "  Batch 23,520  of  27,688.    Elapsed: 5:24:24.\n",
      "  Batch 23,560  of  27,688.    Elapsed: 5:24:57.\n",
      "  Batch 23,600  of  27,688.    Elapsed: 5:25:29.\n",
      "  Batch 23,640  of  27,688.    Elapsed: 5:26:01.\n",
      "  Batch 23,680  of  27,688.    Elapsed: 5:26:34.\n",
      "  Batch 23,720  of  27,688.    Elapsed: 5:27:06.\n",
      "  Batch 23,760  of  27,688.    Elapsed: 5:27:38.\n",
      "  Batch 23,800  of  27,688.    Elapsed: 5:28:11.\n",
      "  Batch 23,840  of  27,688.    Elapsed: 5:28:43.\n",
      "  Batch 23,880  of  27,688.    Elapsed: 5:29:16.\n",
      "  Batch 23,920  of  27,688.    Elapsed: 5:29:48.\n",
      "  Batch 23,960  of  27,688.    Elapsed: 5:30:20.\n",
      "  Batch 24,000  of  27,688.    Elapsed: 5:30:53.\n",
      "  Batch 24,040  of  27,688.    Elapsed: 5:31:34.\n",
      "  Batch 24,080  of  27,688.    Elapsed: 5:32:06.\n",
      "  Batch 24,120  of  27,688.    Elapsed: 5:32:39.\n",
      "  Batch 24,160  of  27,688.    Elapsed: 5:33:11.\n",
      "  Batch 24,200  of  27,688.    Elapsed: 5:33:43.\n",
      "  Batch 24,240  of  27,688.    Elapsed: 5:34:16.\n",
      "  Batch 24,280  of  27,688.    Elapsed: 5:34:48.\n",
      "  Batch 24,320  of  27,688.    Elapsed: 5:35:21.\n",
      "  Batch 24,360  of  27,688.    Elapsed: 5:35:53.\n",
      "  Batch 24,400  of  27,688.    Elapsed: 5:36:25.\n",
      "  Batch 24,440  of  27,688.    Elapsed: 5:36:58.\n",
      "  Batch 24,480  of  27,688.    Elapsed: 5:37:30.\n",
      "  Batch 24,520  of  27,688.    Elapsed: 5:38:11.\n",
      "  Batch 24,560  of  27,688.    Elapsed: 5:38:44.\n",
      "  Batch 24,600  of  27,688.    Elapsed: 5:39:16.\n",
      "  Batch 24,640  of  27,688.    Elapsed: 5:39:48.\n",
      "  Batch 24,680  of  27,688.    Elapsed: 5:40:21.\n",
      "  Batch 24,720  of  27,688.    Elapsed: 5:40:53.\n",
      "  Batch 24,760  of  27,688.    Elapsed: 5:41:25.\n",
      "  Batch 24,800  of  27,688.    Elapsed: 5:41:58.\n",
      "  Batch 24,840  of  27,688.    Elapsed: 5:42:30.\n",
      "  Batch 24,880  of  27,688.    Elapsed: 5:43:03.\n",
      "  Batch 24,920  of  27,688.    Elapsed: 5:43:35.\n",
      "  Batch 24,960  of  27,688.    Elapsed: 5:44:07.\n",
      "  Batch 25,000  of  27,688.    Elapsed: 5:44:40.\n",
      "  Batch 25,040  of  27,688.    Elapsed: 5:45:22.\n",
      "  Batch 25,080  of  27,688.    Elapsed: 5:45:54.\n",
      "  Batch 25,120  of  27,688.    Elapsed: 5:46:27.\n",
      "  Batch 25,160  of  27,688.    Elapsed: 5:46:59.\n",
      "  Batch 25,200  of  27,688.    Elapsed: 5:47:31.\n",
      "  Batch 25,240  of  27,688.    Elapsed: 5:48:04.\n",
      "  Batch 25,280  of  27,688.    Elapsed: 5:48:36.\n",
      "  Batch 25,320  of  27,688.    Elapsed: 5:49:08.\n",
      "  Batch 25,360  of  27,688.    Elapsed: 5:49:41.\n",
      "  Batch 25,400  of  27,688.    Elapsed: 5:50:13.\n",
      "  Batch 25,440  of  27,688.    Elapsed: 5:50:46.\n",
      "  Batch 25,480  of  27,688.    Elapsed: 5:51:18.\n",
      "  Batch 25,520  of  27,688.    Elapsed: 5:52:00.\n",
      "  Batch 25,560  of  27,688.    Elapsed: 5:52:32.\n",
      "  Batch 25,600  of  27,688.    Elapsed: 5:53:04.\n",
      "  Batch 25,640  of  27,688.    Elapsed: 5:53:37.\n",
      "  Batch 25,680  of  27,688.    Elapsed: 5:54:09.\n",
      "  Batch 25,720  of  27,688.    Elapsed: 5:54:42.\n",
      "  Batch 25,760  of  27,688.    Elapsed: 5:55:14.\n",
      "  Batch 25,800  of  27,688.    Elapsed: 5:55:46.\n",
      "  Batch 25,840  of  27,688.    Elapsed: 5:56:19.\n",
      "  Batch 25,880  of  27,688.    Elapsed: 5:56:51.\n",
      "  Batch 25,920  of  27,688.    Elapsed: 5:57:23.\n",
      "  Batch 25,960  of  27,688.    Elapsed: 5:57:56.\n",
      "  Batch 26,000  of  27,688.    Elapsed: 5:58:28.\n",
      "  Batch 26,040  of  27,688.    Elapsed: 5:59:09.\n",
      "  Batch 26,080  of  27,688.    Elapsed: 5:59:42.\n",
      "  Batch 26,120  of  27,688.    Elapsed: 6:00:14.\n",
      "  Batch 26,160  of  27,688.    Elapsed: 6:00:47.\n",
      "  Batch 26,200  of  27,688.    Elapsed: 6:01:19.\n",
      "  Batch 26,240  of  27,688.    Elapsed: 6:01:51.\n",
      "  Batch 26,280  of  27,688.    Elapsed: 6:02:24.\n",
      "  Batch 26,320  of  27,688.    Elapsed: 6:02:56.\n",
      "  Batch 26,360  of  27,688.    Elapsed: 6:03:28.\n",
      "  Batch 26,400  of  27,688.    Elapsed: 6:04:01.\n",
      "  Batch 26,440  of  27,688.    Elapsed: 6:04:33.\n",
      "  Batch 26,480  of  27,688.    Elapsed: 6:05:05.\n",
      "  Batch 26,520  of  27,688.    Elapsed: 6:05:47.\n",
      "  Batch 26,560  of  27,688.    Elapsed: 6:06:19.\n",
      "  Batch 26,600  of  27,688.    Elapsed: 6:06:52.\n",
      "  Batch 26,640  of  27,688.    Elapsed: 6:07:24.\n",
      "  Batch 26,680  of  27,688.    Elapsed: 6:07:56.\n",
      "  Batch 26,720  of  27,688.    Elapsed: 6:08:29.\n",
      "  Batch 26,760  of  27,688.    Elapsed: 6:09:01.\n",
      "  Batch 26,800  of  27,688.    Elapsed: 6:09:33.\n",
      "  Batch 26,840  of  27,688.    Elapsed: 6:10:06.\n",
      "  Batch 26,880  of  27,688.    Elapsed: 6:10:38.\n",
      "  Batch 26,920  of  27,688.    Elapsed: 6:11:11.\n",
      "  Batch 26,960  of  27,688.    Elapsed: 6:11:43.\n",
      "  Batch 27,000  of  27,688.    Elapsed: 6:12:15.\n",
      "  Batch 27,040  of  27,688.    Elapsed: 6:12:57.\n",
      "  Batch 27,080  of  27,688.    Elapsed: 6:13:29.\n",
      "  Batch 27,120  of  27,688.    Elapsed: 6:14:02.\n",
      "  Batch 27,160  of  27,688.    Elapsed: 6:14:34.\n",
      "  Batch 27,200  of  27,688.    Elapsed: 6:15:06.\n",
      "  Batch 27,240  of  27,688.    Elapsed: 6:15:39.\n",
      "  Batch 27,280  of  27,688.    Elapsed: 6:16:11.\n",
      "  Batch 27,320  of  27,688.    Elapsed: 6:16:43.\n",
      "  Batch 27,360  of  27,688.    Elapsed: 6:17:16.\n",
      "  Batch 27,400  of  27,688.    Elapsed: 6:17:48.\n",
      "  Batch 27,440  of  27,688.    Elapsed: 6:18:20.\n",
      "  Batch 27,480  of  27,688.    Elapsed: 6:18:53.\n",
      "  Batch 27,520  of  27,688.    Elapsed: 6:19:34.\n",
      "  Batch 27,560  of  27,688.    Elapsed: 6:20:06.\n",
      "  Batch 27,600  of  27,688.    Elapsed: 6:20:38.\n",
      "  Batch 27,640  of  27,688.    Elapsed: 6:21:11.\n",
      "  Batch 27,680  of  27,688.    Elapsed: 6:21:43.\n",
      "\n",
      "  Average training loss: 0.12\n",
      "  Training epcoh took: 6:21:50\n",
      "\n",
      "Running Validation...\n",
      "  ROC AUC: 0.99\n",
      "  Validation Loss: 0.10\n",
      "  Validation took: 0:13:17\n",
      "\n",
      "Training complete!\n",
      "Total training took 6:35:06 (h:mm:ss)\n"
     ]
    }
   ],
   "source": [
    "epoch = 0\n",
    "\n",
    "seed_val = 42\n",
    "\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "training_stats = []\n",
    "total_t0 = time.time()\n",
    "\n",
    "# ========================================\n",
    "#               Training\n",
    "# ========================================\n",
    "\n",
    "print(\"\")\n",
    "print('======== Epoch {:} / {:} ========'.format(epoch + 1, epochs))\n",
    "print('Training...')\n",
    "\n",
    "t0 = time.time()\n",
    "total_train_loss = 0\n",
    "\n",
    "model.train()\n",
    "\n",
    "for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "    if step % 40 == 0 and not step == 0:\n",
    "        elapsed = format_time(time.time() - t0)\n",
    "        print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(\n",
    "            step, len(train_dataloader), elapsed))\n",
    "\n",
    "    b_input_ids = batch[0].to(device)\n",
    "    b_input_mask = batch[1].to(device)\n",
    "    b_labels = batch[2].to(device)\n",
    "\n",
    "    model.zero_grad()        \n",
    "\n",
    "    loss, logits = model(\n",
    "        b_input_ids, \n",
    "        token_type_ids=None, \n",
    "        attention_mask=b_input_mask, \n",
    "        labels=b_labels\n",
    "        ).values()\n",
    "\n",
    "    total_train_loss += loss.item()\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "\n",
    "    if step % 500 == 0 and not step == 0:\n",
    "        torch.save(\n",
    "            {'epoch': epoch,\n",
    "             'model_state_dict': model.state_dict(),\n",
    "             'optimizer_state_dict': optimizer.state_dict(),\n",
    "             'loss': loss\n",
    "                }, \n",
    "            '{}checkpoint_epoch_1'.format(CHECKPOINTS_PATH)\n",
    "            )\n",
    "\n",
    "avg_train_loss = total_train_loss / len(train_dataloader)            \n",
    "training_time = format_time(time.time() - t0)\n",
    "\n",
    "print(\"\")\n",
    "print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "print(\"  Training epcoh took: {:}\".format(training_time))\n",
    "    \n",
    "# ========================================\n",
    "#               Validation\n",
    "# ========================================\n",
    "\n",
    "print(\"\")\n",
    "print(\"Running Validation...\")\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "model.eval()\n",
    "\n",
    "total_eval_roc_auc = 0\n",
    "total_eval_loss = 0\n",
    "nb_eval_steps = 0\n",
    "\n",
    "for batch in validation_dataloader:\n",
    "    b_input_ids = batch[0].to(device)\n",
    "    b_input_mask = batch[1].to(device)\n",
    "    b_labels = batch[2].to(device)\n",
    " \n",
    "    with torch.no_grad():        \n",
    "        (loss, logits) = model(\n",
    "            b_input_ids, \n",
    "            token_type_ids=None, \n",
    "            attention_mask=b_input_mask,\n",
    "            labels=b_labels\n",
    "            ).values()\n",
    "        \n",
    "    total_eval_loss += loss.item()\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "    total_eval_roc_auc += flat_roc_auc(logits, label_ids)\n",
    "    \n",
    "avg_val_roc_auc = total_eval_roc_auc / len(validation_dataloader)\n",
    "print(\"  ROC AUC: {0:.2f}\".format(avg_val_roc_auc))\n",
    "\n",
    "avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
    "validation_time = format_time(time.time() - t0)\n",
    "\n",
    "print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
    "print(\"  Validation took: {:}\".format(validation_time))\n",
    "\n",
    "training_stats.append(\n",
    "    {\n",
    "        'epoch': epoch + 1,\n",
    "        'Training Loss': avg_train_loss,\n",
    "        'Valid. Loss': avg_val_loss,\n",
    "        'Valid. Accur.': avg_val_roc_auc,\n",
    "        'Training Time': training_time,\n",
    "        'Validation Time': validation_time\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"\")\n",
    "print(\"Training complete!\")\n",
    "\n",
    "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time() - total_t0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UmPSGPB0wqyG"
   },
   "outputs": [],
   "source": [
    "# torch.save({\n",
    "#     'epoch': epoch,\n",
    "#     'model_state_dict': model.state_dict(),\n",
    "#     'optimizer_state_dict': optimizer.state_dict(),\n",
    "#     'loss': loss,\n",
    "#   }, '{}checkpoint_epoch_1'.format(CHECKPOINTS_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14268,
     "status": "ok",
     "timestamp": 1654547786275,
     "user": {
      "displayName": "Никита Орлов",
      "userId": "17221654573895787003"
     },
     "user_tz": -180
    },
    "id": "E2-dhFL-vcrm",
    "outputId": "72024439-39e6-459a-97f0-f4e28c6ca5b4"
   },
   "outputs": [],
   "source": [
    "# print(\"Saving model to %s\" % '{}epoch_1'.format(MODEL_PATH))\n",
    "\n",
    "# model_to_save = model.module if hasattr(model, 'module') else model\n",
    "# model_to_save.save_pretrained('{}epoch_1'.format(MODEL_PATH))\n",
    "# tokenizer.save_pretrained('{}epoch_1'.format(MODEL_PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zFzOC_rHO6Ej"
   },
   "source": [
    "# EPOCH 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11939876,
     "status": "ok",
     "timestamp": 1654578607986,
     "user": {
      "displayName": "Никита Орлов",
      "userId": "17221654573895787003"
     },
     "user_tz": -180
    },
    "id": "xxu14ELuOcly",
    "outputId": "f9b4c621-6a35-435c-b956-979ef448a777"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 2 / 2 ========\n",
      "Training...\n",
      "  Batch    40  of  27,688.    Elapsed: 0:00:32.\n",
      "  Batch    80  of  27,688.    Elapsed: 0:01:05.\n",
      "  Batch   120  of  27,688.    Elapsed: 0:01:37.\n",
      "  Batch   160  of  27,688.    Elapsed: 0:02:09.\n",
      "  Batch   200  of  27,688.    Elapsed: 0:02:42.\n",
      "  Batch   240  of  27,688.    Elapsed: 0:03:14.\n",
      "  Batch   280  of  27,688.    Elapsed: 0:03:46.\n",
      "  Batch   320  of  27,688.    Elapsed: 0:04:19.\n",
      "  Batch   360  of  27,688.    Elapsed: 0:04:51.\n",
      "  Batch   400  of  27,688.    Elapsed: 0:05:23.\n",
      "  Batch   440  of  27,688.    Elapsed: 0:05:56.\n",
      "  Batch   480  of  27,688.    Elapsed: 0:06:28.\n",
      "  Batch   520  of  27,688.    Elapsed: 0:07:09.\n",
      "  Batch   560  of  27,688.    Elapsed: 0:07:41.\n",
      "  Batch   600  of  27,688.    Elapsed: 0:08:14.\n",
      "  Batch   640  of  27,688.    Elapsed: 0:08:46.\n",
      "  Batch   680  of  27,688.    Elapsed: 0:09:18.\n",
      "  Batch   720  of  27,688.    Elapsed: 0:09:51.\n",
      "  Batch   760  of  27,688.    Elapsed: 0:10:23.\n",
      "  Batch   800  of  27,688.    Elapsed: 0:10:55.\n",
      "  Batch   840  of  27,688.    Elapsed: 0:11:28.\n",
      "  Batch   880  of  27,688.    Elapsed: 0:12:00.\n",
      "  Batch   920  of  27,688.    Elapsed: 0:12:32.\n",
      "  Batch   960  of  27,688.    Elapsed: 0:13:05.\n",
      "  Batch 1,000  of  27,688.    Elapsed: 0:13:37.\n",
      "  Batch 1,040  of  27,688.    Elapsed: 0:14:18.\n",
      "  Batch 1,080  of  27,688.    Elapsed: 0:14:50.\n",
      "  Batch 1,120  of  27,688.    Elapsed: 0:15:23.\n",
      "  Batch 1,160  of  27,688.    Elapsed: 0:15:55.\n",
      "  Batch 1,200  of  27,688.    Elapsed: 0:16:27.\n",
      "  Batch 1,240  of  27,688.    Elapsed: 0:17:00.\n",
      "  Batch 1,280  of  27,688.    Elapsed: 0:17:32.\n",
      "  Batch 1,320  of  27,688.    Elapsed: 0:18:04.\n",
      "  Batch 1,360  of  27,688.    Elapsed: 0:18:37.\n",
      "  Batch 1,400  of  27,688.    Elapsed: 0:19:09.\n",
      "  Batch 1,440  of  27,688.    Elapsed: 0:19:41.\n",
      "  Batch 1,480  of  27,688.    Elapsed: 0:20:14.\n",
      "  Batch 1,520  of  27,688.    Elapsed: 0:20:55.\n",
      "  Batch 1,560  of  27,688.    Elapsed: 0:21:27.\n",
      "  Batch 1,600  of  27,688.    Elapsed: 0:22:00.\n",
      "  Batch 1,640  of  27,688.    Elapsed: 0:22:32.\n",
      "  Batch 1,680  of  27,688.    Elapsed: 0:23:04.\n",
      "  Batch 1,720  of  27,688.    Elapsed: 0:23:37.\n",
      "  Batch 1,760  of  27,688.    Elapsed: 0:24:09.\n",
      "  Batch 1,800  of  27,688.    Elapsed: 0:24:41.\n",
      "  Batch 1,840  of  27,688.    Elapsed: 0:25:14.\n",
      "  Batch 1,880  of  27,688.    Elapsed: 0:25:46.\n",
      "  Batch 1,920  of  27,688.    Elapsed: 0:26:18.\n",
      "  Batch 1,960  of  27,688.    Elapsed: 0:26:51.\n",
      "  Batch 2,000  of  27,688.    Elapsed: 0:27:23.\n",
      "  Batch 2,040  of  27,688.    Elapsed: 0:28:04.\n",
      "  Batch 2,080  of  27,688.    Elapsed: 0:28:37.\n",
      "  Batch 2,120  of  27,688.    Elapsed: 0:29:09.\n",
      "  Batch 2,160  of  27,688.    Elapsed: 0:29:41.\n",
      "  Batch 2,200  of  27,688.    Elapsed: 0:30:14.\n",
      "  Batch 2,240  of  27,688.    Elapsed: 0:30:46.\n",
      "  Batch 2,280  of  27,688.    Elapsed: 0:31:18.\n",
      "  Batch 2,320  of  27,688.    Elapsed: 0:31:51.\n",
      "  Batch 2,360  of  27,688.    Elapsed: 0:32:23.\n",
      "  Batch 2,400  of  27,688.    Elapsed: 0:32:55.\n",
      "  Batch 2,440  of  27,688.    Elapsed: 0:33:28.\n",
      "  Batch 2,480  of  27,688.    Elapsed: 0:34:00.\n",
      "  Batch 2,520  of  27,688.    Elapsed: 0:34:41.\n",
      "  Batch 2,560  of  27,688.    Elapsed: 0:35:13.\n",
      "  Batch 2,600  of  27,688.    Elapsed: 0:35:46.\n",
      "  Batch 2,640  of  27,688.    Elapsed: 0:36:18.\n",
      "  Batch 2,680  of  27,688.    Elapsed: 0:36:50.\n",
      "  Batch 2,720  of  27,688.    Elapsed: 0:37:23.\n",
      "  Batch 2,760  of  27,688.    Elapsed: 0:37:55.\n",
      "  Batch 2,800  of  27,688.    Elapsed: 0:38:28.\n",
      "  Batch 2,840  of  27,688.    Elapsed: 0:39:00.\n",
      "  Batch 2,880  of  27,688.    Elapsed: 0:39:32.\n",
      "  Batch 2,920  of  27,688.    Elapsed: 0:40:05.\n",
      "  Batch 2,960  of  27,688.    Elapsed: 0:40:37.\n",
      "  Batch 3,000  of  27,688.    Elapsed: 0:41:09.\n",
      "  Batch 3,040  of  27,688.    Elapsed: 0:41:51.\n",
      "  Batch 3,080  of  27,688.    Elapsed: 0:42:23.\n",
      "  Batch 3,120  of  27,688.    Elapsed: 0:42:55.\n",
      "  Batch 3,160  of  27,688.    Elapsed: 0:43:28.\n",
      "  Batch 3,200  of  27,688.    Elapsed: 0:44:00.\n",
      "  Batch 3,240  of  27,688.    Elapsed: 0:44:32.\n",
      "  Batch 3,280  of  27,688.    Elapsed: 0:45:05.\n",
      "  Batch 3,320  of  27,688.    Elapsed: 0:45:37.\n",
      "  Batch 3,360  of  27,688.    Elapsed: 0:46:09.\n",
      "  Batch 3,400  of  27,688.    Elapsed: 0:46:42.\n",
      "  Batch 3,440  of  27,688.    Elapsed: 0:47:14.\n",
      "  Batch 3,480  of  27,688.    Elapsed: 0:47:46.\n",
      "  Batch 3,520  of  27,688.    Elapsed: 0:48:27.\n",
      "  Batch 3,560  of  27,688.    Elapsed: 0:49:00.\n",
      "  Batch 3,600  of  27,688.    Elapsed: 0:49:32.\n",
      "  Batch 3,640  of  27,688.    Elapsed: 0:50:04.\n",
      "  Batch 3,680  of  27,688.    Elapsed: 0:50:37.\n",
      "  Batch 3,720  of  27,688.    Elapsed: 0:51:09.\n",
      "  Batch 3,760  of  27,688.    Elapsed: 0:51:41.\n",
      "  Batch 3,800  of  27,688.    Elapsed: 0:52:14.\n",
      "  Batch 3,840  of  27,688.    Elapsed: 0:52:46.\n",
      "  Batch 3,880  of  27,688.    Elapsed: 0:53:19.\n",
      "  Batch 3,920  of  27,688.    Elapsed: 0:53:51.\n",
      "  Batch 3,960  of  27,688.    Elapsed: 0:54:23.\n",
      "  Batch 4,000  of  27,688.    Elapsed: 0:54:56.\n",
      "  Batch 4,040  of  27,688.    Elapsed: 0:55:37.\n",
      "  Batch 4,080  of  27,688.    Elapsed: 0:56:10.\n",
      "  Batch 4,120  of  27,688.    Elapsed: 0:56:42.\n",
      "  Batch 4,160  of  27,688.    Elapsed: 0:57:14.\n",
      "  Batch 4,200  of  27,688.    Elapsed: 0:57:47.\n",
      "  Batch 4,240  of  27,688.    Elapsed: 0:58:19.\n",
      "  Batch 4,280  of  27,688.    Elapsed: 0:58:51.\n",
      "  Batch 4,320  of  27,688.    Elapsed: 0:59:24.\n",
      "  Batch 4,360  of  27,688.    Elapsed: 0:59:56.\n",
      "  Batch 4,400  of  27,688.    Elapsed: 1:00:28.\n",
      "  Batch 4,440  of  27,688.    Elapsed: 1:01:01.\n",
      "  Batch 4,480  of  27,688.    Elapsed: 1:01:33.\n",
      "  Batch 4,520  of  27,688.    Elapsed: 1:02:14.\n",
      "  Batch 4,560  of  27,688.    Elapsed: 1:02:47.\n",
      "  Batch 4,600  of  27,688.    Elapsed: 1:03:19.\n",
      "  Batch 4,640  of  27,688.    Elapsed: 1:03:51.\n",
      "  Batch 4,680  of  27,688.    Elapsed: 1:04:24.\n",
      "  Batch 4,720  of  27,688.    Elapsed: 1:04:56.\n",
      "  Batch 4,760  of  27,688.    Elapsed: 1:05:29.\n",
      "  Batch 4,800  of  27,688.    Elapsed: 1:06:01.\n",
      "  Batch 4,840  of  27,688.    Elapsed: 1:06:33.\n",
      "  Batch 4,880  of  27,688.    Elapsed: 1:07:06.\n",
      "  Batch 4,920  of  27,688.    Elapsed: 1:07:38.\n",
      "  Batch 4,960  of  27,688.    Elapsed: 1:08:10.\n",
      "  Batch 5,000  of  27,688.    Elapsed: 1:08:43.\n",
      "  Batch 5,040  of  27,688.    Elapsed: 1:09:25.\n",
      "  Batch 5,080  of  27,688.    Elapsed: 1:09:57.\n",
      "  Batch 5,120  of  27,688.    Elapsed: 1:10:29.\n",
      "  Batch 5,160  of  27,688.    Elapsed: 1:11:02.\n",
      "  Batch 5,200  of  27,688.    Elapsed: 1:11:34.\n",
      "  Batch 5,240  of  27,688.    Elapsed: 1:12:06.\n",
      "  Batch 5,280  of  27,688.    Elapsed: 1:12:39.\n",
      "  Batch 5,320  of  27,688.    Elapsed: 1:13:11.\n",
      "  Batch 5,360  of  27,688.    Elapsed: 1:13:43.\n",
      "  Batch 5,400  of  27,688.    Elapsed: 1:14:16.\n",
      "  Batch 5,440  of  27,688.    Elapsed: 1:14:48.\n",
      "  Batch 5,480  of  27,688.    Elapsed: 1:15:21.\n",
      "  Batch 5,520  of  27,688.    Elapsed: 1:16:02.\n",
      "  Batch 5,560  of  27,688.    Elapsed: 1:16:34.\n",
      "  Batch 5,600  of  27,688.    Elapsed: 1:17:07.\n",
      "  Batch 5,640  of  27,688.    Elapsed: 1:17:39.\n",
      "  Batch 5,680  of  27,688.    Elapsed: 1:18:11.\n",
      "  Batch 5,720  of  27,688.    Elapsed: 1:18:44.\n",
      "  Batch 5,760  of  27,688.    Elapsed: 1:19:16.\n",
      "  Batch 5,800  of  27,688.    Elapsed: 1:19:48.\n",
      "  Batch 5,840  of  27,688.    Elapsed: 1:20:21.\n",
      "  Batch 5,880  of  27,688.    Elapsed: 1:20:53.\n",
      "  Batch 5,920  of  27,688.    Elapsed: 1:21:26.\n",
      "  Batch 5,960  of  27,688.    Elapsed: 1:21:58.\n",
      "  Batch 6,000  of  27,688.    Elapsed: 1:22:30.\n",
      "  Batch 6,040  of  27,688.    Elapsed: 1:23:12.\n",
      "  Batch 6,080  of  27,688.    Elapsed: 1:23:44.\n",
      "  Batch 6,120  of  27,688.    Elapsed: 1:24:16.\n",
      "  Batch 6,160  of  27,688.    Elapsed: 1:24:49.\n",
      "  Batch 6,200  of  27,688.    Elapsed: 1:25:21.\n",
      "  Batch 6,240  of  27,688.    Elapsed: 1:25:54.\n",
      "  Batch 6,280  of  27,688.    Elapsed: 1:26:26.\n",
      "  Batch 6,320  of  27,688.    Elapsed: 1:26:58.\n",
      "  Batch 6,360  of  27,688.    Elapsed: 1:27:31.\n",
      "  Batch 6,400  of  27,688.    Elapsed: 1:28:03.\n",
      "  Batch 6,440  of  27,688.    Elapsed: 1:28:35.\n",
      "  Batch 6,480  of  27,688.    Elapsed: 1:29:08.\n",
      "  Batch 6,520  of  27,688.    Elapsed: 1:29:50.\n",
      "  Batch 6,560  of  27,688.    Elapsed: 1:30:22.\n",
      "  Batch 6,600  of  27,688.    Elapsed: 1:30:54.\n",
      "  Batch 6,640  of  27,688.    Elapsed: 1:31:27.\n",
      "  Batch 6,680  of  27,688.    Elapsed: 1:31:59.\n",
      "  Batch 6,720  of  27,688.    Elapsed: 1:32:31.\n",
      "  Batch 6,760  of  27,688.    Elapsed: 1:33:04.\n",
      "  Batch 6,800  of  27,688.    Elapsed: 1:33:36.\n",
      "  Batch 6,840  of  27,688.    Elapsed: 1:34:09.\n",
      "  Batch 6,880  of  27,688.    Elapsed: 1:34:41.\n",
      "  Batch 6,920  of  27,688.    Elapsed: 1:35:13.\n",
      "  Batch 6,960  of  27,688.    Elapsed: 1:35:46.\n",
      "  Batch 7,000  of  27,688.    Elapsed: 1:36:18.\n",
      "  Batch 7,040  of  27,688.    Elapsed: 1:37:00.\n",
      "  Batch 7,080  of  27,688.    Elapsed: 1:37:32.\n",
      "  Batch 7,120  of  27,688.    Elapsed: 1:38:04.\n",
      "  Batch 7,160  of  27,688.    Elapsed: 1:38:37.\n",
      "  Batch 7,200  of  27,688.    Elapsed: 1:39:09.\n",
      "  Batch 7,240  of  27,688.    Elapsed: 1:39:42.\n",
      "  Batch 7,280  of  27,688.    Elapsed: 1:40:14.\n",
      "  Batch 7,320  of  27,688.    Elapsed: 1:40:46.\n",
      "  Batch 7,360  of  27,688.    Elapsed: 1:41:19.\n",
      "  Batch 7,400  of  27,688.    Elapsed: 1:41:51.\n",
      "  Batch 7,440  of  27,688.    Elapsed: 1:42:23.\n",
      "  Batch 7,480  of  27,688.    Elapsed: 1:42:56.\n",
      "  Batch 7,520  of  27,688.    Elapsed: 1:43:37.\n",
      "  Batch 7,560  of  27,688.    Elapsed: 1:44:10.\n",
      "  Batch 7,600  of  27,688.    Elapsed: 1:44:42.\n",
      "  Batch 7,640  of  27,688.    Elapsed: 1:45:14.\n",
      "  Batch 7,680  of  27,688.    Elapsed: 1:45:47.\n",
      "  Batch 7,720  of  27,688.    Elapsed: 1:46:19.\n",
      "  Batch 7,760  of  27,688.    Elapsed: 1:46:51.\n",
      "  Batch 7,800  of  27,688.    Elapsed: 1:47:24.\n",
      "  Batch 7,840  of  27,688.    Elapsed: 1:47:56.\n",
      "  Batch 7,880  of  27,688.    Elapsed: 1:48:29.\n",
      "  Batch 7,920  of  27,688.    Elapsed: 1:49:01.\n",
      "  Batch 7,960  of  27,688.    Elapsed: 1:49:33.\n",
      "  Batch 8,000  of  27,688.    Elapsed: 1:50:06.\n",
      "  Batch 8,040  of  27,688.    Elapsed: 1:50:47.\n",
      "  Batch 8,080  of  27,688.    Elapsed: 1:51:19.\n",
      "  Batch 8,120  of  27,688.    Elapsed: 1:51:52.\n",
      "  Batch 8,160  of  27,688.    Elapsed: 1:52:24.\n",
      "  Batch 8,200  of  27,688.    Elapsed: 1:52:57.\n",
      "  Batch 8,240  of  27,688.    Elapsed: 1:53:29.\n",
      "  Batch 8,280  of  27,688.    Elapsed: 1:54:01.\n",
      "  Batch 8,320  of  27,688.    Elapsed: 1:54:34.\n",
      "  Batch 8,360  of  27,688.    Elapsed: 1:55:06.\n",
      "  Batch 8,400  of  27,688.    Elapsed: 1:55:38.\n",
      "  Batch 8,440  of  27,688.    Elapsed: 1:56:11.\n",
      "  Batch 8,480  of  27,688.    Elapsed: 1:56:43.\n",
      "  Batch 8,520  of  27,688.    Elapsed: 1:57:25.\n",
      "  Batch 8,560  of  27,688.    Elapsed: 1:57:57.\n",
      "  Batch 8,600  of  27,688.    Elapsed: 1:58:30.\n",
      "  Batch 8,640  of  27,688.    Elapsed: 1:59:02.\n",
      "  Batch 8,680  of  27,688.    Elapsed: 1:59:34.\n",
      "  Batch 8,720  of  27,688.    Elapsed: 2:00:07.\n",
      "  Batch 8,760  of  27,688.    Elapsed: 2:00:39.\n",
      "  Batch 8,800  of  27,688.    Elapsed: 2:01:11.\n",
      "  Batch 8,840  of  27,688.    Elapsed: 2:01:44.\n",
      "  Batch 8,880  of  27,688.    Elapsed: 2:02:16.\n",
      "  Batch 8,920  of  27,688.    Elapsed: 2:02:48.\n",
      "  Batch 8,960  of  27,688.    Elapsed: 2:03:21.\n",
      "  Batch 9,000  of  27,688.    Elapsed: 2:03:53.\n",
      "  Batch 9,040  of  27,688.    Elapsed: 2:04:35.\n",
      "  Batch 9,080  of  27,688.    Elapsed: 2:05:08.\n",
      "  Batch 9,120  of  27,688.    Elapsed: 2:05:40.\n",
      "  Batch 9,160  of  27,688.    Elapsed: 2:06:12.\n",
      "  Batch 9,200  of  27,688.    Elapsed: 2:06:45.\n",
      "  Batch 9,240  of  27,688.    Elapsed: 2:07:17.\n",
      "  Batch 9,280  of  27,688.    Elapsed: 2:07:49.\n",
      "  Batch 9,320  of  27,688.    Elapsed: 2:08:22.\n",
      "  Batch 9,360  of  27,688.    Elapsed: 2:08:54.\n",
      "  Batch 9,400  of  27,688.    Elapsed: 2:09:27.\n",
      "  Batch 9,440  of  27,688.    Elapsed: 2:09:59.\n",
      "  Batch 9,480  of  27,688.    Elapsed: 2:10:31.\n",
      "  Batch 9,520  of  27,688.    Elapsed: 2:11:13.\n",
      "  Batch 9,560  of  27,688.    Elapsed: 2:11:45.\n",
      "  Batch 9,600  of  27,688.    Elapsed: 2:12:17.\n",
      "  Batch 9,640  of  27,688.    Elapsed: 2:12:50.\n",
      "  Batch 9,680  of  27,688.    Elapsed: 2:13:22.\n",
      "  Batch 9,720  of  27,688.    Elapsed: 2:13:54.\n",
      "  Batch 9,760  of  27,688.    Elapsed: 2:14:27.\n",
      "  Batch 9,800  of  27,688.    Elapsed: 2:14:59.\n",
      "  Batch 9,840  of  27,688.    Elapsed: 2:15:32.\n",
      "  Batch 9,880  of  27,688.    Elapsed: 2:16:04.\n",
      "  Batch 9,920  of  27,688.    Elapsed: 2:16:36.\n",
      "  Batch 9,960  of  27,688.    Elapsed: 2:17:09.\n",
      "  Batch 10,000  of  27,688.    Elapsed: 2:17:41.\n",
      "  Batch 10,040  of  27,688.    Elapsed: 2:18:22.\n",
      "  Batch 10,080  of  27,688.    Elapsed: 2:18:55.\n",
      "  Batch 10,120  of  27,688.    Elapsed: 2:19:27.\n",
      "  Batch 10,160  of  27,688.    Elapsed: 2:19:59.\n",
      "  Batch 10,200  of  27,688.    Elapsed: 2:20:32.\n",
      "  Batch 10,240  of  27,688.    Elapsed: 2:21:04.\n",
      "  Batch 10,280  of  27,688.    Elapsed: 2:21:36.\n",
      "  Batch 10,320  of  27,688.    Elapsed: 2:22:09.\n",
      "  Batch 10,360  of  27,688.    Elapsed: 2:22:41.\n",
      "  Batch 10,400  of  27,688.    Elapsed: 2:23:14.\n",
      "  Batch 10,440  of  27,688.    Elapsed: 2:23:46.\n",
      "  Batch 10,480  of  27,688.    Elapsed: 2:24:18.\n",
      "  Batch 10,520  of  27,688.    Elapsed: 2:25:00.\n",
      "  Batch 10,560  of  27,688.    Elapsed: 2:25:32.\n",
      "  Batch 10,600  of  27,688.    Elapsed: 2:26:04.\n",
      "  Batch 10,640  of  27,688.    Elapsed: 2:26:37.\n",
      "  Batch 10,680  of  27,688.    Elapsed: 2:27:09.\n",
      "  Batch 10,720  of  27,688.    Elapsed: 2:27:41.\n",
      "  Batch 10,760  of  27,688.    Elapsed: 2:28:14.\n",
      "  Batch 10,800  of  27,688.    Elapsed: 2:28:46.\n",
      "  Batch 10,840  of  27,688.    Elapsed: 2:29:18.\n",
      "  Batch 10,880  of  27,688.    Elapsed: 2:29:51.\n",
      "  Batch 10,920  of  27,688.    Elapsed: 2:30:23.\n",
      "  Batch 10,960  of  27,688.    Elapsed: 2:30:55.\n",
      "  Batch 11,000  of  27,688.    Elapsed: 2:31:28.\n",
      "  Batch 11,040  of  27,688.    Elapsed: 2:32:09.\n",
      "  Batch 11,080  of  27,688.    Elapsed: 2:32:41.\n",
      "  Batch 11,120  of  27,688.    Elapsed: 2:33:14.\n",
      "  Batch 11,160  of  27,688.    Elapsed: 2:33:46.\n",
      "  Batch 11,200  of  27,688.    Elapsed: 2:34:18.\n",
      "  Batch 11,240  of  27,688.    Elapsed: 2:34:51.\n",
      "  Batch 11,280  of  27,688.    Elapsed: 2:35:23.\n",
      "  Batch 11,320  of  27,688.    Elapsed: 2:35:55.\n",
      "  Batch 11,360  of  27,688.    Elapsed: 2:36:28.\n",
      "  Batch 11,400  of  27,688.    Elapsed: 2:37:00.\n",
      "  Batch 11,440  of  27,688.    Elapsed: 2:37:32.\n",
      "  Batch 11,480  of  27,688.    Elapsed: 2:38:05.\n",
      "  Batch 11,520  of  27,688.    Elapsed: 2:38:46.\n",
      "  Batch 11,560  of  27,688.    Elapsed: 2:39:18.\n",
      "  Batch 11,600  of  27,688.    Elapsed: 2:39:51.\n",
      "  Batch 11,640  of  27,688.    Elapsed: 2:40:23.\n",
      "  Batch 11,680  of  27,688.    Elapsed: 2:40:55.\n",
      "  Batch 11,720  of  27,688.    Elapsed: 2:41:28.\n",
      "  Batch 11,760  of  27,688.    Elapsed: 2:42:00.\n",
      "  Batch 11,800  of  27,688.    Elapsed: 2:42:32.\n",
      "  Batch 11,840  of  27,688.    Elapsed: 2:43:05.\n",
      "  Batch 11,880  of  27,688.    Elapsed: 2:43:37.\n",
      "  Batch 11,920  of  27,688.    Elapsed: 2:44:09.\n",
      "  Batch 11,960  of  27,688.    Elapsed: 2:44:42.\n",
      "  Batch 12,000  of  27,688.    Elapsed: 2:45:14.\n",
      "  Batch 12,040  of  27,688.    Elapsed: 2:45:56.\n",
      "  Batch 12,080  of  27,688.    Elapsed: 2:46:28.\n",
      "  Batch 12,120  of  27,688.    Elapsed: 2:47:00.\n",
      "  Batch 12,160  of  27,688.    Elapsed: 2:47:33.\n",
      "  Batch 12,200  of  27,688.    Elapsed: 2:48:05.\n",
      "  Batch 12,240  of  27,688.    Elapsed: 2:48:37.\n",
      "  Batch 12,280  of  27,688.    Elapsed: 2:49:10.\n",
      "  Batch 12,320  of  27,688.    Elapsed: 2:49:42.\n",
      "  Batch 12,360  of  27,688.    Elapsed: 2:50:14.\n",
      "  Batch 12,400  of  27,688.    Elapsed: 2:50:47.\n",
      "  Batch 12,440  of  27,688.    Elapsed: 2:51:19.\n",
      "  Batch 12,480  of  27,688.    Elapsed: 2:51:51.\n",
      "  Batch 12,520  of  27,688.    Elapsed: 2:52:33.\n",
      "  Batch 12,560  of  27,688.    Elapsed: 2:53:05.\n",
      "  Batch 12,600  of  27,688.    Elapsed: 2:53:37.\n",
      "  Batch 12,640  of  27,688.    Elapsed: 2:54:10.\n",
      "  Batch 12,680  of  27,688.    Elapsed: 2:54:42.\n",
      "  Batch 12,720  of  27,688.    Elapsed: 2:55:14.\n",
      "  Batch 12,760  of  27,688.    Elapsed: 2:55:47.\n",
      "  Batch 12,800  of  27,688.    Elapsed: 2:56:19.\n",
      "  Batch 12,840  of  27,688.    Elapsed: 2:56:51.\n",
      "  Batch 12,880  of  27,688.    Elapsed: 2:57:24.\n",
      "  Batch 12,920  of  27,688.    Elapsed: 2:57:56.\n",
      "  Batch 12,960  of  27,688.    Elapsed: 2:58:28.\n",
      "  Batch 13,000  of  27,688.    Elapsed: 2:59:01.\n",
      "  Batch 13,040  of  27,688.    Elapsed: 2:59:42.\n",
      "  Batch 13,080  of  27,688.    Elapsed: 3:00:14.\n",
      "  Batch 13,120  of  27,688.    Elapsed: 3:00:47.\n",
      "  Batch 13,160  of  27,688.    Elapsed: 3:01:19.\n",
      "  Batch 13,200  of  27,688.    Elapsed: 3:01:51.\n",
      "  Batch 13,240  of  27,688.    Elapsed: 3:02:24.\n",
      "  Batch 13,280  of  27,688.    Elapsed: 3:02:56.\n",
      "  Batch 13,320  of  27,688.    Elapsed: 3:03:28.\n",
      "  Batch 13,360  of  27,688.    Elapsed: 3:04:01.\n",
      "  Batch 13,400  of  27,688.    Elapsed: 3:04:33.\n",
      "  Batch 13,440  of  27,688.    Elapsed: 3:05:05.\n",
      "  Batch 13,480  of  27,688.    Elapsed: 3:05:38.\n",
      "  Batch 13,520  of  27,688.    Elapsed: 3:06:19.\n",
      "  Batch 13,560  of  27,688.    Elapsed: 3:06:52.\n",
      "  Batch 13,600  of  27,688.    Elapsed: 3:07:24.\n",
      "  Batch 13,640  of  27,688.    Elapsed: 3:07:56.\n",
      "  Batch 13,680  of  27,688.    Elapsed: 3:08:29.\n",
      "  Batch 13,720  of  27,688.    Elapsed: 3:09:01.\n",
      "  Batch 13,760  of  27,688.    Elapsed: 3:09:33.\n",
      "  Batch 13,800  of  27,688.    Elapsed: 3:10:06.\n",
      "  Batch 13,840  of  27,688.    Elapsed: 3:10:38.\n",
      "  Batch 13,880  of  27,688.    Elapsed: 3:11:10.\n",
      "  Batch 13,920  of  27,688.    Elapsed: 3:11:43.\n",
      "  Batch 13,960  of  27,688.    Elapsed: 3:12:15.\n",
      "  Batch 14,000  of  27,688.    Elapsed: 3:12:47.\n",
      "  Batch 14,040  of  27,688.    Elapsed: 3:13:29.\n",
      "  Batch 14,080  of  27,688.    Elapsed: 3:14:01.\n",
      "  Batch 14,120  of  27,688.    Elapsed: 3:14:33.\n",
      "  Batch 14,160  of  27,688.    Elapsed: 3:15:06.\n",
      "  Batch 14,200  of  27,688.    Elapsed: 3:15:38.\n",
      "  Batch 14,240  of  27,688.    Elapsed: 3:16:10.\n",
      "  Batch 14,280  of  27,688.    Elapsed: 3:16:43.\n",
      "  Batch 14,320  of  27,688.    Elapsed: 3:17:15.\n",
      "  Batch 14,360  of  27,688.    Elapsed: 3:17:47.\n",
      "  Batch 14,400  of  27,688.    Elapsed: 3:18:19.\n",
      "  Batch 14,440  of  27,688.    Elapsed: 3:18:52.\n",
      "  Batch 14,480  of  27,688.    Elapsed: 3:19:24.\n",
      "  Batch 14,520  of  27,688.    Elapsed: 3:20:05.\n",
      "  Batch 14,560  of  27,688.    Elapsed: 3:20:38.\n",
      "  Batch 14,600  of  27,688.    Elapsed: 3:21:10.\n",
      "  Batch 14,640  of  27,688.    Elapsed: 3:21:42.\n",
      "  Batch 14,680  of  27,688.    Elapsed: 3:22:15.\n",
      "  Batch 14,720  of  27,688.    Elapsed: 3:22:47.\n",
      "  Batch 14,760  of  27,688.    Elapsed: 3:23:19.\n",
      "  Batch 14,800  of  27,688.    Elapsed: 3:23:52.\n",
      "  Batch 14,840  of  27,688.    Elapsed: 3:24:24.\n",
      "  Batch 14,880  of  27,688.    Elapsed: 3:24:56.\n",
      "  Batch 14,920  of  27,688.    Elapsed: 3:25:28.\n",
      "  Batch 14,960  of  27,688.    Elapsed: 3:26:01.\n",
      "  Batch 15,000  of  27,688.    Elapsed: 3:26:33.\n",
      "  Batch 15,040  of  27,688.    Elapsed: 3:27:14.\n",
      "  Batch 15,080  of  27,688.    Elapsed: 3:27:47.\n",
      "  Batch 15,120  of  27,688.    Elapsed: 3:28:19.\n",
      "  Batch 15,160  of  27,688.    Elapsed: 3:28:51.\n",
      "  Batch 15,200  of  27,688.    Elapsed: 3:29:24.\n",
      "  Batch 15,240  of  27,688.    Elapsed: 3:29:56.\n",
      "  Batch 15,280  of  27,688.    Elapsed: 3:30:28.\n",
      "  Batch 15,320  of  27,688.    Elapsed: 3:31:01.\n",
      "  Batch 15,360  of  27,688.    Elapsed: 3:31:33.\n",
      "  Batch 15,400  of  27,688.    Elapsed: 3:32:05.\n",
      "  Batch 15,440  of  27,688.    Elapsed: 3:32:38.\n",
      "  Batch 15,480  of  27,688.    Elapsed: 3:33:10.\n",
      "  Batch 15,520  of  27,688.    Elapsed: 3:33:51.\n",
      "  Batch 15,560  of  27,688.    Elapsed: 3:34:24.\n",
      "  Batch 15,600  of  27,688.    Elapsed: 3:34:56.\n",
      "  Batch 15,640  of  27,688.    Elapsed: 3:35:28.\n",
      "  Batch 15,680  of  27,688.    Elapsed: 3:36:01.\n",
      "  Batch 15,720  of  27,688.    Elapsed: 3:36:33.\n",
      "  Batch 15,760  of  27,688.    Elapsed: 3:37:05.\n",
      "  Batch 15,800  of  27,688.    Elapsed: 3:37:38.\n",
      "  Batch 15,840  of  27,688.    Elapsed: 3:38:10.\n",
      "  Batch 15,880  of  27,688.    Elapsed: 3:38:42.\n",
      "  Batch 15,920  of  27,688.    Elapsed: 3:39:15.\n",
      "  Batch 15,960  of  27,688.    Elapsed: 3:39:47.\n",
      "  Batch 16,000  of  27,688.    Elapsed: 3:40:20.\n",
      "  Batch 16,040  of  27,688.    Elapsed: 3:41:01.\n",
      "  Batch 16,080  of  27,688.    Elapsed: 3:41:33.\n",
      "  Batch 16,120  of  27,688.    Elapsed: 3:42:06.\n",
      "  Batch 16,160  of  27,688.    Elapsed: 3:42:38.\n",
      "  Batch 16,200  of  27,688.    Elapsed: 3:43:10.\n",
      "  Batch 16,240  of  27,688.    Elapsed: 3:43:43.\n",
      "  Batch 16,280  of  27,688.    Elapsed: 3:44:15.\n",
      "  Batch 16,320  of  27,688.    Elapsed: 3:44:47.\n",
      "  Batch 16,360  of  27,688.    Elapsed: 3:45:20.\n",
      "  Batch 16,400  of  27,688.    Elapsed: 3:45:52.\n",
      "  Batch 16,440  of  27,688.    Elapsed: 3:46:24.\n",
      "  Batch 16,480  of  27,688.    Elapsed: 3:46:57.\n",
      "  Batch 16,520  of  27,688.    Elapsed: 3:47:38.\n",
      "  Batch 16,560  of  27,688.    Elapsed: 3:48:11.\n",
      "  Batch 16,600  of  27,688.    Elapsed: 3:48:43.\n",
      "  Batch 16,640  of  27,688.    Elapsed: 3:49:16.\n",
      "  Batch 16,680  of  27,688.    Elapsed: 3:49:48.\n",
      "  Batch 16,720  of  27,688.    Elapsed: 3:50:20.\n",
      "  Batch 16,760  of  27,688.    Elapsed: 3:50:53.\n",
      "  Batch 16,800  of  27,688.    Elapsed: 3:51:25.\n",
      "  Batch 16,840  of  27,688.    Elapsed: 3:51:57.\n",
      "  Batch 16,880  of  27,688.    Elapsed: 3:52:30.\n",
      "  Batch 16,920  of  27,688.    Elapsed: 3:53:02.\n",
      "  Batch 16,960  of  27,688.    Elapsed: 3:53:35.\n",
      "  Batch 17,000  of  27,688.    Elapsed: 3:54:07.\n",
      "  Batch 17,040  of  27,688.    Elapsed: 3:54:48.\n",
      "  Batch 17,080  of  27,688.    Elapsed: 3:55:21.\n",
      "  Batch 17,120  of  27,688.    Elapsed: 3:55:53.\n",
      "  Batch 17,160  of  27,688.    Elapsed: 3:56:25.\n",
      "  Batch 17,200  of  27,688.    Elapsed: 3:56:58.\n",
      "  Batch 17,240  of  27,688.    Elapsed: 3:57:30.\n",
      "  Batch 17,280  of  27,688.    Elapsed: 3:58:02.\n",
      "  Batch 17,320  of  27,688.    Elapsed: 3:58:35.\n",
      "  Batch 17,360  of  27,688.    Elapsed: 3:59:07.\n",
      "  Batch 17,400  of  27,688.    Elapsed: 3:59:40.\n",
      "  Batch 17,440  of  27,688.    Elapsed: 4:00:12.\n",
      "  Batch 17,480  of  27,688.    Elapsed: 4:00:44.\n",
      "  Batch 17,520  of  27,688.    Elapsed: 4:01:26.\n",
      "  Batch 17,560  of  27,688.    Elapsed: 4:01:58.\n",
      "  Batch 17,600  of  27,688.    Elapsed: 4:02:30.\n",
      "  Batch 17,640  of  27,688.    Elapsed: 4:03:03.\n",
      "  Batch 17,680  of  27,688.    Elapsed: 4:03:35.\n",
      "  Batch 17,720  of  27,688.    Elapsed: 4:04:07.\n",
      "  Batch 17,760  of  27,688.    Elapsed: 4:04:40.\n",
      "  Batch 17,800  of  27,688.    Elapsed: 4:05:12.\n",
      "  Batch 17,840  of  27,688.    Elapsed: 4:05:44.\n",
      "  Batch 17,880  of  27,688.    Elapsed: 4:06:17.\n",
      "  Batch 17,920  of  27,688.    Elapsed: 4:06:49.\n",
      "  Batch 17,960  of  27,688.    Elapsed: 4:07:22.\n",
      "  Batch 18,000  of  27,688.    Elapsed: 4:07:54.\n",
      "  Batch 18,040  of  27,688.    Elapsed: 4:08:36.\n",
      "  Batch 18,080  of  27,688.    Elapsed: 4:09:08.\n",
      "  Batch 18,120  of  27,688.    Elapsed: 4:09:41.\n",
      "  Batch 18,160  of  27,688.    Elapsed: 4:10:13.\n",
      "  Batch 18,200  of  27,688.    Elapsed: 4:10:45.\n",
      "  Batch 18,240  of  27,688.    Elapsed: 4:11:18.\n",
      "  Batch 18,280  of  27,688.    Elapsed: 4:11:50.\n",
      "  Batch 18,320  of  27,688.    Elapsed: 4:12:22.\n",
      "  Batch 18,360  of  27,688.    Elapsed: 4:12:55.\n",
      "  Batch 18,400  of  27,688.    Elapsed: 4:13:27.\n",
      "  Batch 18,440  of  27,688.    Elapsed: 4:14:00.\n",
      "  Batch 18,480  of  27,688.    Elapsed: 4:14:32.\n",
      "  Batch 18,520  of  27,688.    Elapsed: 4:15:13.\n",
      "  Batch 18,560  of  27,688.    Elapsed: 4:15:45.\n",
      "  Batch 18,600  of  27,688.    Elapsed: 4:16:18.\n",
      "  Batch 18,640  of  27,688.    Elapsed: 4:16:50.\n",
      "  Batch 18,680  of  27,688.    Elapsed: 4:17:23.\n",
      "  Batch 18,720  of  27,688.    Elapsed: 4:17:55.\n",
      "  Batch 18,760  of  27,688.    Elapsed: 4:18:27.\n",
      "  Batch 18,800  of  27,688.    Elapsed: 4:19:00.\n",
      "  Batch 18,840  of  27,688.    Elapsed: 4:19:32.\n",
      "  Batch 18,880  of  27,688.    Elapsed: 4:20:04.\n",
      "  Batch 18,920  of  27,688.    Elapsed: 4:20:37.\n",
      "  Batch 18,960  of  27,688.    Elapsed: 4:21:09.\n",
      "  Batch 19,000  of  27,688.    Elapsed: 4:21:41.\n",
      "  Batch 19,040  of  27,688.    Elapsed: 4:22:22.\n",
      "  Batch 19,080  of  27,688.    Elapsed: 4:22:55.\n",
      "  Batch 19,120  of  27,688.    Elapsed: 4:23:27.\n",
      "  Batch 19,160  of  27,688.    Elapsed: 4:24:00.\n",
      "  Batch 19,200  of  27,688.    Elapsed: 4:24:32.\n",
      "  Batch 19,240  of  27,688.    Elapsed: 4:25:04.\n",
      "  Batch 19,280  of  27,688.    Elapsed: 4:25:37.\n",
      "  Batch 19,320  of  27,688.    Elapsed: 4:26:09.\n",
      "  Batch 19,360  of  27,688.    Elapsed: 4:26:41.\n",
      "  Batch 19,400  of  27,688.    Elapsed: 4:27:14.\n",
      "  Batch 19,440  of  27,688.    Elapsed: 4:27:46.\n",
      "  Batch 19,480  of  27,688.    Elapsed: 4:28:18.\n",
      "  Batch 19,520  of  27,688.    Elapsed: 4:29:00.\n",
      "  Batch 19,560  of  27,688.    Elapsed: 4:29:33.\n",
      "  Batch 19,600  of  27,688.    Elapsed: 4:30:05.\n",
      "  Batch 19,640  of  27,688.    Elapsed: 4:30:37.\n",
      "  Batch 19,680  of  27,688.    Elapsed: 4:31:10.\n",
      "  Batch 19,720  of  27,688.    Elapsed: 4:31:42.\n",
      "  Batch 19,760  of  27,688.    Elapsed: 4:32:14.\n",
      "  Batch 19,800  of  27,688.    Elapsed: 4:32:47.\n",
      "  Batch 19,840  of  27,688.    Elapsed: 4:33:19.\n",
      "  Batch 19,880  of  27,688.    Elapsed: 4:33:51.\n",
      "  Batch 19,920  of  27,688.    Elapsed: 4:34:24.\n",
      "  Batch 19,960  of  27,688.    Elapsed: 4:34:56.\n",
      "  Batch 20,000  of  27,688.    Elapsed: 4:35:28.\n",
      "  Batch 20,040  of  27,688.    Elapsed: 4:36:10.\n",
      "  Batch 20,080  of  27,688.    Elapsed: 4:36:42.\n",
      "  Batch 20,120  of  27,688.    Elapsed: 4:37:14.\n",
      "  Batch 20,160  of  27,688.    Elapsed: 4:37:47.\n",
      "  Batch 20,200  of  27,688.    Elapsed: 4:38:19.\n",
      "  Batch 20,240  of  27,688.    Elapsed: 4:38:51.\n",
      "  Batch 20,280  of  27,688.    Elapsed: 4:39:24.\n",
      "  Batch 20,320  of  27,688.    Elapsed: 4:39:56.\n",
      "  Batch 20,360  of  27,688.    Elapsed: 4:40:28.\n",
      "  Batch 20,400  of  27,688.    Elapsed: 4:41:01.\n",
      "  Batch 20,440  of  27,688.    Elapsed: 4:41:33.\n",
      "  Batch 20,480  of  27,688.    Elapsed: 4:42:05.\n",
      "  Batch 20,520  of  27,688.    Elapsed: 4:42:46.\n",
      "  Batch 20,560  of  27,688.    Elapsed: 4:43:19.\n",
      "  Batch 20,600  of  27,688.    Elapsed: 4:43:51.\n",
      "  Batch 20,640  of  27,688.    Elapsed: 4:44:23.\n",
      "  Batch 20,680  of  27,688.    Elapsed: 4:44:56.\n",
      "  Batch 20,720  of  27,688.    Elapsed: 4:45:28.\n",
      "  Batch 20,760  of  27,688.    Elapsed: 4:46:01.\n",
      "  Batch 20,800  of  27,688.    Elapsed: 4:46:33.\n",
      "  Batch 20,840  of  27,688.    Elapsed: 4:47:05.\n",
      "  Batch 20,880  of  27,688.    Elapsed: 4:47:38.\n",
      "  Batch 20,920  of  27,688.    Elapsed: 4:48:10.\n",
      "  Batch 20,960  of  27,688.    Elapsed: 4:48:42.\n",
      "  Batch 21,000  of  27,688.    Elapsed: 4:49:15.\n",
      "  Batch 21,040  of  27,688.    Elapsed: 4:49:57.\n",
      "  Batch 21,080  of  27,688.    Elapsed: 4:50:29.\n",
      "  Batch 21,120  of  27,688.    Elapsed: 4:51:01.\n",
      "  Batch 21,160  of  27,688.    Elapsed: 4:51:34.\n",
      "  Batch 21,200  of  27,688.    Elapsed: 4:52:06.\n",
      "  Batch 21,240  of  27,688.    Elapsed: 4:52:38.\n",
      "  Batch 21,280  of  27,688.    Elapsed: 4:53:11.\n",
      "  Batch 21,320  of  27,688.    Elapsed: 4:53:43.\n",
      "  Batch 21,360  of  27,688.    Elapsed: 4:54:15.\n",
      "  Batch 21,400  of  27,688.    Elapsed: 4:54:48.\n",
      "  Batch 21,440  of  27,688.    Elapsed: 4:55:20.\n",
      "  Batch 21,480  of  27,688.    Elapsed: 4:55:52.\n",
      "  Batch 21,520  of  27,688.    Elapsed: 4:56:33.\n",
      "  Batch 21,560  of  27,688.    Elapsed: 4:57:06.\n",
      "  Batch 21,600  of  27,688.    Elapsed: 4:57:38.\n",
      "  Batch 21,640  of  27,688.    Elapsed: 4:58:10.\n",
      "  Batch 21,680  of  27,688.    Elapsed: 4:58:43.\n",
      "  Batch 21,720  of  27,688.    Elapsed: 4:59:15.\n",
      "  Batch 21,760  of  27,688.    Elapsed: 4:59:47.\n",
      "  Batch 21,800  of  27,688.    Elapsed: 5:00:20.\n",
      "  Batch 21,840  of  27,688.    Elapsed: 5:00:52.\n",
      "  Batch 21,880  of  27,688.    Elapsed: 5:01:24.\n",
      "  Batch 21,920  of  27,688.    Elapsed: 5:01:57.\n",
      "  Batch 21,960  of  27,688.    Elapsed: 5:02:29.\n",
      "  Batch 22,000  of  27,688.    Elapsed: 5:03:01.\n",
      "  Batch 22,040  of  27,688.    Elapsed: 5:03:43.\n",
      "  Batch 22,080  of  27,688.    Elapsed: 5:04:15.\n",
      "  Batch 22,120  of  27,688.    Elapsed: 5:04:47.\n",
      "  Batch 22,160  of  27,688.    Elapsed: 5:05:20.\n",
      "  Batch 22,200  of  27,688.    Elapsed: 5:05:52.\n",
      "  Batch 22,240  of  27,688.    Elapsed: 5:06:24.\n",
      "  Batch 22,280  of  27,688.    Elapsed: 5:06:57.\n",
      "  Batch 22,320  of  27,688.    Elapsed: 5:07:29.\n",
      "  Batch 22,360  of  27,688.    Elapsed: 5:08:01.\n",
      "  Batch 22,400  of  27,688.    Elapsed: 5:08:34.\n",
      "  Batch 22,440  of  27,688.    Elapsed: 5:09:06.\n",
      "  Batch 22,480  of  27,688.    Elapsed: 5:09:38.\n",
      "  Batch 22,520  of  27,688.    Elapsed: 5:10:20.\n",
      "  Batch 22,560  of  27,688.    Elapsed: 5:10:52.\n",
      "  Batch 22,600  of  27,688.    Elapsed: 5:11:25.\n",
      "  Batch 22,640  of  27,688.    Elapsed: 5:11:57.\n",
      "  Batch 22,680  of  27,688.    Elapsed: 5:12:29.\n",
      "  Batch 22,720  of  27,688.    Elapsed: 5:13:02.\n",
      "  Batch 22,760  of  27,688.    Elapsed: 5:13:34.\n",
      "  Batch 22,800  of  27,688.    Elapsed: 5:14:06.\n",
      "  Batch 22,840  of  27,688.    Elapsed: 5:14:39.\n",
      "  Batch 22,880  of  27,688.    Elapsed: 5:15:11.\n",
      "  Batch 22,920  of  27,688.    Elapsed: 5:15:43.\n",
      "  Batch 22,960  of  27,688.    Elapsed: 5:16:16.\n",
      "  Batch 23,000  of  27,688.    Elapsed: 5:16:48.\n",
      "  Batch 23,040  of  27,688.    Elapsed: 5:17:29.\n",
      "  Batch 23,080  of  27,688.    Elapsed: 5:18:02.\n",
      "  Batch 23,120  of  27,688.    Elapsed: 5:18:34.\n",
      "  Batch 23,160  of  27,688.    Elapsed: 5:19:06.\n",
      "  Batch 23,200  of  27,688.    Elapsed: 5:19:39.\n",
      "  Batch 23,240  of  27,688.    Elapsed: 5:20:11.\n",
      "  Batch 23,280  of  27,688.    Elapsed: 5:20:43.\n",
      "  Batch 23,320  of  27,688.    Elapsed: 5:21:16.\n",
      "  Batch 23,360  of  27,688.    Elapsed: 5:21:48.\n",
      "  Batch 23,400  of  27,688.    Elapsed: 5:22:20.\n",
      "  Batch 23,440  of  27,688.    Elapsed: 5:22:53.\n",
      "  Batch 23,480  of  27,688.    Elapsed: 5:23:25.\n",
      "  Batch 23,520  of  27,688.    Elapsed: 5:24:06.\n",
      "  Batch 23,560  of  27,688.    Elapsed: 5:24:39.\n",
      "  Batch 23,600  of  27,688.    Elapsed: 5:25:11.\n",
      "  Batch 23,640  of  27,688.    Elapsed: 5:25:43.\n",
      "  Batch 23,680  of  27,688.    Elapsed: 5:26:16.\n",
      "  Batch 23,720  of  27,688.    Elapsed: 5:26:48.\n",
      "  Batch 23,760  of  27,688.    Elapsed: 5:27:20.\n",
      "  Batch 23,800  of  27,688.    Elapsed: 5:27:53.\n",
      "  Batch 23,840  of  27,688.    Elapsed: 5:28:25.\n",
      "  Batch 23,880  of  27,688.    Elapsed: 5:28:57.\n",
      "  Batch 23,920  of  27,688.    Elapsed: 5:29:30.\n",
      "  Batch 23,960  of  27,688.    Elapsed: 5:30:02.\n",
      "  Batch 24,000  of  27,688.    Elapsed: 5:30:34.\n",
      "  Batch 24,040  of  27,688.    Elapsed: 5:31:16.\n",
      "  Batch 24,080  of  27,688.    Elapsed: 5:31:48.\n",
      "  Batch 24,120  of  27,688.    Elapsed: 5:32:20.\n",
      "  Batch 24,160  of  27,688.    Elapsed: 5:32:53.\n",
      "  Batch 24,200  of  27,688.    Elapsed: 5:33:25.\n",
      "  Batch 24,240  of  27,688.    Elapsed: 5:33:57.\n",
      "  Batch 24,280  of  27,688.    Elapsed: 5:34:30.\n",
      "  Batch 24,320  of  27,688.    Elapsed: 5:35:02.\n",
      "  Batch 24,360  of  27,688.    Elapsed: 5:35:34.\n",
      "  Batch 24,400  of  27,688.    Elapsed: 5:36:07.\n",
      "  Batch 24,440  of  27,688.    Elapsed: 5:36:39.\n",
      "  Batch 24,480  of  27,688.    Elapsed: 5:37:11.\n",
      "  Batch 24,520  of  27,688.    Elapsed: 5:37:52.\n",
      "  Batch 24,560  of  27,688.    Elapsed: 5:38:25.\n",
      "  Batch 24,600  of  27,688.    Elapsed: 5:38:57.\n",
      "  Batch 24,640  of  27,688.    Elapsed: 5:39:29.\n",
      "  Batch 24,680  of  27,688.    Elapsed: 5:40:02.\n",
      "  Batch 24,720  of  27,688.    Elapsed: 5:40:34.\n",
      "  Batch 24,760  of  27,688.    Elapsed: 5:41:07.\n",
      "  Batch 24,800  of  27,688.    Elapsed: 5:41:39.\n",
      "  Batch 24,840  of  27,688.    Elapsed: 5:42:11.\n",
      "  Batch 24,880  of  27,688.    Elapsed: 5:42:44.\n",
      "  Batch 24,920  of  27,688.    Elapsed: 5:43:16.\n",
      "  Batch 24,960  of  27,688.    Elapsed: 5:43:48.\n",
      "  Batch 25,000  of  27,688.    Elapsed: 5:44:21.\n",
      "  Batch 25,040  of  27,688.    Elapsed: 5:45:02.\n",
      "  Batch 25,080  of  27,688.    Elapsed: 5:45:34.\n",
      "  Batch 25,120  of  27,688.    Elapsed: 5:46:06.\n",
      "  Batch 25,160  of  27,688.    Elapsed: 5:46:39.\n",
      "  Batch 25,200  of  27,688.    Elapsed: 5:47:11.\n",
      "  Batch 25,240  of  27,688.    Elapsed: 5:47:43.\n",
      "  Batch 25,280  of  27,688.    Elapsed: 5:48:16.\n",
      "  Batch 25,320  of  27,688.    Elapsed: 5:48:48.\n",
      "  Batch 25,360  of  27,688.    Elapsed: 5:49:20.\n",
      "  Batch 25,400  of  27,688.    Elapsed: 5:49:53.\n",
      "  Batch 25,440  of  27,688.    Elapsed: 5:50:25.\n",
      "  Batch 25,480  of  27,688.    Elapsed: 5:50:57.\n",
      "  Batch 25,520  of  27,688.    Elapsed: 5:51:39.\n",
      "  Batch 25,560  of  27,688.    Elapsed: 5:52:11.\n",
      "  Batch 25,600  of  27,688.    Elapsed: 5:52:44.\n",
      "  Batch 25,640  of  27,688.    Elapsed: 5:53:16.\n",
      "  Batch 25,680  of  27,688.    Elapsed: 5:53:48.\n",
      "  Batch 25,720  of  27,688.    Elapsed: 5:54:21.\n",
      "  Batch 25,760  of  27,688.    Elapsed: 5:54:53.\n",
      "  Batch 25,800  of  27,688.    Elapsed: 5:55:25.\n",
      "  Batch 25,840  of  27,688.    Elapsed: 5:55:58.\n",
      "  Batch 25,880  of  27,688.    Elapsed: 5:56:30.\n",
      "  Batch 25,920  of  27,688.    Elapsed: 5:57:02.\n",
      "  Batch 25,960  of  27,688.    Elapsed: 5:57:35.\n",
      "  Batch 26,000  of  27,688.    Elapsed: 5:58:07.\n",
      "  Batch 26,040  of  27,688.    Elapsed: 5:58:48.\n",
      "  Batch 26,080  of  27,688.    Elapsed: 5:59:21.\n",
      "  Batch 26,120  of  27,688.    Elapsed: 5:59:53.\n",
      "  Batch 26,160  of  27,688.    Elapsed: 6:00:25.\n",
      "  Batch 26,200  of  27,688.    Elapsed: 6:00:58.\n",
      "  Batch 26,240  of  27,688.    Elapsed: 6:01:30.\n",
      "  Batch 26,280  of  27,688.    Elapsed: 6:02:02.\n",
      "  Batch 26,320  of  27,688.    Elapsed: 6:02:35.\n",
      "  Batch 26,360  of  27,688.    Elapsed: 6:03:07.\n",
      "  Batch 26,400  of  27,688.    Elapsed: 6:03:39.\n",
      "  Batch 26,440  of  27,688.    Elapsed: 6:04:12.\n",
      "  Batch 26,480  of  27,688.    Elapsed: 6:04:44.\n",
      "  Batch 26,520  of  27,688.    Elapsed: 6:05:26.\n",
      "  Batch 26,560  of  27,688.    Elapsed: 6:05:58.\n",
      "  Batch 26,600  of  27,688.    Elapsed: 6:06:30.\n",
      "  Batch 26,640  of  27,688.    Elapsed: 6:07:03.\n",
      "  Batch 26,680  of  27,688.    Elapsed: 6:07:35.\n",
      "  Batch 26,720  of  27,688.    Elapsed: 6:08:07.\n",
      "  Batch 26,760  of  27,688.    Elapsed: 6:08:40.\n",
      "  Batch 26,800  of  27,688.    Elapsed: 6:09:12.\n",
      "  Batch 26,840  of  27,688.    Elapsed: 6:09:44.\n",
      "  Batch 26,880  of  27,688.    Elapsed: 6:10:16.\n",
      "  Batch 26,920  of  27,688.    Elapsed: 6:10:49.\n",
      "  Batch 26,960  of  27,688.    Elapsed: 6:11:21.\n",
      "  Batch 27,000  of  27,688.    Elapsed: 6:11:53.\n",
      "  Batch 27,040  of  27,688.    Elapsed: 6:12:35.\n",
      "  Batch 27,080  of  27,688.    Elapsed: 6:13:07.\n",
      "  Batch 27,120  of  27,688.    Elapsed: 6:13:40.\n",
      "  Batch 27,160  of  27,688.    Elapsed: 6:14:12.\n",
      "  Batch 27,200  of  27,688.    Elapsed: 6:14:44.\n",
      "  Batch 27,240  of  27,688.    Elapsed: 6:15:17.\n",
      "  Batch 27,280  of  27,688.    Elapsed: 6:15:49.\n",
      "  Batch 27,320  of  27,688.    Elapsed: 6:16:21.\n",
      "  Batch 27,360  of  27,688.    Elapsed: 6:16:54.\n",
      "  Batch 27,400  of  27,688.    Elapsed: 6:17:26.\n",
      "  Batch 27,440  of  27,688.    Elapsed: 6:17:58.\n",
      "  Batch 27,480  of  27,688.    Elapsed: 6:18:30.\n",
      "  Batch 27,520  of  27,688.    Elapsed: 6:19:12.\n",
      "  Batch 27,560  of  27,688.    Elapsed: 6:19:44.\n",
      "  Batch 27,600  of  27,688.    Elapsed: 6:20:16.\n",
      "  Batch 27,640  of  27,688.    Elapsed: 6:20:49.\n",
      "  Batch 27,680  of  27,688.    Elapsed: 6:21:21.\n",
      "\n",
      "  Average training loss: 0.08\n",
      "  Training epcoh took: 6:21:27\n",
      "\n",
      "Running Validation...\n",
      "  ROC AUC: 0.99\n",
      "  Validation Loss: 0.11\n",
      "  Validation took: 0:13:17\n",
      "\n",
      "Training complete!\n",
      "Total training took 6:34:44 (h:mm:ss)\n"
     ]
    }
   ],
   "source": [
    "epoch = 1\n",
    "\n",
    "seed_val = 42\n",
    "\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "# training_stats = []\n",
    "total_t0 = time.time()\n",
    "\n",
    "# ========================================\n",
    "#               Training\n",
    "# ========================================\n",
    "\n",
    "\n",
    "print(\"\")\n",
    "print('======== Epoch {:} / {:} ========'.format(epoch + 1, epochs))\n",
    "print('Training...')\n",
    "\n",
    "t0 = time.time()\n",
    "total_train_loss = 0\n",
    "\n",
    "model.train()\n",
    "\n",
    "for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "    if step % 40 == 0 and not step == 0:\n",
    "        elapsed = format_time(time.time() - t0)\n",
    "        print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(\n",
    "            step, len(train_dataloader), elapsed))\n",
    "\n",
    "    b_input_ids = batch[0].to(device)\n",
    "    b_input_mask = batch[1].to(device)\n",
    "    b_labels = batch[2].to(device)\n",
    "\n",
    "    model.zero_grad()        \n",
    "\n",
    "    loss, logits = model(\n",
    "        b_input_ids, \n",
    "        token_type_ids=None, \n",
    "        attention_mask=b_input_mask, \n",
    "        labels=b_labels).values()\n",
    "\n",
    "    total_train_loss += loss.item()\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "\n",
    "    if step % 500 == 0 and not step == 0:\n",
    "        torch.save(\n",
    "            {'epoch': epoch,\n",
    "             'model_state_dict': model.state_dict(),\n",
    "             'optimizer_state_dict': optimizer.state_dict(),\n",
    "             'loss': loss\n",
    "                }, \n",
    "            '{}checkpoint_epoch_2'.format(CHECKPOINTS_PATH)\n",
    "            )\n",
    "\n",
    "avg_train_loss = total_train_loss / len(train_dataloader)            \n",
    "training_time = format_time(time.time() - t0)\n",
    "\n",
    "print(\"\")\n",
    "print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "print(\"  Training epcoh took: {:}\".format(training_time))\n",
    "    \n",
    "# ========================================\n",
    "#               Validation\n",
    "# ========================================\n",
    "\n",
    "print(\"\")\n",
    "print(\"Running Validation...\")\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "model.eval()\n",
    "\n",
    "total_eval_roc_auc = 0\n",
    "total_eval_loss = 0\n",
    "nb_eval_steps = 0\n",
    "\n",
    "for batch in validation_dataloader:\n",
    "    \n",
    "    b_input_ids = batch[0].to(device)\n",
    "    b_input_mask = batch[1].to(device)\n",
    "    b_labels = batch[2].to(device)\n",
    "    \n",
    "    with torch.no_grad():        \n",
    "        (loss, logits) = model(\n",
    "            b_input_ids, \n",
    "            token_type_ids=None, \n",
    "            attention_mask=b_input_mask,\n",
    "            labels=b_labels).values()\n",
    "        \n",
    "    total_eval_loss += loss.item()\n",
    "\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "    total_eval_roc_auc += flat_roc_auc(logits, label_ids)\n",
    "    \n",
    "avg_val_roc_auc = total_eval_roc_auc / len(validation_dataloader)\n",
    "print(\"  ROC AUC: {0:.2f}\".format(avg_val_roc_auc))\n",
    "\n",
    "avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
    "validation_time = format_time(time.time() - t0)\n",
    "\n",
    "print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
    "print(\"  Validation took: {:}\".format(validation_time))\n",
    "\n",
    "training_stats.append(\n",
    "    {\n",
    "        'epoch': epoch + 1,\n",
    "        'Training Loss': avg_train_loss,\n",
    "        'Valid. Loss': avg_val_loss,\n",
    "        'Valid. Accur.': avg_val_roc_auc,\n",
    "        'Training Time': training_time,\n",
    "        'Validation Time': validation_time\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"\")\n",
    "print(\"Training complete!\")\n",
    "\n",
    "print(\"Total training took {:} (h:mm:ss)\".format(\n",
    "    format_time(time.time()-total_t0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UTDxvOvaOcqP"
   },
   "outputs": [],
   "source": [
    "# torch.save({\n",
    "#     'epoch': epoch,\n",
    "#     'model_state_dict': model.state_dict(),\n",
    "#     'optimizer_state_dict': optimizer.state_dict(),\n",
    "#     'loss': loss,\n",
    "#   }, '{}checkpoint_epoch_2'.format(CHECKPOINTS_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2698,
     "status": "ok",
     "timestamp": 1654578620578,
     "user": {
      "displayName": "Никита Орлов",
      "userId": "17221654573895787003"
     },
     "user_tz": -180
    },
    "id": "2QKVcdkVOcuO",
    "outputId": "60a361d2-bf8f-4763-e9a7-6a70aafa8993"
   },
   "outputs": [],
   "source": [
    "# print(\"Saving model to %s\" % '{}epoch_2'.format(MODEL_PATH))\n",
    "\n",
    "# Take care of distributed/parallel training\n",
    "# model_to_save = model.module if hasattr(model, 'module') else model  \n",
    "# model_to_save.save_pretrained('{}epoch_2'.format(MODEL_PATH))\n",
    "# tokenizer.save_pretrained('{}epoch_2'.format(MODEL_PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Sr5_SPNlqGK"
   },
   "source": [
    "# PREDICT SCORES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lV8MeDT0mbwE"
   },
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "            train_dataset,\n",
    "            sampler=SequentialSampler(train_dataset),\n",
    "            batch_size=batch_size\n",
    "            )\n",
    "validation_dataloader = DataLoader(\n",
    "            val_dataset,\n",
    "            sampler = SequentialSampler(val_dataset),\n",
    "            batch_size = batch_size\n",
    "            )\n",
    "test_dataloader = DataLoader(\n",
    "            test_dataset,\n",
    "            sampler = SequentialSampler(test_dataset),\n",
    "            batch_size = batch_size\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3wcGAJLqmV06"
   },
   "source": [
    "## Epoch 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2109,
     "status": "ok",
     "timestamp": 1654586514657,
     "user": {
      "displayName": "Никита Орлов",
      "userId": "17221654573895787003"
     },
     "user_tz": -180
    },
    "id": "T3sgy7a5lDFg",
    "outputId": "5140549e-0505-4b45-f4a6-d681cc0ad239"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('{}epoch_1'.format(MODEL_PATH))\n",
    "model = BertForSequenceClassification.from_pretrained('{}epoch_1'.format(MODEL_PATH))\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2368594,
     "status": "ok",
     "timestamp": 1654593278715,
     "user": {
      "displayName": "Никита Орлов",
      "userId": "17221654573895787003"
     },
     "user_tz": -180
    },
    "id": "PRv5lqxzlDfP",
    "outputId": "46e6829f-5886-4d6f-f2ff-45bbd0dc23aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting labels for 886,038 test sentences...\n",
      "  Batch    40  of  3,462.    Elapsed: 0:01:18.\n",
      "  Batch    80  of  3,462.    Elapsed: 0:02:35.\n",
      "  Batch   120  of  3,462.    Elapsed: 0:03:53.\n",
      "  Batch   160  of  3,462.    Elapsed: 0:05:11.\n",
      "  Batch   200  of  3,462.    Elapsed: 0:06:28.\n",
      "  Batch   240  of  3,462.    Elapsed: 0:07:46.\n",
      "  Batch   280  of  3,462.    Elapsed: 0:09:04.\n",
      "  Batch   320  of  3,462.    Elapsed: 0:10:21.\n",
      "  Batch   360  of  3,462.    Elapsed: 0:11:39.\n",
      "  Batch   400  of  3,462.    Elapsed: 0:12:57.\n",
      "  Batch   440  of  3,462.    Elapsed: 0:14:14.\n",
      "  Batch   480  of  3,462.    Elapsed: 0:15:32.\n",
      "  Batch   520  of  3,462.    Elapsed: 0:16:50.\n",
      "  Batch   560  of  3,462.    Elapsed: 0:18:07.\n",
      "  Batch   600  of  3,462.    Elapsed: 0:19:25.\n",
      "  Batch   640  of  3,462.    Elapsed: 0:20:43.\n",
      "  Batch   680  of  3,462.    Elapsed: 0:22:00.\n",
      "  Batch   720  of  3,462.    Elapsed: 0:23:18.\n",
      "  Batch   760  of  3,462.    Elapsed: 0:24:36.\n",
      "  Batch   800  of  3,462.    Elapsed: 0:25:53.\n",
      "  Batch   840  of  3,462.    Elapsed: 0:27:11.\n",
      "  Batch   880  of  3,462.    Elapsed: 0:28:29.\n",
      "  Batch   920  of  3,462.    Elapsed: 0:29:46.\n",
      "  Batch   960  of  3,462.    Elapsed: 0:31:04.\n",
      "  Batch 1,000  of  3,462.    Elapsed: 0:32:22.\n",
      "  Batch 1,040  of  3,462.    Elapsed: 0:33:39.\n",
      "  Batch 1,080  of  3,462.    Elapsed: 0:34:57.\n",
      "  Batch 1,120  of  3,462.    Elapsed: 0:36:15.\n",
      "  Batch 1,160  of  3,462.    Elapsed: 0:37:32.\n",
      "  Batch 1,200  of  3,462.    Elapsed: 0:38:50.\n",
      "  Batch 1,240  of  3,462.    Elapsed: 0:40:08.\n",
      "  Batch 1,280  of  3,462.    Elapsed: 0:41:25.\n",
      "  Batch 1,320  of  3,462.    Elapsed: 0:42:43.\n",
      "  Batch 1,360  of  3,462.    Elapsed: 0:44:01.\n",
      "  Batch 1,400  of  3,462.    Elapsed: 0:45:18.\n",
      "  Batch 1,440  of  3,462.    Elapsed: 0:46:36.\n",
      "  Batch 1,480  of  3,462.    Elapsed: 0:47:54.\n",
      "  Batch 1,520  of  3,462.    Elapsed: 0:49:11.\n",
      "  Batch 1,560  of  3,462.    Elapsed: 0:50:29.\n",
      "  Batch 1,600  of  3,462.    Elapsed: 0:51:47.\n",
      "  Batch 1,640  of  3,462.    Elapsed: 0:53:04.\n",
      "  Batch 1,680  of  3,462.    Elapsed: 0:54:22.\n",
      "  Batch 1,720  of  3,462.    Elapsed: 0:55:40.\n",
      "  Batch 1,760  of  3,462.    Elapsed: 0:56:57.\n",
      "  Batch 1,800  of  3,462.    Elapsed: 0:58:15.\n",
      "  Batch 1,840  of  3,462.    Elapsed: 0:59:33.\n",
      "  Batch 1,880  of  3,462.    Elapsed: 1:00:50.\n",
      "  Batch 1,920  of  3,462.    Elapsed: 1:02:08.\n",
      "  Batch 1,960  of  3,462.    Elapsed: 1:03:26.\n",
      "  Batch 2,000  of  3,462.    Elapsed: 1:04:43.\n",
      "  Batch 2,040  of  3,462.    Elapsed: 1:06:01.\n",
      "  Batch 2,080  of  3,462.    Elapsed: 1:07:19.\n",
      "  Batch 2,120  of  3,462.    Elapsed: 1:08:36.\n",
      "  Batch 2,160  of  3,462.    Elapsed: 1:09:54.\n",
      "  Batch 2,200  of  3,462.    Elapsed: 1:11:12.\n",
      "  Batch 2,240  of  3,462.    Elapsed: 1:12:29.\n",
      "  Batch 2,280  of  3,462.    Elapsed: 1:13:47.\n",
      "  Batch 2,320  of  3,462.    Elapsed: 1:15:04.\n",
      "  Batch 2,360  of  3,462.    Elapsed: 1:16:22.\n",
      "  Batch 2,400  of  3,462.    Elapsed: 1:17:40.\n",
      "  Batch 2,440  of  3,462.    Elapsed: 1:18:57.\n",
      "  Batch 2,480  of  3,462.    Elapsed: 1:20:15.\n",
      "  Batch 2,520  of  3,462.    Elapsed: 1:21:33.\n",
      "  Batch 2,560  of  3,462.    Elapsed: 1:22:50.\n",
      "  Batch 2,600  of  3,462.    Elapsed: 1:24:08.\n",
      "  Batch 2,640  of  3,462.    Elapsed: 1:25:26.\n",
      "  Batch 2,680  of  3,462.    Elapsed: 1:26:43.\n",
      "  Batch 2,720  of  3,462.    Elapsed: 1:28:01.\n",
      "  Batch 2,760  of  3,462.    Elapsed: 1:29:19.\n",
      "  Batch 2,800  of  3,462.    Elapsed: 1:30:37.\n",
      "  Batch 2,840  of  3,462.    Elapsed: 1:31:54.\n",
      "  Batch 2,880  of  3,462.    Elapsed: 1:33:12.\n",
      "  Batch 2,920  of  3,462.    Elapsed: 1:34:30.\n",
      "  Batch 2,960  of  3,462.    Elapsed: 1:35:47.\n",
      "  Batch 3,000  of  3,462.    Elapsed: 1:37:05.\n",
      "  Batch 3,040  of  3,462.    Elapsed: 1:38:23.\n",
      "  Batch 3,080  of  3,462.    Elapsed: 1:39:40.\n",
      "  Batch 3,120  of  3,462.    Elapsed: 1:40:58.\n",
      "  Batch 3,160  of  3,462.    Elapsed: 1:42:15.\n",
      "  Batch 3,200  of  3,462.    Elapsed: 1:43:33.\n",
      "  Batch 3,240  of  3,462.    Elapsed: 1:44:51.\n",
      "  Batch 3,280  of  3,462.    Elapsed: 1:46:08.\n",
      "  Batch 3,320  of  3,462.    Elapsed: 1:47:26.\n",
      "  Batch 3,360  of  3,462.    Elapsed: 1:48:44.\n",
      "  Batch 3,400  of  3,462.    Elapsed: 1:50:01.\n",
      "  Batch 3,440  of  3,462.    Elapsed: 1:51:19.\n",
      "    DONE.\n",
      "0.9909812298330304\n",
      "category\n",
      "Бытовая электроника    0.984525\n",
      "Для бизнеса            0.938466\n",
      "Для дома и дачи        0.986483\n",
      "Животные               0.995989\n",
      "Личные вещи            0.991953\n",
      "Недвижимость           0.993003\n",
      "Работа                 0.979863\n",
      "Транспорт              0.993481\n",
      "Услуги                 0.985805\n",
      "Хобби и отдых          0.982197\n",
      "dtype: float64\n",
      "0.9831763576093808\n"
     ]
    }
   ],
   "source": [
    "print('Predicting labels for {:,} test sentences...'.format(len(train_input_ids)))\n",
    "\n",
    "t0 = time.time()\n",
    "model.eval()\n",
    "predictions , true_labels = [], []\n",
    " \n",
    "for step, batch in enumerate(train_dataloader):\n",
    "    if step % 40 == 0 and not step == 0:\n",
    "        elapsed = format_time(time.time() - t0)\n",
    "        print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(\n",
    "            step, len(train_dataloader), elapsed))\n",
    "\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "  \n",
    "    with torch.no_grad():\n",
    "        outputs = model(\n",
    "            b_input_ids, \n",
    "            token_type_ids=None, \n",
    "            attention_mask=b_input_mask)\n",
    "\n",
    "    logits = outputs[0]\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "    predictions.append(logits)\n",
    "    true_labels.append(label_ids)\n",
    "\n",
    "print('    DONE.')\n",
    "\n",
    "flat_predictions = np.concatenate(predictions, axis=0)\n",
    "flat_predictions = flat_predictions[:, 1].flatten()\n",
    "flat_true_labels = np.concatenate(true_labels, axis=0)\n",
    "\n",
    "df_train['predict_bert'] = flat_predictions\n",
    "\n",
    "print(roc_auc_score(flat_true_labels, df_train['predict_bert']))\n",
    "print(df_train.groupby(['category']).apply(auc_group))\n",
    "print(df_train.groupby(['category']).apply(auc_group).mean())\n",
    "\n",
    "df_train[['id', 'predict_bert']].to_csv(\n",
    "    '{}/bert_scores/epoch_1/X_train.csv'.format(FOLDER_PATH), sep='|')\n",
    "# pd.read_csv('{}/bert_scores/epoch_1/X_train.csv'.format(FOLDER_PATH), sep='|', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 747878,
     "status": "ok",
     "timestamp": 1654594664814,
     "user": {
      "displayName": "Никита Орлов",
      "userId": "17221654573895787003"
     },
     "user_tz": -180
    },
    "id": "PqACqHuflDpG",
    "outputId": "e78406f9-f574-42bc-fa95-448fa07db787"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting labels for 98,449 test sentences...\n",
      "  Batch    40  of    385.    Elapsed: 0:01:18.\n",
      "  Batch    80  of    385.    Elapsed: 0:02:35.\n",
      "  Batch   120  of    385.    Elapsed: 0:03:53.\n",
      "  Batch   160  of    385.    Elapsed: 0:05:11.\n",
      "  Batch   200  of    385.    Elapsed: 0:06:28.\n",
      "  Batch   240  of    385.    Elapsed: 0:07:46.\n",
      "  Batch   280  of    385.    Elapsed: 0:09:04.\n",
      "  Batch   320  of    385.    Elapsed: 0:10:21.\n",
      "  Batch   360  of    385.    Elapsed: 0:11:39.\n",
      "    DONE.\n",
      "0.9890402769725187\n",
      "category\n",
      "Бытовая электроника    0.979131\n",
      "Для бизнеса            0.909541\n",
      "Для дома и дачи        0.984002\n",
      "Животные               0.994192\n",
      "Личные вещи            0.991080\n",
      "Недвижимость           0.991627\n",
      "Работа                 0.972892\n",
      "Транспорт              0.992203\n",
      "Услуги                 0.983476\n",
      "Хобби и отдых          0.978216\n",
      "dtype: float64\n",
      "0.9776359457039107\n"
     ]
    }
   ],
   "source": [
    "print('Predicting labels for {:,} test sentences...'.format(len(val_input_ids)))\n",
    "\n",
    "t0 = time.time()\n",
    "model.eval()\n",
    "\n",
    "predictions , true_labels = [], []\n",
    "\n",
    "for step, batch in enumerate(validation_dataloader):\n",
    "    if step % 40 == 0 and not step == 0:\n",
    "        elapsed = format_time(time.time() - t0)\n",
    "        print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(\n",
    "            step, len(validation_dataloader), elapsed))\n",
    "\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "  \n",
    "    with torch.no_grad():\n",
    "        outputs = model(\n",
    "            b_input_ids, \n",
    "            token_type_ids=None, \n",
    "            attention_mask=b_input_mask)\n",
    "\n",
    "    logits = outputs[0]\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "    predictions.append(logits)\n",
    "    true_labels.append(label_ids)\n",
    "\n",
    "print('    DONE.')\n",
    "\n",
    "flat_predictions = np.concatenate(predictions, axis=0)\n",
    "flat_predictions = flat_predictions[:, 1].flatten()\n",
    "flat_true_labels = np.concatenate(true_labels, axis=0)\n",
    "\n",
    "df_val['predict_bert'] = flat_predictions\n",
    "\n",
    "print(roc_auc_score(flat_true_labels, df_val['predict_bert']))\n",
    "print(df_val.groupby(['category']).apply(auc_group))\n",
    "print(df_val.groupby(['category']).apply(auc_group).mean())\n",
    "\n",
    "df_val[['id', 'predict_bert']].to_csv(\n",
    "    '{}/bert_scores/epoch_1/X_val.csv'.format(FOLDER_PATH), sep='|')\n",
    "# pd.read_csv('{}/bert_scores/epoch_1/X_val.csv'.format(FOLDER_PATH), sep='|', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 123666,
     "status": "ok",
     "timestamp": 1654595088027,
     "user": {
      "displayName": "Никита Орлов",
      "userId": "17221654573895787003"
     },
     "user_tz": -180
    },
    "id": "rImeFQgqlDtv",
    "outputId": "e164dac9-7181-44d1-eab4-264ab9747e5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting labels for 16,237 test sentences...\n",
      "  Batch    40  of     64.    Elapsed: 0:01:18.\n",
      "    DONE.\n",
      "0.9772855360449079\n",
      "category\n",
      "Бытовая электроника    0.957294\n",
      "Для бизнеса            0.827395\n",
      "Для дома и дачи        0.961471\n",
      "Животные               0.965079\n",
      "Личные вещи            0.819097\n",
      "Недвижимость           0.989863\n",
      "Работа                 0.969762\n",
      "Транспорт              0.995151\n",
      "Услуги                 0.948250\n",
      "Хобби и отдых          0.917549\n",
      "dtype: float64\n",
      "0.9350910975603\n"
     ]
    }
   ],
   "source": [
    "print('Predicting labels for {:,} test sentences...'.format(len(test_input_ids)))\n",
    "\n",
    "t0 = time.time()\n",
    "model.eval()\n",
    "\n",
    "predictions , true_labels = [], []\n",
    "\n",
    "for step, batch in enumerate(test_dataloader):\n",
    "    if step % 40 == 0 and not step == 0:\n",
    "        elapsed = format_time(time.time() - t0)\n",
    "        print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(\n",
    "            step, len(test_dataloader), elapsed))\n",
    "  \n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(\n",
    "            b_input_ids, \n",
    "            token_type_ids=None, \n",
    "            attention_mask=b_input_mask)\n",
    "  \n",
    "    logits = outputs[0]\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "    predictions.append(logits)\n",
    "    true_labels.append(label_ids)\n",
    "\n",
    "print('    DONE.')\n",
    "\n",
    "flat_predictions = np.concatenate(predictions, axis=0)\n",
    "flat_predictions = flat_predictions[:, 1].flatten()\n",
    "flat_true_labels = np.concatenate(true_labels, axis=0)\n",
    "\n",
    "df_test['predict_bert'] = flat_predictions\n",
    "\n",
    "print(roc_auc_score(flat_true_labels, df_test['predict_bert']))\n",
    "print(df_test.groupby(['category']).apply(auc_group))\n",
    "print(df_test.groupby(['category']).apply(auc_group).mean())\n",
    "\n",
    "df_test[['id', 'predict_bert']].to_csv(\n",
    "    '{}/bert_scores/epoch_1/X_test.csv'.format(FOLDER_PATH), sep='|')\n",
    "# pd.read_csv('{}/bert_scores/epoch_1/X_test.csv'.format(FOLDER_PATH), sep='|', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J1DVNvZXnJnZ"
   },
   "source": [
    "## EPOCH 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8807,
     "status": "ok",
     "timestamp": 1654638355473,
     "user": {
      "displayName": "Никита Орлов",
      "userId": "17221654573895787003"
     },
     "user_tz": -180
    },
    "id": "xDqvVgq2lETD",
    "outputId": "2dc23171-b32d-421f-df77-cffdb6ae943d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('{}epoch_2'.format(MODEL_PATH))\n",
    "model = BertForSequenceClassification.from_pretrained('{}epoch_2'.format(MODEL_PATH))\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2467134,
     "status": "ok",
     "timestamp": 1654651842613,
     "user": {
      "displayName": "Никита Орлов",
      "userId": "17221654573895787003"
     },
     "user_tz": -180
    },
    "id": "lKgGoOLtOcyb",
    "outputId": "c923dff7-1c32-4a9c-923a-0edadb68dd1e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting labels for 886,038 test sentences...\n",
      "  Batch    40  of  3,462.    Elapsed: 0:02:36.\n",
      "  Batch    80  of  3,462.    Elapsed: 0:05:12.\n",
      "  Batch   120  of  3,462.    Elapsed: 0:07:48.\n",
      "  Batch   160  of  3,462.    Elapsed: 0:10:23.\n",
      "  Batch   200  of  3,462.    Elapsed: 0:12:59.\n",
      "  Batch   240  of  3,462.    Elapsed: 0:15:35.\n",
      "  Batch   280  of  3,462.    Elapsed: 0:18:10.\n",
      "  Batch   320  of  3,462.    Elapsed: 0:20:46.\n",
      "  Batch   360  of  3,462.    Elapsed: 0:23:22.\n",
      "  Batch   400  of  3,462.    Elapsed: 0:25:57.\n",
      "  Batch   440  of  3,462.    Elapsed: 0:28:32.\n",
      "  Batch   480  of  3,462.    Elapsed: 0:31:08.\n",
      "  Batch   520  of  3,462.    Elapsed: 0:33:44.\n",
      "  Batch   560  of  3,462.    Elapsed: 0:36:19.\n",
      "  Batch   600  of  3,462.    Elapsed: 0:38:55.\n",
      "  Batch   640  of  3,462.    Elapsed: 0:41:30.\n",
      "  Batch   680  of  3,462.    Elapsed: 0:44:06.\n",
      "  Batch   720  of  3,462.    Elapsed: 0:46:42.\n",
      "  Batch   760  of  3,462.    Elapsed: 0:49:17.\n",
      "  Batch   800  of  3,462.    Elapsed: 0:51:53.\n",
      "  Batch   840  of  3,462.    Elapsed: 0:54:29.\n",
      "  Batch   880  of  3,462.    Elapsed: 0:57:04.\n",
      "  Batch   920  of  3,462.    Elapsed: 0:59:40.\n",
      "  Batch   960  of  3,462.    Elapsed: 1:02:16.\n",
      "  Batch 1,000  of  3,462.    Elapsed: 1:04:51.\n",
      "  Batch 1,040  of  3,462.    Elapsed: 1:07:27.\n",
      "  Batch 1,080  of  3,462.    Elapsed: 1:10:03.\n",
      "  Batch 1,120  of  3,462.    Elapsed: 1:12:39.\n",
      "  Batch 1,160  of  3,462.    Elapsed: 1:15:14.\n",
      "  Batch 1,200  of  3,462.    Elapsed: 1:17:50.\n",
      "  Batch 1,240  of  3,462.    Elapsed: 1:20:26.\n",
      "  Batch 1,280  of  3,462.    Elapsed: 1:23:02.\n",
      "  Batch 1,320  of  3,462.    Elapsed: 1:25:38.\n",
      "  Batch 1,360  of  3,462.    Elapsed: 1:28:14.\n",
      "  Batch 1,400  of  3,462.    Elapsed: 1:30:49.\n",
      "  Batch 1,440  of  3,462.    Elapsed: 1:33:25.\n",
      "  Batch 1,480  of  3,462.    Elapsed: 1:36:01.\n",
      "  Batch 1,520  of  3,462.    Elapsed: 1:38:36.\n",
      "  Batch 1,560  of  3,462.    Elapsed: 1:41:12.\n",
      "  Batch 1,600  of  3,462.    Elapsed: 1:43:47.\n",
      "  Batch 1,640  of  3,462.    Elapsed: 1:46:23.\n",
      "  Batch 1,680  of  3,462.    Elapsed: 1:48:59.\n",
      "  Batch 1,720  of  3,462.    Elapsed: 1:51:35.\n",
      "  Batch 1,760  of  3,462.    Elapsed: 1:54:11.\n",
      "  Batch 1,800  of  3,462.    Elapsed: 1:56:46.\n",
      "  Batch 1,840  of  3,462.    Elapsed: 1:59:22.\n",
      "  Batch 1,880  of  3,462.    Elapsed: 2:01:58.\n",
      "  Batch 1,920  of  3,462.    Elapsed: 2:04:34.\n",
      "  Batch 1,960  of  3,462.    Elapsed: 2:07:10.\n",
      "  Batch 2,000  of  3,462.    Elapsed: 2:09:46.\n",
      "  Batch 2,040  of  3,462.    Elapsed: 2:12:21.\n",
      "  Batch 2,080  of  3,462.    Elapsed: 2:14:57.\n",
      "  Batch 2,120  of  3,462.    Elapsed: 2:17:33.\n",
      "  Batch 2,160  of  3,462.    Elapsed: 2:20:08.\n",
      "  Batch 2,200  of  3,462.    Elapsed: 2:22:44.\n",
      "  Batch 2,240  of  3,462.    Elapsed: 2:25:19.\n",
      "  Batch 2,280  of  3,462.    Elapsed: 2:27:55.\n",
      "  Batch 2,320  of  3,462.    Elapsed: 2:30:30.\n",
      "  Batch 2,360  of  3,462.    Elapsed: 2:33:06.\n",
      "  Batch 2,400  of  3,462.    Elapsed: 2:35:42.\n",
      "  Batch 2,440  of  3,462.    Elapsed: 2:38:17.\n",
      "  Batch 2,480  of  3,462.    Elapsed: 2:40:53.\n",
      "  Batch 2,520  of  3,462.    Elapsed: 2:43:29.\n",
      "  Batch 2,560  of  3,462.    Elapsed: 2:46:05.\n",
      "  Batch 2,600  of  3,462.    Elapsed: 2:48:40.\n",
      "  Batch 2,640  of  3,462.    Elapsed: 2:51:16.\n",
      "  Batch 2,680  of  3,462.    Elapsed: 2:53:51.\n",
      "  Batch 2,720  of  3,462.    Elapsed: 2:56:27.\n",
      "  Batch 2,760  of  3,462.    Elapsed: 2:59:03.\n",
      "  Batch 2,800  of  3,462.    Elapsed: 3:01:39.\n",
      "  Batch 2,840  of  3,462.    Elapsed: 3:04:14.\n",
      "  Batch 2,880  of  3,462.    Elapsed: 3:06:50.\n",
      "  Batch 2,920  of  3,462.    Elapsed: 3:09:26.\n",
      "  Batch 2,960  of  3,462.    Elapsed: 3:12:02.\n",
      "  Batch 3,000  of  3,462.    Elapsed: 3:14:37.\n",
      "  Batch 3,040  of  3,462.    Elapsed: 3:17:13.\n",
      "  Batch 3,080  of  3,462.    Elapsed: 3:19:49.\n",
      "  Batch 3,120  of  3,462.    Elapsed: 3:22:24.\n",
      "  Batch 3,160  of  3,462.    Elapsed: 3:25:00.\n",
      "  Batch 3,200  of  3,462.    Elapsed: 3:27:36.\n",
      "  Batch 3,240  of  3,462.    Elapsed: 3:30:12.\n",
      "  Batch 3,280  of  3,462.    Elapsed: 3:32:48.\n",
      "  Batch 3,320  of  3,462.    Elapsed: 3:35:24.\n",
      "  Batch 3,360  of  3,462.    Elapsed: 3:38:00.\n",
      "  Batch 3,400  of  3,462.    Elapsed: 3:40:36.\n",
      "  Batch 3,440  of  3,462.    Elapsed: 3:43:12.\n",
      "    DONE.\n",
      "0.9938641955995801\n",
      "category\n",
      "Бытовая электроника    0.990385\n",
      "Для бизнеса            0.964454\n",
      "Для дома и дачи        0.990624\n",
      "Животные               0.996793\n",
      "Личные вещи            0.994647\n",
      "Недвижимость           0.994542\n",
      "Работа                 0.988002\n",
      "Транспорт              0.995327\n",
      "Услуги                 0.989910\n",
      "Хобби и отдых          0.987872\n",
      "dtype: float64\n",
      "0.9892553508430284\n"
     ]
    }
   ],
   "source": [
    "print('Predicting labels for {:,} test sentences...'.format(len(train_input_ids)))\n",
    "\n",
    "t0 = time.time()\n",
    "model.eval()\n",
    "predictions , true_labels = [], []\n",
    " \n",
    "for step, batch in enumerate(train_dataloader):\n",
    "    if step % 40 == 0 and not step == 0:\n",
    "        elapsed = format_time(time.time() - t0)\n",
    "        print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(\n",
    "            step, len(train_dataloader), elapsed))\n",
    "\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(\n",
    "            b_input_ids, \n",
    "            token_type_ids=None, \n",
    "            attention_mask=b_input_mask)\n",
    "\n",
    "    logits = outputs[0]\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "    predictions.append(logits)\n",
    "    true_labels.append(label_ids)\n",
    "\n",
    "print('    DONE.')\n",
    "\n",
    "flat_predictions = np.concatenate(predictions, axis=0)\n",
    "flat_predictions = flat_predictions[:, 1].flatten()\n",
    "flat_true_labels = np.concatenate(true_labels, axis=0)\n",
    "\n",
    "df_train['predict_bert'] = flat_predictions\n",
    "\n",
    "print(roc_auc_score(flat_true_labels, df_train['predict_bert']))\n",
    "print(df_train.groupby(['category']).apply(auc_group))\n",
    "print(df_train.groupby(['category']).apply(auc_group).mean())\n",
    "\n",
    "df_train[['id', 'predict_bert']].to_csv(\n",
    "    '{}/bert_scores/epoch_2/X_train.csv'.format(FOLDER_PATH), sep='|')\n",
    "# pd.read_csv('{}/bert_scores/epoch_2/X_train.csv'.format(FOLDER_PATH), sep='|', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1500409,
     "status": "ok",
     "timestamp": 1654653343025,
     "user": {
      "displayName": "Никита Орлов",
      "userId": "17221654573895787003"
     },
     "user_tz": -180
    },
    "id": "RWx83keRHyQ9",
    "outputId": "5a310cd8-45bc-47f2-d849-64fbab88d58c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting labels for 98,449 test sentences...\n",
      "  Batch    40  of    385.    Elapsed: 0:02:36.\n",
      "  Batch    80  of    385.    Elapsed: 0:05:12.\n",
      "  Batch   120  of    385.    Elapsed: 0:07:47.\n",
      "  Batch   160  of    385.    Elapsed: 0:10:23.\n",
      "  Batch   200  of    385.    Elapsed: 0:12:59.\n",
      "  Batch   240  of    385.    Elapsed: 0:15:35.\n",
      "  Batch   280  of    385.    Elapsed: 0:18:11.\n",
      "  Batch   320  of    385.    Elapsed: 0:20:47.\n",
      "  Batch   360  of    385.    Elapsed: 0:23:23.\n",
      "    DONE.\n",
      "0.9901755146496052\n",
      "category\n",
      "Бытовая электроника    0.984113\n",
      "Для бизнеса            0.916818\n",
      "Для дома и дачи        0.985664\n",
      "Животные               0.994496\n",
      "Личные вещи            0.991983\n",
      "Недвижимость           0.991764\n",
      "Работа                 0.975350\n",
      "Транспорт              0.993404\n",
      "Услуги                 0.983979\n",
      "Хобби и отдых          0.977090\n",
      "dtype: float64\n",
      "0.9794662319041224\n"
     ]
    }
   ],
   "source": [
    "print('Predicting labels for {:,} test sentences...'.format(len(val_input_ids)))\n",
    "\n",
    "t0 = time.time()\n",
    "model.eval()\n",
    "\n",
    "predictions , true_labels = [], []\n",
    "\n",
    "for step, batch in enumerate(validation_dataloader):\n",
    "    if step % 40 == 0 and not step == 0:\n",
    "        elapsed = format_time(time.time() - t0)\n",
    "        print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(\n",
    "            step, len(validation_dataloader), elapsed))\n",
    "\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "  \n",
    "    with torch.no_grad():\n",
    "        outputs = model(\n",
    "            b_input_ids, \n",
    "            token_type_ids=None, \n",
    "            attention_mask=b_input_mask)\n",
    "\n",
    "    logits = outputs[0]\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "    predictions.append(logits)\n",
    "    true_labels.append(label_ids)\n",
    "\n",
    "print('    DONE.')\n",
    "\n",
    "flat_predictions = np.concatenate(predictions, axis=0)\n",
    "flat_predictions = flat_predictions[:, 1].flatten()\n",
    "flat_true_labels = np.concatenate(true_labels, axis=0)\n",
    "\n",
    "df_val['predict_bert'] = flat_predictions\n",
    "\n",
    "print(roc_auc_score(flat_true_labels, df_val['predict_bert']))\n",
    "print(df_val.groupby(['category']).apply(auc_group))\n",
    "print(df_val.groupby(['category']).apply(auc_group).mean())\n",
    "\n",
    "df_val[['id', 'predict_bert']].to_csv(\n",
    "    '{}/bert_scores/epoch_2/X_val.csv'.format(FOLDER_PATH), sep='|')\n",
    "# pd.read_csv('{}/bert_scores/epoch_2/X_val.csv'.format(FOLDER_PATH), sep='|', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 247099,
     "status": "ok",
     "timestamp": 1654653590088,
     "user": {
      "displayName": "Никита Орлов",
      "userId": "17221654573895787003"
     },
     "user_tz": -180
    },
    "id": "BOfPFeGDaXkA",
    "outputId": "cfa791ad-3722-4cc9-c268-1db2d44bc51d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting labels for 16,237 test sentences...\n",
      "  Batch    40  of     64.    Elapsed: 0:02:36.\n",
      "    DONE.\n",
      "0.982158992977741\n",
      "category\n",
      "Бытовая электроника    0.968108\n",
      "Для бизнеса            0.911899\n",
      "Для дома и дачи        0.970597\n",
      "Животные               0.965533\n",
      "Личные вещи            0.859187\n",
      "Недвижимость           0.991380\n",
      "Работа                 0.979102\n",
      "Транспорт              0.995556\n",
      "Услуги                 0.951216\n",
      "Хобби и отдых          0.929565\n",
      "dtype: float64\n",
      "0.9522144032508862\n"
     ]
    }
   ],
   "source": [
    "print('Predicting labels for {:,} test sentences...'.format(len(test_input_ids)))\n",
    "\n",
    "t0 = time.time()\n",
    "model.eval()\n",
    "\n",
    "predictions , true_labels = [], []\n",
    "\n",
    "for step, batch in enumerate(test_dataloader):\n",
    "    if step % 40 == 0 and not step == 0:\n",
    "        elapsed = format_time(time.time() - t0)\n",
    "        print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(test_dataloader), elapsed))\n",
    "  \n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "  \n",
    "    with torch.no_grad():\n",
    "        outputs = model(\n",
    "            b_input_ids, \n",
    "            token_type_ids=None, \n",
    "            attention_mask=b_input_mask)\n",
    "  \n",
    "    logits = outputs[0]\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "\n",
    "    predictions.append(logits)\n",
    "    true_labels.append(label_ids)\n",
    "\n",
    "print('    DONE.')\n",
    "\n",
    "flat_predictions = np.concatenate(predictions, axis=0)\n",
    "flat_predictions = flat_predictions[:, 1].flatten()\n",
    "flat_true_labels = np.concatenate(true_labels, axis=0)\n",
    "\n",
    "df_test['predict_bert'] = flat_predictions\n",
    "\n",
    "print(roc_auc_score(flat_true_labels, df_test['predict_bert']))\n",
    "print(df_test.groupby(['category']).apply(auc_group))\n",
    "print(df_test.groupby(['category']).apply(auc_group).mean())\n",
    "\n",
    "df_test[['id', 'predict_bert']].to_csv(\n",
    "    '{}/bert_scores/epoch_2/X_test.csv'.format(FOLDER_PATH), sep='|')\n",
    "# pd.read_csv('{}/bert_scores/epoch_2/X_test.csv'.format(FOLDER_PATH), sep='|', index_col=0)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMZwgC8MLrzJKpmjorPETuv",
   "collapsed_sections": [],
   "machine_shape": "hm",
   "mount_file_id": "1DeY76aa055GqUCM_P0SocvigtTy9BK6k",
   "provenance": [
    {
     "file_id": "1DeY76aa055GqUCM_P0SocvigtTy9BK6k",
     "timestamp": 1664806480180
    },
    {
     "file_id": "1AfcJqrprKDmgO0_qbffR55Bvi52uNbbW",
     "timestamp": 1654514311444
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "05791eff4b74487f995a6cd51a8ce486": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_60b820e8f550425f95796cd2f0ecca3b",
      "placeholder": "​",
      "style": "IPY_MODEL_32cd25fcbe1941cf9674d49f66fa837c",
      "value": "Downloading: 100%"
     }
    },
    "057a965896ed4378ab5339db4b6155d4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "05a057f5242247f586ed2cc6468e4aa9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "05fbe7bb7190462d9e1189d2e81fb7f6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "071b93d88c17473aad8b3fcdb7801c41": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_abf2d3c4c5c944e3ae83ff0cba9f4b44",
      "max": 714355318,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0b4af6ff48bb4e7caf64e0e802ddadad",
      "value": 714355318
     }
    },
    "095dfcdff7944b0c9470e0fe85f69225": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0b4af6ff48bb4e7caf64e0e802ddadad": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "11374bd33580487483d643da4c38d838": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1b798bb4873842a68a4fd6e1061f58fa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cc5ea50bc77a434488a5bc88e8ee13f1",
      "max": 886038,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_057a965896ed4378ab5339db4b6155d4",
      "value": 886038
     }
    },
    "1c774e0029b0451b9ae6c3af7b8a1141": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4a3ad148b12c4af4be28dc579ca4180d",
      "max": 24,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_50b37be900a24c40bb50c8976261836c",
      "value": 24
     }
    },
    "1f8cb1a444fc4ea7847f7b72f517498c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "23897c9fe7cc40818615466a92a7a928": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_da8caa8d438c4418af22e61c56521da7",
      "max": 642,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e0321a99b6d74bc98e5b8f43c8418055",
      "value": 642
     }
    },
    "24e36f8a747347adaee71ec8baff30ba": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2867cfebe57c41a290c702c879635fa3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "29a00386264b4e62b9ea5d6e1067054c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_30438e54b06e4b12833ffe738cb9d233",
      "max": 1649718,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_cf7274ce4c3d42028ad256108e67f120",
      "value": 1649718
     }
    },
    "2c10bd5bbadb4042b9a83388e7d55fff": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2cf074fb0ace470d90e82fef4a4be4c0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7d3dd9bcd2544d8b894e88fcdb1eca6f",
      "placeholder": "​",
      "style": "IPY_MODEL_3d5429c2c86c46fa83f6a52e7a6ccb80",
      "value": " 16237/16237 [00:57&lt;00:00, 301.78it/s]"
     }
    },
    "2e08d9642e4745d8a0997ddd73033fbf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "30438e54b06e4b12833ffe738cb9d233": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "30b30a1d140740e4bde9543a617e635a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_484099351add4e5592fd3eb789fae512",
      "max": 112,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b00badb5a5bd40b599f24d284205dfcb",
      "value": 112
     }
    },
    "32cd25fcbe1941cf9674d49f66fa837c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3cc1e5ac220845fe9d307828267ab28c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3fba166dda4c4ab5ad57ff3630238b64",
       "IPY_MODEL_1c774e0029b0451b9ae6c3af7b8a1141",
       "IPY_MODEL_7ce6f44f6bfb484b89a15884fa1e3542"
      ],
      "layout": "IPY_MODEL_a353afa3a08f44d1961cb0bfe68e3e52"
     }
    },
    "3d5429c2c86c46fa83f6a52e7a6ccb80": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3ebfd9fdcdb042b2b5e13308aa872e93": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9e754f6b27ce4004b6229e5e9b3bcbfa",
      "max": 98449,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_05fbe7bb7190462d9e1189d2e81fb7f6",
      "value": 98449
     }
    },
    "3fba166dda4c4ab5ad57ff3630238b64": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a44c550b9a9c401cb947082e6a265b26",
      "placeholder": "​",
      "style": "IPY_MODEL_758b78759d75479ab441efcc9f1e32dc",
      "value": "Downloading: 100%"
     }
    },
    "44f319aff64c4bd1bbb9c71abbde14c7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "484099351add4e5592fd3eb789fae512": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4a3ad148b12c4af4be28dc579ca4180d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4b5e777a4a96423daca8076369398642": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4ba0da3784784e9b96e1c257d355c011": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "50b37be900a24c40bb50c8976261836c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "523bd4d09a58439794e7706be0787d11": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "593ba65557a541b8bdb38037d9fd0a1e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5c4b7ba1d4bc4f1c9a236f8012ad0d26": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5cee5851f1f447668c9bdc6907bfc2f0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d3c1327977484bb2acd15cd33ec7e119",
       "IPY_MODEL_23897c9fe7cc40818615466a92a7a928",
       "IPY_MODEL_8f63360cfacc49f388fdb848097d5ec4"
      ],
      "layout": "IPY_MODEL_1f8cb1a444fc4ea7847f7b72f517498c"
     }
    },
    "5d5cfc77b6e24a26a3fa64cb22c64fad": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5da14ccd33844a89a47b88a63e90c5a6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8f96098c11ce412c9abd6765d7ef0a27",
       "IPY_MODEL_1b798bb4873842a68a4fd6e1061f58fa",
       "IPY_MODEL_6ea7ff4b866e4023a37e890f44bda847"
      ],
      "layout": "IPY_MODEL_e67f25a6e9b24c6395607e80fbe4e418"
     }
    },
    "60b820e8f550425f95796cd2f0ecca3b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "65a8d99e2bd54dc4b3b4c7aef779b2df": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b61afbe1091840f29a2faed5bde0875f",
      "placeholder": "​",
      "style": "IPY_MODEL_feba45020c754830b7332a4b329c0e9f",
      "value": " 112/112 [00:00&lt;00:00, 3.98kB/s]"
     }
    },
    "6d5edf645e12481f934e60caba667fe0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6ea7ff4b866e4023a37e890f44bda847": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_92d14e2ad1a54671b9380c6ca94bf14b",
      "placeholder": "​",
      "style": "IPY_MODEL_5d5cfc77b6e24a26a3fa64cb22c64fad",
      "value": " 886038/886038 [40:32&lt;00:00, 369.42it/s]"
     }
    },
    "758b78759d75479ab441efcc9f1e32dc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7ce6f44f6bfb484b89a15884fa1e3542": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c068ad5eb1b44047993cbbef767be0f8",
      "placeholder": "​",
      "style": "IPY_MODEL_b837e6a7bac24fedb92b7802168ce640",
      "value": " 24.0/24.0 [00:00&lt;00:00, 800B/s]"
     }
    },
    "7d3dd9bcd2544d8b894e88fcdb1eca6f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "81910c054aeb4e36a6574d8fdded3f00": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "876182259d4641c6924e0c0b6cf44ed9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d7f676d7537e4534b61cbc2047071705",
       "IPY_MODEL_29a00386264b4e62b9ea5d6e1067054c",
       "IPY_MODEL_aaddc2bb67d6417cb6423d8e596b1bf9"
      ],
      "layout": "IPY_MODEL_4b5e777a4a96423daca8076369398642"
     }
    },
    "8a8dd96b7fb04e14bf030320b4e21194": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8bf26675224348db9a67a98b71213b59": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8f63360cfacc49f388fdb848097d5ec4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2e08d9642e4745d8a0997ddd73033fbf",
      "placeholder": "​",
      "style": "IPY_MODEL_81910c054aeb4e36a6574d8fdded3f00",
      "value": " 642/642 [00:00&lt;00:00, 24.8kB/s]"
     }
    },
    "8f96098c11ce412c9abd6765d7ef0a27": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2867cfebe57c41a290c702c879635fa3",
      "placeholder": "​",
      "style": "IPY_MODEL_4ba0da3784784e9b96e1c257d355c011",
      "value": "100%"
     }
    },
    "92d14e2ad1a54671b9380c6ca94bf14b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "952aabb078474aa299ce60bcd38af2c6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "95906dd8dfdc431bbc58679dc8bda46e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b3713751711b4557897a6ce904fc6377",
       "IPY_MODEL_3ebfd9fdcdb042b2b5e13308aa872e93",
       "IPY_MODEL_ae8b408ea4c2484da9b6f01e8530bb01"
      ],
      "layout": "IPY_MODEL_24e36f8a747347adaee71ec8baff30ba"
     }
    },
    "9e754f6b27ce4004b6229e5e9b3bcbfa": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a353afa3a08f44d1961cb0bfe68e3e52": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a376f520e405413fb03ba1d402e12d56": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a44c550b9a9c401cb947082e6a265b26": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a92f0d23b5774fa1bafe30a24eecf4d1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "aaddc2bb67d6417cb6423d8e596b1bf9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_593ba65557a541b8bdb38037d9fd0a1e",
      "placeholder": "​",
      "style": "IPY_MODEL_a92f0d23b5774fa1bafe30a24eecf4d1",
      "value": " 1.57M/1.57M [00:00&lt;00:00, 3.73MB/s]"
     }
    },
    "ab5762e0ac4d4994a96012f5db4aea0a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "abf2d3c4c5c944e3ae83ff0cba9f4b44": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ae8b408ea4c2484da9b6f01e8530bb01": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_095dfcdff7944b0c9470e0fe85f69225",
      "placeholder": "​",
      "style": "IPY_MODEL_fddb966dbc184598b3fbf401fceb1462",
      "value": " 98449/98449 [04:36&lt;00:00, 378.55it/s]"
     }
    },
    "aec7707589d24291b9e5ef97f90daee1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "af032737f88a497baea5cfcd1eff8c81": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b00badb5a5bd40b599f24d284205dfcb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b3713751711b4557897a6ce904fc6377": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_05a057f5242247f586ed2cc6468e4aa9",
      "placeholder": "​",
      "style": "IPY_MODEL_d396c4021235419080e8c93a72cd017e",
      "value": "100%"
     }
    },
    "b61afbe1091840f29a2faed5bde0875f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b837e6a7bac24fedb92b7802168ce640": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bf1b459ed2c64ac6aad50ca2ead6b418": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_952aabb078474aa299ce60bcd38af2c6",
      "placeholder": "​",
      "style": "IPY_MODEL_e58cb3a9d5b64acbaf11ef3d15032f2c",
      "value": "100%"
     }
    },
    "c068ad5eb1b44047993cbbef767be0f8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c0e686f5f4eb4641b7a466d9d993d417": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_05791eff4b74487f995a6cd51a8ce486",
       "IPY_MODEL_071b93d88c17473aad8b3fcdb7801c41",
       "IPY_MODEL_e0cbaa0fe4884257a6863fb934c9cdee"
      ],
      "layout": "IPY_MODEL_ab5762e0ac4d4994a96012f5db4aea0a"
     }
    },
    "c6a086f0872d4c6caccbb438bf5cc300": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cc5ea50bc77a434488a5bc88e8ee13f1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cf7274ce4c3d42028ad256108e67f120": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d396c4021235419080e8c93a72cd017e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d3c1327977484bb2acd15cd33ec7e119": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6d5edf645e12481f934e60caba667fe0",
      "placeholder": "​",
      "style": "IPY_MODEL_44f319aff64c4bd1bbb9c71abbde14c7",
      "value": "Downloading: 100%"
     }
    },
    "d7f676d7537e4534b61cbc2047071705": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5c4b7ba1d4bc4f1c9a236f8012ad0d26",
      "placeholder": "​",
      "style": "IPY_MODEL_c6a086f0872d4c6caccbb438bf5cc300",
      "value": "Downloading: 100%"
     }
    },
    "da8caa8d438c4418af22e61c56521da7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "df09aace68a143829e3eb99b6859d138": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8bf26675224348db9a67a98b71213b59",
      "placeholder": "​",
      "style": "IPY_MODEL_a376f520e405413fb03ba1d402e12d56",
      "value": "Downloading: 100%"
     }
    },
    "dfa9a81186764e1db86c2fb5e16a4aad": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_df09aace68a143829e3eb99b6859d138",
       "IPY_MODEL_30b30a1d140740e4bde9543a617e635a",
       "IPY_MODEL_65a8d99e2bd54dc4b3b4c7aef779b2df"
      ],
      "layout": "IPY_MODEL_af032737f88a497baea5cfcd1eff8c81"
     }
    },
    "e0321a99b6d74bc98e5b8f43c8418055": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e0cbaa0fe4884257a6863fb934c9cdee": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8a8dd96b7fb04e14bf030320b4e21194",
      "placeholder": "​",
      "style": "IPY_MODEL_2c10bd5bbadb4042b9a83388e7d55fff",
      "value": " 681M/681M [00:11&lt;00:00, 68.3MB/s]"
     }
    },
    "e58cb3a9d5b64acbaf11ef3d15032f2c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e67f25a6e9b24c6395607e80fbe4e418": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ed81d0dcffc244c6963f97a3cd3ac91b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_aec7707589d24291b9e5ef97f90daee1",
      "max": 16237,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_523bd4d09a58439794e7706be0787d11",
      "value": 16237
     }
    },
    "f65213fb61534f91812fb209fe851104": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_bf1b459ed2c64ac6aad50ca2ead6b418",
       "IPY_MODEL_ed81d0dcffc244c6963f97a3cd3ac91b",
       "IPY_MODEL_2cf074fb0ace470d90e82fef4a4be4c0"
      ],
      "layout": "IPY_MODEL_11374bd33580487483d643da4c38d838"
     }
    },
    "fddb966dbc184598b3fbf401fceb1462": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "feba45020c754830b7332a4b329c0e9f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
